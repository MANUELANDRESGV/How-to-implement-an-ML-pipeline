{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VALIDACIONCRUZADA",
      "provenance": [],
      "authorship_tag": "ABX9TyMpLHZ8rFoYDG1nMDm/7pPN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MANUELANDRESGV/How-to-implement-an-ML-pipeline/blob/master/VALIDACIONCRUZADA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cWEiEWLErsZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import decomposition \n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score,KFold\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "p7CGLu0lj8lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data.csv')#LECTURA DAT"
      ],
      "metadata": {
        "id": "jL2wmDtcFw4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWwyehGxFw80",
        "outputId": "4f6aeb35-3bbe-4fda-a13f-ca38f8ee3c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'CreatedDate', 'StartDate', 'UpdatedDate',\n",
              "       'EstimatedClosureDate', 'ClosureDate', 'EndDate', 'ProjectId',\n",
              "       'ProjectStatusId', 'Status', 'BranchName', 'ProductType',\n",
              "       'PortfolioType', 'SectorType', 'SubSectorType', 'CustomerId',\n",
              "       'SalesManagerIdentity', 'PMIdentity', 'PreSaleManagerIdentity',\n",
              "       'CurrencyIdentity', 'ExchangeRateFixed', 'SaleSubtotal', 'SaleDiscount',\n",
              "       'SaleTotal', 'PurchaseSubtotal', 'ExpenseTotal', 'PurchaseTotal',\n",
              "       'Utility', 'BaseSaleSubtotal', 'BaseSaleDiscount', 'BaseSaleTotal',\n",
              "       'BasePurchaseSubtotal', 'BaseExpenseTotal', 'BasePurchaseTotal',\n",
              "       'BaseUtility', 'BaseInitialRealCost', 'BaseInvoicedTotal',\n",
              "       'NextSaleinvoiceAmount', 'BaseNextSaleinvoiceAmount'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminación de columnas NO RELEVANTES para la prediccion"
      ],
      "metadata": {
        "id": "v8h5EUj9QOot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= data.drop(['Unnamed: 0',  'StartDate', 'UpdatedDate',                     \n",
        "       'EstimatedClosureDate', 'ClosureDate', 'EndDate', 'ProjectId',\n",
        "        'Status', 'PurchaseSubtotal', 'ExpenseTotal', 'PurchaseTotal',\n",
        "       'Utility', 'BaseSaleSubtotal', 'BaseSaleDiscount', 'BaseSaleTotal',\n",
        "       'BasePurchaseSubtotal', 'BaseExpenseTotal', 'BasePurchaseTotal',\n",
        "       'BaseUtility', 'BaseInitialRealCost', 'BaseInvoicedTotal',\n",
        "       'NextSaleinvoiceAmount', 'BaseNextSaleinvoiceAmount','PMIdentity',\n",
        "        'PreSaleManagerIdentity',\n",
        "       'CurrencyIdentity', 'ExchangeRateFixed','CustomerId'\n",
        "       ], axis=1)"
      ],
      "metadata": {
        "id": "0lGmrS1dFxDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas = data.columns"
      ],
      "metadata": {
        "id": "CgHSTTKAFxHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columnas seleccionadas"
      ],
      "metadata": {
        "id": "rKOwcVLYQfIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas                                                        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmNlnkmMFxLY",
        "outputId": "29e7e6b9-6238-4718-a080-4a66d78b5d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CreatedDate', 'ProjectStatusId', 'BranchName', 'ProductType',\n",
              "       'PortfolioType', 'SectorType', 'SubSectorType', 'SalesManagerIdentity',\n",
              "       'SaleSubtotal', 'SaleDiscount', 'SaleTotal'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CREACION DE TABLA DE CATEGORIAS (data2)"
      ],
      "metadata": {
        "id": "fVemt2KBQmvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnasCat=pd.DataFrame(data.loc[:,[ 'BranchName','ProductType', 'PortfolioType', 'SectorType', 'SubSectorType' ]])"
      ],
      "metadata": {
        "id": "FuOIVxXfFxPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categoria(columna):\n",
        "  new_data = data[columna]\n",
        "  new_data = new_data.astype('category')\n",
        "  new_data = new_data.cat.codes  \n",
        "  return new_data"
      ],
      "metadata": {
        "id": "bTJYefB0MNKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "C2=pd.DataFrame(categoria('BranchName'))\n",
        "C3=pd.DataFrame(categoria( 'ProductType'))\n",
        "C4=pd.DataFrame(categoria('PortfolioType'))\n",
        "C5=pd.DataFrame(categoria('SectorType'))\n",
        "C6=pd.DataFrame(categoria('SubSectorType'))\n"
      ],
      "metadata": {
        "id": "3qqpPhVAUUFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C3=C3.rename(columns={0:'ProductType'})"
      ],
      "metadata": {
        "id": "UgRm3uJv83FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C2=C2.rename(columns={0:'BranchName'})"
      ],
      "metadata": {
        "id": "7Dy0ATzOUKIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C4=C4.rename(columns={0:'PortfolioType'})"
      ],
      "metadata": {
        "id": "WK27msxU9IXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C5=C5.rename(columns={0:'SectorType'})"
      ],
      "metadata": {
        "id": "xdoB8KrZ9Ijz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C6=C6.rename(columns={0:'SubSectorType'})"
      ],
      "metadata": {
        "id": "MykL122y9IwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.concat([C2,C3,C4,C5,C6], axis=1)"
      ],
      "metadata": {
        "id": "K6PIFXDWFxVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3AlrmkH2bTa6",
        "outputId": "ba1eda54-d215-44b2-9c43-ee2c32f55a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      BranchName  ProductType  PortfolioType  SectorType  SubSectorType\n",
              "0              0            3              7           5              7\n",
              "1              0            3              7           5              7\n",
              "2              0            3              3           6              9\n",
              "3              5            2              7           5              7\n",
              "4              3            2              7           5              7\n",
              "...          ...          ...            ...         ...            ...\n",
              "4195           0            4              5           6              9\n",
              "4196           0            5              5           6              9\n",
              "4197           0            5              0           6              9\n",
              "4198           0            5              2           5              7\n",
              "4199           3            5              2           5              7\n",
              "\n",
              "[4200 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52db52c0-cab9-488a-a390-198a997462e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BranchName</th>\n",
              "      <th>ProductType</th>\n",
              "      <th>PortfolioType</th>\n",
              "      <th>SectorType</th>\n",
              "      <th>SubSectorType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4195</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4196</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4198</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4199</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4200 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52db52c0-cab9-488a-a390-198a997462e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52db52c0-cab9-488a-a390-198a997462e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52db52c0-cab9-488a-a390-198a997462e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CREACION DE TABLA DE FECHA DE VENTA"
      ],
      "metadata": {
        "id": "YnCdvWbqROor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fecha=data['CreatedDate']"
      ],
      "metadata": {
        "id": "baiM5_69bbuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creacion=pd.DataFrame({'CreatedDate':pd.to_datetime(fecha)})"
      ],
      "metadata": {
        "id": "7cBYgMHibtiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creacion['año']=creacion['CreatedDate'].dt.year"
      ],
      "metadata": {
        "id": "ysDeXIgUed3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creacion['mes']=creacion['CreatedDate'].dt.month"
      ],
      "metadata": {
        "id": "1An6W--Hf1rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creacion['dia']=creacion['CreatedDate'].dt.day"
      ],
      "metadata": {
        "id": "PfPyw__GgCza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creacion=creacion.drop(['CreatedDate'],axis=1)"
      ],
      "metadata": {
        "id": "hhQIKeBugH0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminacion de Elementos modificados de la tabla original"
      ],
      "metadata": {
        "id": "qhd9adB2RaeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.drop(['BranchName','ProductType', 'PortfolioType', 'SectorType', 'SubSectorType','CreatedDate'],axis=1)"
      ],
      "metadata": {
        "id": "KTvvC134gj-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XnKTCbhhiqsM",
        "outputId": "cdd8c107-1c66-4f2b-a63a-ee0e11216449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ProjectStatusId  SalesManagerIdentity  SaleSubtotal  SaleDiscount  \\\n",
              "0                   1                   487     -0.146508     -0.025552   \n",
              "1                   1                   487     -0.134001     -0.025552   \n",
              "2                   1                   487     -0.093690     -0.025552   \n",
              "3                   2                   773     -0.140009     -0.025552   \n",
              "4                   2                   996     -0.018438     -0.025552   \n",
              "...               ...                   ...           ...           ...   \n",
              "4195                9                   251     -0.140780     -0.025552   \n",
              "4196                5                   248     -0.146132     -0.025552   \n",
              "4197                5                   248     -0.147079     -0.025552   \n",
              "4198                5                   248     -0.146433     -0.025552   \n",
              "4199                9                   248     -0.145874     -0.025552   \n",
              "\n",
              "      SaleTotal  \n",
              "0     -0.145327  \n",
              "1     -0.136870  \n",
              "2     -0.092412  \n",
              "3     -0.138816  \n",
              "4     -0.017023  \n",
              "...         ...  \n",
              "4195  -0.139589  \n",
              "4196  -0.144950  \n",
              "4197  -0.145899  \n",
              "4198  -0.145252  \n",
              "4199  -0.144692  \n",
              "\n",
              "[4200 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d7479a2-73ea-44ad-9cce-365ed96c5aa3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProjectStatusId</th>\n",
              "      <th>SalesManagerIdentity</th>\n",
              "      <th>SaleSubtotal</th>\n",
              "      <th>SaleDiscount</th>\n",
              "      <th>SaleTotal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>487</td>\n",
              "      <td>-0.146508</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.145327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>487</td>\n",
              "      <td>-0.134001</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.136870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>487</td>\n",
              "      <td>-0.093690</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.092412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>773</td>\n",
              "      <td>-0.140009</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.138816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>996</td>\n",
              "      <td>-0.018438</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.017023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4195</th>\n",
              "      <td>9</td>\n",
              "      <td>251</td>\n",
              "      <td>-0.140780</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.139589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4196</th>\n",
              "      <td>5</td>\n",
              "      <td>248</td>\n",
              "      <td>-0.146132</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.144950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>5</td>\n",
              "      <td>248</td>\n",
              "      <td>-0.147079</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.145899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4198</th>\n",
              "      <td>5</td>\n",
              "      <td>248</td>\n",
              "      <td>-0.146433</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.145252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4199</th>\n",
              "      <td>9</td>\n",
              "      <td>248</td>\n",
              "      <td>-0.145874</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.144692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4200 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d7479a2-73ea-44ad-9cce-365ed96c5aa3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d7479a2-73ea-44ad-9cce-365ed96c5aa3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d7479a2-73ea-44ad-9cce-365ed96c5aa3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCATENACION DE TABLAS EN data2"
      ],
      "metadata": {
        "id": "r8RXKMzXRtXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.concat([data2,data,creacion], axis=1)"
      ],
      "metadata": {
        "id": "CCgTwuwIhw4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "OEa9xH3ZiHj6",
        "outputId": "34dd54de-7b88-408b-9668-a59b7bf54975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      BranchName  ProductType  PortfolioType  SectorType  SubSectorType  \\\n",
              "0              0            3              7           5              7   \n",
              "1              0            3              7           5              7   \n",
              "2              0            3              3           6              9   \n",
              "3              5            2              7           5              7   \n",
              "4              3            2              7           5              7   \n",
              "...          ...          ...            ...         ...            ...   \n",
              "4195           0            4              5           6              9   \n",
              "4196           0            5              5           6              9   \n",
              "4197           0            5              0           6              9   \n",
              "4198           0            5              2           5              7   \n",
              "4199           3            5              2           5              7   \n",
              "\n",
              "      ProjectStatusId  SalesManagerIdentity  SaleSubtotal  SaleDiscount  \\\n",
              "0                   1                   487     -0.146508     -0.025552   \n",
              "1                   1                   487     -0.134001     -0.025552   \n",
              "2                   1                   487     -0.093690     -0.025552   \n",
              "3                   2                   773     -0.140009     -0.025552   \n",
              "4                   2                   996     -0.018438     -0.025552   \n",
              "...               ...                   ...           ...           ...   \n",
              "4195                9                   251     -0.140780     -0.025552   \n",
              "4196                5                   248     -0.146132     -0.025552   \n",
              "4197                5                   248     -0.147079     -0.025552   \n",
              "4198                5                   248     -0.146433     -0.025552   \n",
              "4199                9                   248     -0.145874     -0.025552   \n",
              "\n",
              "      SaleTotal   año  mes  dia  \n",
              "0     -0.145327  2022    1   14  \n",
              "1     -0.136870  2022    1   14  \n",
              "2     -0.092412  2022    1   14  \n",
              "3     -0.138816  2022    1   14  \n",
              "4     -0.017023  2022    1   13  \n",
              "...         ...   ...  ...  ...  \n",
              "4195  -0.139589  2017    9    8  \n",
              "4196  -0.144950  2017    9    1  \n",
              "4197  -0.145899  2017    9    1  \n",
              "4198  -0.145252  2017    9    1  \n",
              "4199  -0.144692  2017    8   30  \n",
              "\n",
              "[4200 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6ff7922-4f26-4f41-aa04-0be0b953925c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BranchName</th>\n",
              "      <th>ProductType</th>\n",
              "      <th>PortfolioType</th>\n",
              "      <th>SectorType</th>\n",
              "      <th>SubSectorType</th>\n",
              "      <th>ProjectStatusId</th>\n",
              "      <th>SalesManagerIdentity</th>\n",
              "      <th>SaleSubtotal</th>\n",
              "      <th>SaleDiscount</th>\n",
              "      <th>SaleTotal</th>\n",
              "      <th>año</th>\n",
              "      <th>mes</th>\n",
              "      <th>dia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>487</td>\n",
              "      <td>-0.146508</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.145327</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>487</td>\n",
              "      <td>-0.134001</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.136870</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>487</td>\n",
              "      <td>-0.093690</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.092412</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>773</td>\n",
              "      <td>-0.140009</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.138816</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>996</td>\n",
              "      <td>-0.018438</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.017023</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4195</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>251</td>\n",
              "      <td>-0.140780</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.139589</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4196</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>248</td>\n",
              "      <td>-0.146132</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.144950</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>248</td>\n",
              "      <td>-0.147079</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.145899</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4198</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>248</td>\n",
              "      <td>-0.146433</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.145252</td>\n",
              "      <td>2017</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4199</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>248</td>\n",
              "      <td>-0.145874</td>\n",
              "      <td>-0.025552</td>\n",
              "      <td>-0.144692</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4200 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6ff7922-4f26-4f41-aa04-0be0b953925c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6ff7922-4f26-4f41-aa04-0be0b953925c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6ff7922-4f26-4f41-aa04-0be0b953925c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2.to_csv('data1.csv', index=False)"
      ],
      "metadata": {
        "id": "inqHTB0vjK2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(object):\n",
        "    def __init__(self):\n",
        "        self.root_dir = os.path.join(os.getcwd(), os.pardir) #directory where data is located. In our case the data is in the project root directory\n",
        "        self.data_dir = os.path.join(self.root_dir, 'data', 'raw')\n",
        "        self.raw = None #stores raw data\n",
        "\n",
        "    def get(self, file_name):\n",
        "        data = pd.read_csv(os.path.join(self.data_dir, file_name))\n",
        "        self.raw = data\n",
        "        return data.info()\n",
        "        \n",
        "    \n",
        "    def plot(self, feature=None, target=None, color=None):\n",
        "        assert self.raw is not None, \"Use get(file_name) method to import data\"\n",
        "        fig = px.scatter(x=self.raw[feature], y=self.raw[target], color=color)\n",
        "        fig.show()\n",
        "        \n",
        "    #Unsupervised learning algortihms\n",
        "    \n",
        "    def pca(self, features, target):\n",
        "        #feature engineering: reduce dimensionality    \n",
        "        pca = decomposition.PCA(n_components='mle')\n",
        "        principal_components = pca.fit_transform(features)\n",
        "        principal_components = pd.DataFrame(principal_components)\n",
        "        columns = [f'PC{index}' for index in principal_components]\n",
        "        principal_components.columns = columns\n",
        "        return pd.concat([principal_components, target], axis=1)\n",
        "    \n",
        "    def kmeans(self, features, num_clusters):\n",
        "        #Classify using k-means\n",
        "        k_means = KMeans(num_clusters).fit(features)\n",
        "        identified_clusters = k_means.predict(features)\n",
        "        return pd.concat([pd.DataFrame(features), pd.DataFrame(identified_clusters)], axis=1)\n",
        "\n",
        "    #Supervised learning algorithm\n",
        "    def make_ds(self, features, split=0.001):\n",
        "        data = self.kmeans(features, num_clusters=2)\n",
        "        \n",
        "        train_labels = data.iloc[:int(len(data)*split),-1]\n",
        "        train_data = data.iloc[:int(len(data)*split),:-2]\n",
        "        \n",
        "        test_labels = data.iloc[int(len(data)*split):,-1]\n",
        "        test_data = data.iloc[int(len(data)*split):,:-2]\n",
        "        \n",
        "        return train_data, train_labels, test_data, test_labels\n",
        "    \n",
        "    def logistic_regression(self, features):\n",
        "        train_data, train_labels, test_data, test_labels = self.make_ds(features)\n",
        "        clf = LogisticRegression(random_state=0).fit(train_data, train_labels)\n",
        "        prediction = clf.predict(test_data)\n",
        "        return confusion_matrix(test_labels.to_numpy(), prediction)\n",
        "    \n",
        "    def svm(self, features):\n",
        "        train_data, train_labels, test_data, test_labels = self.make_ds(features)\n",
        "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "        clf.fit(train_data, train_labels)\n",
        "        prediction = clf.predict(test_data)\n",
        "        return confusion_matrix(test_labels.to_numpy(), prediction)\n",
        "    \n",
        "    def knn(self, features, n_neighbors=3):\n",
        "        train_data, train_labels, test_data, test_labels = self.make_ds(features)\n",
        "        neigh = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "        neigh.fit(train_data, train_labels)\n",
        "        prediction = neigh.predict(test_data)\n",
        "        return confusion_matrix(test_labels.to_numpy(), prediction)"
      ],
      "metadata": {
        "id": "tM6NBSgijh-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data3=Data()"
      ],
      "metadata": {
        "id": "X_601q_Wj2Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data3.get('/content/data1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_-MhHZHj2cY",
        "outputId": "ec5eb66a-795e-44fe-94e8-76368ea8c7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4200 entries, 0 to 4199\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   BranchName            4200 non-null   int64  \n",
            " 1   ProductType           4200 non-null   int64  \n",
            " 2   PortfolioType         4200 non-null   int64  \n",
            " 3   SectorType            4200 non-null   int64  \n",
            " 4   SubSectorType         4200 non-null   int64  \n",
            " 5   ProjectStatusId       4200 non-null   int64  \n",
            " 6   SalesManagerIdentity  4200 non-null   int64  \n",
            " 7   SaleSubtotal          4200 non-null   float64\n",
            " 8   SaleDiscount          4200 non-null   float64\n",
            " 9   SaleTotal             4200 non-null   float64\n",
            " 10  año                   4200 non-null   int64  \n",
            " 11  mes                   4200 non-null   int64  \n",
            " 12  dia                   4200 non-null   int64  \n",
            "dtypes: float64(3), int64(10)\n",
            "memory usage: 426.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizacion  de datos"
      ],
      "metadata": {
        "id": "Vt-110aWSJdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_norm(df_input):\n",
        "    return df_input.apply(lambda x: (x-x.mean())/ x.std(), axis=0)"
      ],
      "metadata": {
        "id": "7VZk6xCgj2sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "45RdRRWqFfnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data4=mean_norm(data3.raw)"
      ],
      "metadata": {
        "id": "YAcD88M0ybK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ESTABLECIMIENTO DEL CONJUNTO DE ENTRENAMIENTO Y OBJETIVO A PREDECIR"
      ],
      "metadata": {
        "id": "weL1ay1kSZzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=data4"
      ],
      "metadata": {
        "id": "EUmwXorQ0msP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data = data3.raw[['ProductType']]"
      ],
      "metadata": {
        "id": "nyBIGCl_sgb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data = target_data[1:].reset_index().drop('index', axis=1)\n",
        "train_data = train_data[:-1]"
      ],
      "metadata": {
        "id": "3ADM_OGWsg5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21A8LWYVsglG",
        "outputId": "19015070-b7a9-4811-8be4-e9042ddaf753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4199, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWt8VBiNsg_c",
        "outputId": "5bc2df1e-9662-415e-f8f9-d0920bec2b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4199, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.array(train_data)"
      ],
      "metadata": {
        "id": "CaFeZnzPshEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data= np.array(target_data)"
      ],
      "metadata": {
        "id": "HvCDolVBt5Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conjunto de Validacion"
      ],
      "metadata": {
        "id": "gEpiIrHPTAJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=train_data"
      ],
      "metadata": {
        "id": "sWXWtV9leq89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=target_data"
      ],
      "metadata": {
        "id": "G12esctEgJBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "# Use KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1111)\n",
        "\n",
        "# Create splits\n",
        "splits = kf.split(X)\n",
        "\n",
        "for train_index, val_index in splits:\n",
        "    # Setup the training and validation data\n",
        "    X_train, y_train = X[train_index], y[train_index]\n",
        "    X_val, y_val = X[val_index], y[val_index]\n"
      ],
      "metadata": {
        "id": "-_rqv3x5uAXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELO"
      ],
      "metadata": {
        "id": "-QA_fWF5uHvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.InputLayer(input_shape=( 13))) #Input layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Hidden layers\n",
        "#model.add(tf.keras.layers.Dense(10, activation=None)) #Linear\n",
        " #Non-linear\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "#model.add(tf.keras.layers.BatchNormalization())\n",
        "#model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "#model.add(tf.keras.layers.BatchNormalization())\n",
        "#model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "#model.add(tf.keras.layers.BatchNormalization())\n",
        "#model.add(tf.keras.layers.Activation('relu'))\n",
        "#model.add(tf.keras.layers.Dense(1024, activation='relu',kernel_regularizer=tf.keras.regularizers.L2()))\n",
        "model.add(tf.keras.layers.Dense(6, activation='softmax',kernel_regularizer=tf.keras.regularizers.L2(.3))) #Output layer\n",
        "#model.add(tf.keras.layers.Dense(1, activation=None)) #Output layer"
      ],
      "metadata": {
        "id": "84Ot615DuJXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),#'mse',#\n",
        "             metrics=['accuracy'],#'mae'],#\n",
        "             optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))#optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)"
      ],
      "metadata": {
        "id": "p3YkdwPquWrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOKB26jmufaJ",
        "outputId": "4a257106-f158-48fe-d1f4-e802b6fafc79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 13)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               7168      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,060,870\n",
            "Trainable params: 1,060,870\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_data #NO DEBE DE ESTAR NORMALIZADO POR  LA FUNCION DE ERROR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZjiz_vWumF9",
        "outputId": "65620586-5bd1-4b0e-dfcf-8fb4420a328f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [3],\n",
              "       [2],\n",
              "       ...,\n",
              "       [5],\n",
              "       [5],\n",
              "       [5]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1fp2HdHupx-",
        "outputId": "7f33828b-a46c-44f8-9321-b77567ad6cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.60076258, -0.00383104,  1.38051667, ...,  2.25539416,\n",
              "        -1.76665113, -0.21541787],\n",
              "       [-0.60076258, -0.00383104,  1.38051667, ...,  2.25539416,\n",
              "        -1.76665113, -0.21541787],\n",
              "       [-0.60076258, -0.00383104, -0.57551606, ...,  2.25539416,\n",
              "        -1.76665113, -0.21541787],\n",
              "       ...,\n",
              "       [-0.60076258,  1.68989307,  0.40250031, ..., -2.06528431,\n",
              "         0.61678505, -1.68859116],\n",
              "       [-0.60076258,  1.68989307, -2.0425406 , ..., -2.06528431,\n",
              "         0.61678505, -1.68859116],\n",
              "       [-0.60076258,  1.68989307, -1.06452424, ..., -2.06528431,\n",
              "         0.61678505, -1.68859116]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data, target_data , batch_size=512, epochs=1500,validation_data=(X_val, y_val))#,validation_data=(val_data,val_target_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HSGVAFnuxPK",
        "outputId": "a3107af9-c79b-4f0a-b55f-a86b41a1e1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "9/9 [==============================] - 4s 223ms/step - loss: 5.2319 - accuracy: 0.3953 - val_loss: 5.0728 - val_accuracy: 0.4768\n",
            "Epoch 2/1500\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 4.9630 - accuracy: 0.4863 - val_loss: 4.8360 - val_accuracy: 0.4768\n",
            "Epoch 3/1500\n",
            "9/9 [==============================] - 1s 141ms/step - loss: 4.7589 - accuracy: 0.4863 - val_loss: 4.6638 - val_accuracy: 0.4768\n",
            "Epoch 4/1500\n",
            "9/9 [==============================] - 1s 167ms/step - loss: 4.5929 - accuracy: 0.4863 - val_loss: 4.5072 - val_accuracy: 0.4768\n",
            "Epoch 5/1500\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 4.4561 - accuracy: 0.4863 - val_loss: 4.3787 - val_accuracy: 0.4756\n",
            "Epoch 6/1500\n",
            "9/9 [==============================] - 1s 148ms/step - loss: 4.3324 - accuracy: 0.5161 - val_loss: 4.2662 - val_accuracy: 0.5125\n",
            "Epoch 7/1500\n",
            "9/9 [==============================] - 1s 135ms/step - loss: 4.2236 - accuracy: 0.5275 - val_loss: 4.1603 - val_accuracy: 0.5197\n",
            "Epoch 8/1500\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 4.1238 - accuracy: 0.5287 - val_loss: 4.0675 - val_accuracy: 0.5209\n",
            "Epoch 9/1500\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 4.0325 - accuracy: 0.5392 - val_loss: 3.9840 - val_accuracy: 0.5304\n",
            "Epoch 10/1500\n",
            "9/9 [==============================] - 1s 143ms/step - loss: 3.9485 - accuracy: 0.5404 - val_loss: 3.8966 - val_accuracy: 0.5340\n",
            "Epoch 11/1500\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 3.8681 - accuracy: 0.5482 - val_loss: 3.8198 - val_accuracy: 0.5316\n",
            "Epoch 12/1500\n",
            "9/9 [==============================] - 1s 139ms/step - loss: 3.7889 - accuracy: 0.5487 - val_loss: 3.7464 - val_accuracy: 0.5340\n",
            "Epoch 13/1500\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 3.7164 - accuracy: 0.5451 - val_loss: 3.6794 - val_accuracy: 0.5387\n",
            "Epoch 14/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 3.6422 - accuracy: 0.5497 - val_loss: 3.6041 - val_accuracy: 0.5352\n",
            "Epoch 15/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 3.5735 - accuracy: 0.5518 - val_loss: 3.5370 - val_accuracy: 0.5411\n",
            "Epoch 16/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 3.5054 - accuracy: 0.5487 - val_loss: 3.4731 - val_accuracy: 0.5471\n",
            "Epoch 17/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 3.4401 - accuracy: 0.5516 - val_loss: 3.4024 - val_accuracy: 0.5352\n",
            "Epoch 18/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 3.3795 - accuracy: 0.5523 - val_loss: 3.3527 - val_accuracy: 0.5375\n",
            "Epoch 19/1500\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 3.3196 - accuracy: 0.5578 - val_loss: 3.2811 - val_accuracy: 0.5495\n",
            "Epoch 20/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 3.2570 - accuracy: 0.5549 - val_loss: 3.2367 - val_accuracy: 0.5435\n",
            "Epoch 21/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 3.2036 - accuracy: 0.5487 - val_loss: 3.1693 - val_accuracy: 0.5399\n",
            "Epoch 22/1500\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 3.1431 - accuracy: 0.5585 - val_loss: 3.1111 - val_accuracy: 0.5423\n",
            "Epoch 23/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 3.0843 - accuracy: 0.5592 - val_loss: 3.0554 - val_accuracy: 0.5507\n",
            "Epoch 24/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.0283 - accuracy: 0.5585 - val_loss: 3.0036 - val_accuracy: 0.5483\n",
            "Epoch 25/1500\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 2.9750 - accuracy: 0.5589 - val_loss: 2.9465 - val_accuracy: 0.5530\n",
            "Epoch 26/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 2.9230 - accuracy: 0.5654 - val_loss: 2.9060 - val_accuracy: 0.5542\n",
            "Epoch 27/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.8719 - accuracy: 0.5649 - val_loss: 2.8487 - val_accuracy: 0.5650\n",
            "Epoch 28/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.8239 - accuracy: 0.5680 - val_loss: 2.8083 - val_accuracy: 0.5530\n",
            "Epoch 29/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 2.7755 - accuracy: 0.5637 - val_loss: 2.7538 - val_accuracy: 0.5602\n",
            "Epoch 30/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 2.7301 - accuracy: 0.5666 - val_loss: 2.7127 - val_accuracy: 0.5602\n",
            "Epoch 31/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.6859 - accuracy: 0.5654 - val_loss: 2.6663 - val_accuracy: 0.5650\n",
            "Epoch 32/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.6380 - accuracy: 0.5725 - val_loss: 2.6216 - val_accuracy: 0.5614\n",
            "Epoch 33/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 2.5981 - accuracy: 0.5673 - val_loss: 2.5894 - val_accuracy: 0.5673\n",
            "Epoch 34/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 2.5555 - accuracy: 0.5706 - val_loss: 2.5388 - val_accuracy: 0.5662\n",
            "Epoch 35/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 2.5117 - accuracy: 0.5730 - val_loss: 2.4896 - val_accuracy: 0.5769\n",
            "Epoch 36/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 2.4719 - accuracy: 0.5735 - val_loss: 2.4595 - val_accuracy: 0.5626\n",
            "Epoch 37/1500\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 2.4318 - accuracy: 0.5723 - val_loss: 2.4120 - val_accuracy: 0.5828\n",
            "Epoch 38/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 2.3931 - accuracy: 0.5761 - val_loss: 2.3813 - val_accuracy: 0.5709\n",
            "Epoch 39/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.3537 - accuracy: 0.5761 - val_loss: 2.3373 - val_accuracy: 0.5793\n",
            "Epoch 40/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.3159 - accuracy: 0.5756 - val_loss: 2.3025 - val_accuracy: 0.5805\n",
            "Epoch 41/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 2.2802 - accuracy: 0.5835 - val_loss: 2.2669 - val_accuracy: 0.5793\n",
            "Epoch 42/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.2450 - accuracy: 0.5799 - val_loss: 2.2342 - val_accuracy: 0.5888\n",
            "Epoch 43/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.2144 - accuracy: 0.5811 - val_loss: 2.2017 - val_accuracy: 0.5793\n",
            "Epoch 44/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 2.1795 - accuracy: 0.5782 - val_loss: 2.1763 - val_accuracy: 0.5816\n",
            "Epoch 45/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.1527 - accuracy: 0.5832 - val_loss: 2.1359 - val_accuracy: 0.5888\n",
            "Epoch 46/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 2.1141 - accuracy: 0.5866 - val_loss: 2.1061 - val_accuracy: 0.5888\n",
            "Epoch 47/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 2.0846 - accuracy: 0.5849 - val_loss: 2.0725 - val_accuracy: 0.5936\n",
            "Epoch 48/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 2.0592 - accuracy: 0.5844 - val_loss: 2.0398 - val_accuracy: 0.6007\n",
            "Epoch 49/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 2.0346 - accuracy: 0.5839 - val_loss: 2.0257 - val_accuracy: 0.5852\n",
            "Epoch 50/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 2.0003 - accuracy: 0.5868 - val_loss: 1.9944 - val_accuracy: 0.5912\n",
            "Epoch 51/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.9673 - accuracy: 0.5894 - val_loss: 1.9587 - val_accuracy: 0.5864\n",
            "Epoch 52/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.9393 - accuracy: 0.5913 - val_loss: 1.9289 - val_accuracy: 0.5995\n",
            "Epoch 53/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.9138 - accuracy: 0.5925 - val_loss: 1.9220 - val_accuracy: 0.6019\n",
            "Epoch 54/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.8931 - accuracy: 0.5925 - val_loss: 1.8770 - val_accuracy: 0.5912\n",
            "Epoch 55/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.8681 - accuracy: 0.5970 - val_loss: 1.8667 - val_accuracy: 0.5852\n",
            "Epoch 56/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.8459 - accuracy: 0.5897 - val_loss: 1.8402 - val_accuracy: 0.5876\n",
            "Epoch 57/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.8198 - accuracy: 0.5935 - val_loss: 1.8056 - val_accuracy: 0.5983\n",
            "Epoch 58/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.7890 - accuracy: 0.5956 - val_loss: 1.7823 - val_accuracy: 0.6043\n",
            "Epoch 59/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.7659 - accuracy: 0.5968 - val_loss: 1.7591 - val_accuracy: 0.5912\n",
            "Epoch 60/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.7450 - accuracy: 0.5982 - val_loss: 1.7367 - val_accuracy: 0.6067\n",
            "Epoch 61/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.7230 - accuracy: 0.5994 - val_loss: 1.7187 - val_accuracy: 0.6031\n",
            "Epoch 62/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.7017 - accuracy: 0.6056 - val_loss: 1.7033 - val_accuracy: 0.5852\n",
            "Epoch 63/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.6817 - accuracy: 0.5973 - val_loss: 1.6703 - val_accuracy: 0.6103\n",
            "Epoch 64/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.6584 - accuracy: 0.5997 - val_loss: 1.6533 - val_accuracy: 0.6114\n",
            "Epoch 65/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.6406 - accuracy: 0.6001 - val_loss: 1.6349 - val_accuracy: 0.6234\n",
            "Epoch 66/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.6228 - accuracy: 0.6061 - val_loss: 1.6186 - val_accuracy: 0.6114\n",
            "Epoch 67/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.6099 - accuracy: 0.5992 - val_loss: 1.5928 - val_accuracy: 0.6174\n",
            "Epoch 68/1500\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 1.5912 - accuracy: 0.6006 - val_loss: 1.5932 - val_accuracy: 0.6019\n",
            "Epoch 69/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.5702 - accuracy: 0.6049 - val_loss: 1.5664 - val_accuracy: 0.5983\n",
            "Epoch 70/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.5496 - accuracy: 0.6018 - val_loss: 1.5451 - val_accuracy: 0.6150\n",
            "Epoch 71/1500\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 1.5342 - accuracy: 0.6040 - val_loss: 1.5268 - val_accuracy: 0.6246\n",
            "Epoch 72/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.5165 - accuracy: 0.6082 - val_loss: 1.5081 - val_accuracy: 0.6257\n",
            "Epoch 73/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.5009 - accuracy: 0.6085 - val_loss: 1.4938 - val_accuracy: 0.6317\n",
            "Epoch 74/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.4869 - accuracy: 0.6073 - val_loss: 1.4791 - val_accuracy: 0.6269\n",
            "Epoch 75/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.4691 - accuracy: 0.6109 - val_loss: 1.4638 - val_accuracy: 0.6222\n",
            "Epoch 76/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.4510 - accuracy: 0.6149 - val_loss: 1.4513 - val_accuracy: 0.6317\n",
            "Epoch 77/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.4380 - accuracy: 0.6144 - val_loss: 1.4313 - val_accuracy: 0.6246\n",
            "Epoch 78/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.4265 - accuracy: 0.6070 - val_loss: 1.4278 - val_accuracy: 0.6198\n",
            "Epoch 79/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.4053 - accuracy: 0.6185 - val_loss: 1.4003 - val_accuracy: 0.6293\n",
            "Epoch 80/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.3933 - accuracy: 0.6204 - val_loss: 1.3889 - val_accuracy: 0.6150\n",
            "Epoch 81/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.3778 - accuracy: 0.6199 - val_loss: 1.3852 - val_accuracy: 0.6222\n",
            "Epoch 82/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.3711 - accuracy: 0.6140 - val_loss: 1.3744 - val_accuracy: 0.6091\n",
            "Epoch 83/1500\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 1.3670 - accuracy: 0.6123 - val_loss: 1.3586 - val_accuracy: 0.6257\n",
            "Epoch 84/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.3654 - accuracy: 0.6163 - val_loss: 1.3528 - val_accuracy: 0.6210\n",
            "Epoch 85/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.3429 - accuracy: 0.6137 - val_loss: 1.3253 - val_accuracy: 0.6389\n",
            "Epoch 86/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.3206 - accuracy: 0.6211 - val_loss: 1.3217 - val_accuracy: 0.6281\n",
            "Epoch 87/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.3077 - accuracy: 0.6242 - val_loss: 1.3041 - val_accuracy: 0.6365\n",
            "Epoch 88/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.2942 - accuracy: 0.6292 - val_loss: 1.2904 - val_accuracy: 0.6341\n",
            "Epoch 89/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.2819 - accuracy: 0.6251 - val_loss: 1.2849 - val_accuracy: 0.6353\n",
            "Epoch 90/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.2713 - accuracy: 0.6247 - val_loss: 1.2749 - val_accuracy: 0.6257\n",
            "Epoch 91/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.2597 - accuracy: 0.6278 - val_loss: 1.2602 - val_accuracy: 0.6329\n",
            "Epoch 92/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.2553 - accuracy: 0.6249 - val_loss: 1.2486 - val_accuracy: 0.6389\n",
            "Epoch 93/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.2454 - accuracy: 0.6225 - val_loss: 1.2486 - val_accuracy: 0.6281\n",
            "Epoch 94/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.2344 - accuracy: 0.6280 - val_loss: 1.2274 - val_accuracy: 0.6412\n",
            "Epoch 95/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.2220 - accuracy: 0.6292 - val_loss: 1.2266 - val_accuracy: 0.6353\n",
            "Epoch 96/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.2172 - accuracy: 0.6292 - val_loss: 1.2067 - val_accuracy: 0.6436\n",
            "Epoch 97/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.2012 - accuracy: 0.6375 - val_loss: 1.1999 - val_accuracy: 0.6448\n",
            "Epoch 98/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.1953 - accuracy: 0.6311 - val_loss: 1.1991 - val_accuracy: 0.6257\n",
            "Epoch 99/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.1876 - accuracy: 0.6306 - val_loss: 1.1860 - val_accuracy: 0.6341\n",
            "Epoch 100/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.1752 - accuracy: 0.6361 - val_loss: 1.1726 - val_accuracy: 0.6532\n",
            "Epoch 101/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.1678 - accuracy: 0.6432 - val_loss: 1.1648 - val_accuracy: 0.6400\n",
            "Epoch 102/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.1597 - accuracy: 0.6385 - val_loss: 1.1546 - val_accuracy: 0.6400\n",
            "Epoch 103/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.1484 - accuracy: 0.6361 - val_loss: 1.1436 - val_accuracy: 0.6579\n",
            "Epoch 104/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.1471 - accuracy: 0.6421 - val_loss: 1.1616 - val_accuracy: 0.6424\n",
            "Epoch 105/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.1480 - accuracy: 0.6352 - val_loss: 1.1502 - val_accuracy: 0.6281\n",
            "Epoch 106/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.1442 - accuracy: 0.6375 - val_loss: 1.1299 - val_accuracy: 0.6579\n",
            "Epoch 107/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.1272 - accuracy: 0.6428 - val_loss: 1.1296 - val_accuracy: 0.6377\n",
            "Epoch 108/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.1221 - accuracy: 0.6399 - val_loss: 1.1081 - val_accuracy: 0.6508\n",
            "Epoch 109/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.1171 - accuracy: 0.6418 - val_loss: 1.1188 - val_accuracy: 0.6448\n",
            "Epoch 110/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.1090 - accuracy: 0.6428 - val_loss: 1.1077 - val_accuracy: 0.6460\n",
            "Epoch 111/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 1.0966 - accuracy: 0.6468 - val_loss: 1.0916 - val_accuracy: 0.6532\n",
            "Epoch 112/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.0861 - accuracy: 0.6482 - val_loss: 1.0851 - val_accuracy: 0.6484\n",
            "Epoch 113/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.0776 - accuracy: 0.6511 - val_loss: 1.0792 - val_accuracy: 0.6651\n",
            "Epoch 114/1500\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 1.0726 - accuracy: 0.6513 - val_loss: 1.0734 - val_accuracy: 0.6544\n",
            "Epoch 115/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.0699 - accuracy: 0.6521 - val_loss: 1.0755 - val_accuracy: 0.6484\n",
            "Epoch 116/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.0643 - accuracy: 0.6528 - val_loss: 1.0671 - val_accuracy: 0.6639\n",
            "Epoch 117/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.0608 - accuracy: 0.6563 - val_loss: 1.0523 - val_accuracy: 0.6627\n",
            "Epoch 118/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.0495 - accuracy: 0.6521 - val_loss: 1.0600 - val_accuracy: 0.6520\n",
            "Epoch 119/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.0447 - accuracy: 0.6563 - val_loss: 1.0400 - val_accuracy: 0.6710\n",
            "Epoch 120/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.0381 - accuracy: 0.6561 - val_loss: 1.0378 - val_accuracy: 0.6627\n",
            "Epoch 121/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.0312 - accuracy: 0.6578 - val_loss: 1.0338 - val_accuracy: 0.6627\n",
            "Epoch 122/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.0293 - accuracy: 0.6547 - val_loss: 1.0280 - val_accuracy: 0.6710\n",
            "Epoch 123/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.0267 - accuracy: 0.6549 - val_loss: 1.0236 - val_accuracy: 0.6639\n",
            "Epoch 124/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.0162 - accuracy: 0.6561 - val_loss: 1.0151 - val_accuracy: 0.6651\n",
            "Epoch 125/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.0144 - accuracy: 0.6599 - val_loss: 1.0028 - val_accuracy: 0.6746\n",
            "Epoch 126/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 1.0073 - accuracy: 0.6587 - val_loss: 1.0158 - val_accuracy: 0.6663\n",
            "Epoch 127/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 1.0016 - accuracy: 0.6621 - val_loss: 1.0038 - val_accuracy: 0.6675\n",
            "Epoch 128/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.9969 - accuracy: 0.6623 - val_loss: 0.9961 - val_accuracy: 0.6698\n",
            "Epoch 129/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 0.9984 - accuracy: 0.6716 - val_loss: 0.9859 - val_accuracy: 0.6734\n",
            "Epoch 130/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.9871 - accuracy: 0.6647 - val_loss: 0.9894 - val_accuracy: 0.6722\n",
            "Epoch 131/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.9817 - accuracy: 0.6656 - val_loss: 0.9833 - val_accuracy: 0.6579\n",
            "Epoch 132/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.9736 - accuracy: 0.6721 - val_loss: 0.9783 - val_accuracy: 0.6734\n",
            "Epoch 133/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.9692 - accuracy: 0.6773 - val_loss: 0.9821 - val_accuracy: 0.6639\n",
            "Epoch 134/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.9776 - accuracy: 0.6659 - val_loss: 0.9900 - val_accuracy: 0.6698\n",
            "Epoch 135/1500\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.9731 - accuracy: 0.6652 - val_loss: 0.9650 - val_accuracy: 0.6675\n",
            "Epoch 136/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.9632 - accuracy: 0.6690 - val_loss: 0.9584 - val_accuracy: 0.6758\n",
            "Epoch 137/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.9589 - accuracy: 0.6735 - val_loss: 0.9489 - val_accuracy: 0.6841\n",
            "Epoch 138/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.9518 - accuracy: 0.6749 - val_loss: 0.9570 - val_accuracy: 0.6913\n",
            "Epoch 139/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.9536 - accuracy: 0.6773 - val_loss: 0.9477 - val_accuracy: 0.6710\n",
            "Epoch 140/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.9541 - accuracy: 0.6694 - val_loss: 0.9423 - val_accuracy: 0.6913\n",
            "Epoch 141/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.9425 - accuracy: 0.6756 - val_loss: 0.9356 - val_accuracy: 0.6758\n",
            "Epoch 142/1500\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.9376 - accuracy: 0.6816 - val_loss: 0.9461 - val_accuracy: 0.6806\n",
            "Epoch 143/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9333 - accuracy: 0.6773 - val_loss: 0.9434 - val_accuracy: 0.6841\n",
            "Epoch 144/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.9369 - accuracy: 0.6747 - val_loss: 0.9274 - val_accuracy: 0.6806\n",
            "Epoch 145/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.9188 - accuracy: 0.6856 - val_loss: 0.9180 - val_accuracy: 0.6830\n",
            "Epoch 146/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.9244 - accuracy: 0.6785 - val_loss: 0.9301 - val_accuracy: 0.6746\n",
            "Epoch 147/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.9202 - accuracy: 0.6792 - val_loss: 0.9199 - val_accuracy: 0.6794\n",
            "Epoch 148/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.9244 - accuracy: 0.6790 - val_loss: 0.9157 - val_accuracy: 0.6901\n",
            "Epoch 149/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.9152 - accuracy: 0.6840 - val_loss: 0.9149 - val_accuracy: 0.6877\n",
            "Epoch 150/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.9057 - accuracy: 0.6861 - val_loss: 0.9006 - val_accuracy: 0.6973\n",
            "Epoch 151/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.9019 - accuracy: 0.6899 - val_loss: 0.9057 - val_accuracy: 0.6853\n",
            "Epoch 152/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.9064 - accuracy: 0.6814 - val_loss: 0.9060 - val_accuracy: 0.6973\n",
            "Epoch 153/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 0.9013 - accuracy: 0.6928 - val_loss: 0.8898 - val_accuracy: 0.6913\n",
            "Epoch 154/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.8932 - accuracy: 0.6885 - val_loss: 0.8924 - val_accuracy: 0.6901\n",
            "Epoch 155/1500\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.8857 - accuracy: 0.6947 - val_loss: 0.8871 - val_accuracy: 0.6877\n",
            "Epoch 156/1500\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.8818 - accuracy: 0.6959 - val_loss: 0.8857 - val_accuracy: 0.6925\n",
            "Epoch 157/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.8842 - accuracy: 0.6921 - val_loss: 0.8848 - val_accuracy: 0.6901\n",
            "Epoch 158/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.8792 - accuracy: 0.6961 - val_loss: 0.8735 - val_accuracy: 0.7056\n",
            "Epoch 159/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.8725 - accuracy: 0.6992 - val_loss: 0.8660 - val_accuracy: 0.7068\n",
            "Epoch 160/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.8673 - accuracy: 0.7018 - val_loss: 0.8615 - val_accuracy: 0.7092\n",
            "Epoch 161/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.8676 - accuracy: 0.7021 - val_loss: 0.8727 - val_accuracy: 0.6961\n",
            "Epoch 162/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.8669 - accuracy: 0.6980 - val_loss: 0.8694 - val_accuracy: 0.6877\n",
            "Epoch 163/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 0.8678 - accuracy: 0.6980 - val_loss: 0.8645 - val_accuracy: 0.6961\n",
            "Epoch 164/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.8572 - accuracy: 0.7033 - val_loss: 0.8557 - val_accuracy: 0.7092\n",
            "Epoch 165/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.8613 - accuracy: 0.7025 - val_loss: 0.8627 - val_accuracy: 0.6996\n",
            "Epoch 166/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.8609 - accuracy: 0.6980 - val_loss: 0.8665 - val_accuracy: 0.7008\n",
            "Epoch 167/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.8663 - accuracy: 0.6992 - val_loss: 0.8899 - val_accuracy: 0.6758\n",
            "Epoch 168/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.8663 - accuracy: 0.6894 - val_loss: 0.9060 - val_accuracy: 0.6865\n",
            "Epoch 169/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.8652 - accuracy: 0.6937 - val_loss: 0.8393 - val_accuracy: 0.7199\n",
            "Epoch 170/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.8450 - accuracy: 0.7047 - val_loss: 0.8470 - val_accuracy: 0.6985\n",
            "Epoch 171/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.8371 - accuracy: 0.7078 - val_loss: 0.8394 - val_accuracy: 0.7092\n",
            "Epoch 172/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.8324 - accuracy: 0.7121 - val_loss: 0.8347 - val_accuracy: 0.7104\n",
            "Epoch 173/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.8329 - accuracy: 0.7073 - val_loss: 0.8335 - val_accuracy: 0.6996\n",
            "Epoch 174/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.8261 - accuracy: 0.7118 - val_loss: 0.8277 - val_accuracy: 0.7271\n",
            "Epoch 175/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.8233 - accuracy: 0.7109 - val_loss: 0.8439 - val_accuracy: 0.6985\n",
            "Epoch 176/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.8253 - accuracy: 0.7126 - val_loss: 0.8145 - val_accuracy: 0.7211\n",
            "Epoch 177/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.8176 - accuracy: 0.7206 - val_loss: 0.8319 - val_accuracy: 0.7139\n",
            "Epoch 178/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.8247 - accuracy: 0.7145 - val_loss: 0.8219 - val_accuracy: 0.7151\n",
            "Epoch 179/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.8241 - accuracy: 0.7068 - val_loss: 0.8108 - val_accuracy: 0.7306\n",
            "Epoch 180/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.8149 - accuracy: 0.7123 - val_loss: 0.8324 - val_accuracy: 0.7032\n",
            "Epoch 181/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.8166 - accuracy: 0.7130 - val_loss: 0.8105 - val_accuracy: 0.7342\n",
            "Epoch 182/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.8178 - accuracy: 0.7180 - val_loss: 0.8382 - val_accuracy: 0.6901\n",
            "Epoch 183/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.8157 - accuracy: 0.7123 - val_loss: 0.8148 - val_accuracy: 0.7223\n",
            "Epoch 184/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.8073 - accuracy: 0.7235 - val_loss: 0.8115 - val_accuracy: 0.7080\n",
            "Epoch 185/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.8056 - accuracy: 0.7173 - val_loss: 0.7921 - val_accuracy: 0.7294\n",
            "Epoch 186/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.8037 - accuracy: 0.7223 - val_loss: 0.8097 - val_accuracy: 0.7259\n",
            "Epoch 187/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.8004 - accuracy: 0.7216 - val_loss: 0.7928 - val_accuracy: 0.7473\n",
            "Epoch 188/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7970 - accuracy: 0.7295 - val_loss: 0.7899 - val_accuracy: 0.7223\n",
            "Epoch 189/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.7900 - accuracy: 0.7290 - val_loss: 0.8056 - val_accuracy: 0.7211\n",
            "Epoch 190/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7883 - accuracy: 0.7311 - val_loss: 0.8103 - val_accuracy: 0.7151\n",
            "Epoch 191/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7937 - accuracy: 0.7280 - val_loss: 0.7900 - val_accuracy: 0.7271\n",
            "Epoch 192/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.7849 - accuracy: 0.7273 - val_loss: 0.7978 - val_accuracy: 0.7139\n",
            "Epoch 193/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7859 - accuracy: 0.7307 - val_loss: 0.7777 - val_accuracy: 0.7366\n",
            "Epoch 194/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7775 - accuracy: 0.7333 - val_loss: 0.7834 - val_accuracy: 0.7306\n",
            "Epoch 195/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7765 - accuracy: 0.7311 - val_loss: 0.7793 - val_accuracy: 0.7402\n",
            "Epoch 196/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7746 - accuracy: 0.7316 - val_loss: 0.7726 - val_accuracy: 0.7247\n",
            "Epoch 197/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7700 - accuracy: 0.7304 - val_loss: 0.7721 - val_accuracy: 0.7414\n",
            "Epoch 198/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 0.7685 - accuracy: 0.7354 - val_loss: 0.7696 - val_accuracy: 0.7318\n",
            "Epoch 199/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7683 - accuracy: 0.7357 - val_loss: 0.7762 - val_accuracy: 0.7259\n",
            "Epoch 200/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7639 - accuracy: 0.7337 - val_loss: 0.7621 - val_accuracy: 0.7473\n",
            "Epoch 201/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7615 - accuracy: 0.7349 - val_loss: 0.7531 - val_accuracy: 0.7533\n",
            "Epoch 202/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.7758 - accuracy: 0.7326 - val_loss: 0.8061 - val_accuracy: 0.7092\n",
            "Epoch 203/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.7753 - accuracy: 0.7268 - val_loss: 0.7573 - val_accuracy: 0.7294\n",
            "Epoch 204/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7556 - accuracy: 0.7414 - val_loss: 0.7603 - val_accuracy: 0.7461\n",
            "Epoch 205/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7530 - accuracy: 0.7404 - val_loss: 0.7858 - val_accuracy: 0.7199\n",
            "Epoch 206/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.7660 - accuracy: 0.7328 - val_loss: 0.7837 - val_accuracy: 0.7259\n",
            "Epoch 207/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7590 - accuracy: 0.7366 - val_loss: 0.7530 - val_accuracy: 0.7545\n",
            "Epoch 208/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7528 - accuracy: 0.7480 - val_loss: 0.7578 - val_accuracy: 0.7330\n",
            "Epoch 209/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7512 - accuracy: 0.7366 - val_loss: 0.7602 - val_accuracy: 0.7366\n",
            "Epoch 210/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7506 - accuracy: 0.7395 - val_loss: 0.7514 - val_accuracy: 0.7437\n",
            "Epoch 211/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7498 - accuracy: 0.7423 - val_loss: 0.7656 - val_accuracy: 0.7282\n",
            "Epoch 212/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7439 - accuracy: 0.7397 - val_loss: 0.7418 - val_accuracy: 0.7521\n",
            "Epoch 213/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7316 - accuracy: 0.7521 - val_loss: 0.7353 - val_accuracy: 0.7533\n",
            "Epoch 214/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7305 - accuracy: 0.7549 - val_loss: 0.7636 - val_accuracy: 0.7175\n",
            "Epoch 215/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7520 - accuracy: 0.7340 - val_loss: 0.8020 - val_accuracy: 0.7128\n",
            "Epoch 216/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.7651 - accuracy: 0.7302 - val_loss: 0.7578 - val_accuracy: 0.7366\n",
            "Epoch 217/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7501 - accuracy: 0.7399 - val_loss: 0.8161 - val_accuracy: 0.6961\n",
            "Epoch 218/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7642 - accuracy: 0.7299 - val_loss: 0.7662 - val_accuracy: 0.7378\n",
            "Epoch 219/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.7499 - accuracy: 0.7366 - val_loss: 0.7620 - val_accuracy: 0.7247\n",
            "Epoch 220/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.7400 - accuracy: 0.7411 - val_loss: 0.7508 - val_accuracy: 0.7557\n",
            "Epoch 221/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7317 - accuracy: 0.7530 - val_loss: 0.7190 - val_accuracy: 0.7545\n",
            "Epoch 222/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7171 - accuracy: 0.7530 - val_loss: 0.7654 - val_accuracy: 0.7294\n",
            "Epoch 223/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7332 - accuracy: 0.7442 - val_loss: 0.7648 - val_accuracy: 0.7294\n",
            "Epoch 224/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.7269 - accuracy: 0.7468 - val_loss: 0.7291 - val_accuracy: 0.7580\n",
            "Epoch 225/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7269 - accuracy: 0.7487 - val_loss: 0.7388 - val_accuracy: 0.7390\n",
            "Epoch 226/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7185 - accuracy: 0.7566 - val_loss: 0.7205 - val_accuracy: 0.7604\n",
            "Epoch 227/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7206 - accuracy: 0.7526 - val_loss: 0.7286 - val_accuracy: 0.7390\n",
            "Epoch 228/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7173 - accuracy: 0.7564 - val_loss: 0.7394 - val_accuracy: 0.7426\n",
            "Epoch 229/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7148 - accuracy: 0.7616 - val_loss: 0.7408 - val_accuracy: 0.7306\n",
            "Epoch 230/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7075 - accuracy: 0.7554 - val_loss: 0.7240 - val_accuracy: 0.7604\n",
            "Epoch 231/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.7057 - accuracy: 0.7626 - val_loss: 0.7263 - val_accuracy: 0.7342\n",
            "Epoch 232/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.7182 - accuracy: 0.7492 - val_loss: 0.7127 - val_accuracy: 0.7557\n",
            "Epoch 233/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.7015 - accuracy: 0.7685 - val_loss: 0.7251 - val_accuracy: 0.7366\n",
            "Epoch 234/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.7038 - accuracy: 0.7578 - val_loss: 0.7088 - val_accuracy: 0.7557\n",
            "Epoch 235/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6974 - accuracy: 0.7640 - val_loss: 0.7041 - val_accuracy: 0.7616\n",
            "Epoch 236/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6945 - accuracy: 0.7661 - val_loss: 0.7428 - val_accuracy: 0.7199\n",
            "Epoch 237/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.7091 - accuracy: 0.7564 - val_loss: 0.7298 - val_accuracy: 0.7592\n",
            "Epoch 238/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6977 - accuracy: 0.7609 - val_loss: 0.6963 - val_accuracy: 0.7592\n",
            "Epoch 239/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.6973 - accuracy: 0.7564 - val_loss: 0.6969 - val_accuracy: 0.7712\n",
            "Epoch 240/1500\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 0.6848 - accuracy: 0.7692 - val_loss: 0.7038 - val_accuracy: 0.7580\n",
            "Epoch 241/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6890 - accuracy: 0.7673 - val_loss: 0.6857 - val_accuracy: 0.7688\n",
            "Epoch 242/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6954 - accuracy: 0.7609 - val_loss: 0.7010 - val_accuracy: 0.7616\n",
            "Epoch 243/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6883 - accuracy: 0.7704 - val_loss: 0.6877 - val_accuracy: 0.7712\n",
            "Epoch 244/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6765 - accuracy: 0.7754 - val_loss: 0.6896 - val_accuracy: 0.7604\n",
            "Epoch 245/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.6804 - accuracy: 0.7749 - val_loss: 0.6730 - val_accuracy: 0.7843\n",
            "Epoch 246/1500\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.6809 - accuracy: 0.7671 - val_loss: 0.6939 - val_accuracy: 0.7592\n",
            "Epoch 247/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6743 - accuracy: 0.7754 - val_loss: 0.7045 - val_accuracy: 0.7557\n",
            "Epoch 248/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.6930 - accuracy: 0.7649 - val_loss: 0.7199 - val_accuracy: 0.7354\n",
            "Epoch 249/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6894 - accuracy: 0.7623 - val_loss: 0.6690 - val_accuracy: 0.7819\n",
            "Epoch 250/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.6750 - accuracy: 0.7711 - val_loss: 0.6752 - val_accuracy: 0.7688\n",
            "Epoch 251/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6753 - accuracy: 0.7714 - val_loss: 0.6986 - val_accuracy: 0.7461\n",
            "Epoch 252/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6713 - accuracy: 0.7757 - val_loss: 0.6883 - val_accuracy: 0.7485\n",
            "Epoch 253/1500\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.6742 - accuracy: 0.7714 - val_loss: 0.6736 - val_accuracy: 0.7688\n",
            "Epoch 254/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6663 - accuracy: 0.7747 - val_loss: 0.6750 - val_accuracy: 0.7640\n",
            "Epoch 255/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6687 - accuracy: 0.7730 - val_loss: 0.6922 - val_accuracy: 0.7497\n",
            "Epoch 256/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6801 - accuracy: 0.7652 - val_loss: 0.6706 - val_accuracy: 0.7712\n",
            "Epoch 257/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6652 - accuracy: 0.7764 - val_loss: 0.6596 - val_accuracy: 0.7914\n",
            "Epoch 258/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6677 - accuracy: 0.7766 - val_loss: 0.7193 - val_accuracy: 0.7330\n",
            "Epoch 259/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6822 - accuracy: 0.7666 - val_loss: 0.6556 - val_accuracy: 0.7855\n",
            "Epoch 260/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.6637 - accuracy: 0.7740 - val_loss: 0.6612 - val_accuracy: 0.7759\n",
            "Epoch 261/1500\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.6709 - accuracy: 0.7716 - val_loss: 0.6902 - val_accuracy: 0.7485\n",
            "Epoch 262/1500\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 0.6662 - accuracy: 0.7742 - val_loss: 0.6677 - val_accuracy: 0.7735\n",
            "Epoch 263/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.6523 - accuracy: 0.7764 - val_loss: 0.6585 - val_accuracy: 0.7759\n",
            "Epoch 264/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6479 - accuracy: 0.7864 - val_loss: 0.6790 - val_accuracy: 0.7783\n",
            "Epoch 265/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6542 - accuracy: 0.7788 - val_loss: 0.6625 - val_accuracy: 0.7557\n",
            "Epoch 266/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6632 - accuracy: 0.7714 - val_loss: 0.6809 - val_accuracy: 0.7580\n",
            "Epoch 267/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6600 - accuracy: 0.7752 - val_loss: 0.6569 - val_accuracy: 0.7723\n",
            "Epoch 268/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6574 - accuracy: 0.7766 - val_loss: 0.6519 - val_accuracy: 0.7807\n",
            "Epoch 269/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6382 - accuracy: 0.7902 - val_loss: 0.6472 - val_accuracy: 0.7807\n",
            "Epoch 270/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6440 - accuracy: 0.7833 - val_loss: 0.6363 - val_accuracy: 0.7878\n",
            "Epoch 271/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.6393 - accuracy: 0.7904 - val_loss: 0.6330 - val_accuracy: 0.7974\n",
            "Epoch 272/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.6421 - accuracy: 0.7878 - val_loss: 0.6795 - val_accuracy: 0.7592\n",
            "Epoch 273/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6515 - accuracy: 0.7742 - val_loss: 0.6459 - val_accuracy: 0.7831\n",
            "Epoch 274/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6375 - accuracy: 0.7857 - val_loss: 0.6429 - val_accuracy: 0.7938\n",
            "Epoch 275/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6437 - accuracy: 0.7811 - val_loss: 0.6481 - val_accuracy: 0.7688\n",
            "Epoch 276/1500\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.6425 - accuracy: 0.7835 - val_loss: 0.6584 - val_accuracy: 0.7819\n",
            "Epoch 277/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6394 - accuracy: 0.7864 - val_loss: 0.6703 - val_accuracy: 0.7580\n",
            "Epoch 278/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6457 - accuracy: 0.7835 - val_loss: 0.6281 - val_accuracy: 0.7950\n",
            "Epoch 279/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6434 - accuracy: 0.7838 - val_loss: 0.6633 - val_accuracy: 0.7783\n",
            "Epoch 280/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6422 - accuracy: 0.7838 - val_loss: 0.6393 - val_accuracy: 0.7819\n",
            "Epoch 281/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6326 - accuracy: 0.7821 - val_loss: 0.6367 - val_accuracy: 0.7878\n",
            "Epoch 282/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6279 - accuracy: 0.7864 - val_loss: 0.6477 - val_accuracy: 0.7735\n",
            "Epoch 283/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6274 - accuracy: 0.7895 - val_loss: 0.6848 - val_accuracy: 0.7569\n",
            "Epoch 284/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6353 - accuracy: 0.7864 - val_loss: 0.6203 - val_accuracy: 0.7950\n",
            "Epoch 285/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6187 - accuracy: 0.7947 - val_loss: 0.6325 - val_accuracy: 0.7664\n",
            "Epoch 286/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.6259 - accuracy: 0.7854 - val_loss: 0.6169 - val_accuracy: 0.8045\n",
            "Epoch 287/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6198 - accuracy: 0.7904 - val_loss: 0.6344 - val_accuracy: 0.7759\n",
            "Epoch 288/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6206 - accuracy: 0.7904 - val_loss: 0.6207 - val_accuracy: 0.7890\n",
            "Epoch 289/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6210 - accuracy: 0.7904 - val_loss: 0.6177 - val_accuracy: 0.7974\n",
            "Epoch 290/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6170 - accuracy: 0.7919 - val_loss: 0.6360 - val_accuracy: 0.7771\n",
            "Epoch 291/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6206 - accuracy: 0.7940 - val_loss: 0.6129 - val_accuracy: 0.8069\n",
            "Epoch 292/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.6183 - accuracy: 0.7930 - val_loss: 0.6187 - val_accuracy: 0.7926\n",
            "Epoch 293/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.6119 - accuracy: 0.7973 - val_loss: 0.6186 - val_accuracy: 0.7855\n",
            "Epoch 294/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6150 - accuracy: 0.7916 - val_loss: 0.6371 - val_accuracy: 0.7783\n",
            "Epoch 295/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6146 - accuracy: 0.7964 - val_loss: 0.6016 - val_accuracy: 0.7986\n",
            "Epoch 296/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6130 - accuracy: 0.7935 - val_loss: 0.6305 - val_accuracy: 0.7843\n",
            "Epoch 297/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6197 - accuracy: 0.7909 - val_loss: 0.6124 - val_accuracy: 0.7974\n",
            "Epoch 298/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.6116 - accuracy: 0.7966 - val_loss: 0.6187 - val_accuracy: 0.7914\n",
            "Epoch 299/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.6055 - accuracy: 0.7928 - val_loss: 0.6079 - val_accuracy: 0.7962\n",
            "Epoch 300/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.6085 - accuracy: 0.7921 - val_loss: 0.6081 - val_accuracy: 0.7938\n",
            "Epoch 301/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.6110 - accuracy: 0.7888 - val_loss: 0.6261 - val_accuracy: 0.7819\n",
            "Epoch 302/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.6141 - accuracy: 0.7871 - val_loss: 0.6081 - val_accuracy: 0.8069\n",
            "Epoch 303/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6005 - accuracy: 0.8004 - val_loss: 0.6061 - val_accuracy: 0.7902\n",
            "Epoch 304/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5992 - accuracy: 0.7988 - val_loss: 0.6081 - val_accuracy: 0.8081\n",
            "Epoch 305/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6016 - accuracy: 0.7976 - val_loss: 0.6048 - val_accuracy: 0.7986\n",
            "Epoch 306/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5974 - accuracy: 0.8011 - val_loss: 0.5955 - val_accuracy: 0.8021\n",
            "Epoch 307/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5932 - accuracy: 0.8035 - val_loss: 0.6113 - val_accuracy: 0.7867\n",
            "Epoch 308/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5912 - accuracy: 0.8066 - val_loss: 0.6331 - val_accuracy: 0.7807\n",
            "Epoch 309/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5977 - accuracy: 0.8004 - val_loss: 0.6125 - val_accuracy: 0.8081\n",
            "Epoch 310/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5956 - accuracy: 0.8000 - val_loss: 0.5918 - val_accuracy: 0.8010\n",
            "Epoch 311/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5920 - accuracy: 0.8052 - val_loss: 0.6069 - val_accuracy: 0.7998\n",
            "Epoch 312/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5851 - accuracy: 0.8045 - val_loss: 0.5971 - val_accuracy: 0.7938\n",
            "Epoch 313/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5873 - accuracy: 0.8083 - val_loss: 0.6044 - val_accuracy: 0.7986\n",
            "Epoch 314/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.5961 - accuracy: 0.7983 - val_loss: 0.5986 - val_accuracy: 0.7914\n",
            "Epoch 315/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5968 - accuracy: 0.8004 - val_loss: 0.6067 - val_accuracy: 0.8093\n",
            "Epoch 316/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5940 - accuracy: 0.7997 - val_loss: 0.6160 - val_accuracy: 0.7890\n",
            "Epoch 317/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5940 - accuracy: 0.7964 - val_loss: 0.6129 - val_accuracy: 0.7890\n",
            "Epoch 318/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5865 - accuracy: 0.8066 - val_loss: 0.6003 - val_accuracy: 0.8057\n",
            "Epoch 319/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6131 - accuracy: 0.7857 - val_loss: 0.6220 - val_accuracy: 0.7974\n",
            "Epoch 320/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.6049 - accuracy: 0.7935 - val_loss: 0.6080 - val_accuracy: 0.7926\n",
            "Epoch 321/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5841 - accuracy: 0.8028 - val_loss: 0.5794 - val_accuracy: 0.8069\n",
            "Epoch 322/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.5745 - accuracy: 0.8109 - val_loss: 0.5686 - val_accuracy: 0.8212\n",
            "Epoch 323/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5753 - accuracy: 0.8052 - val_loss: 0.6214 - val_accuracy: 0.7783\n",
            "Epoch 324/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5983 - accuracy: 0.7933 - val_loss: 0.6031 - val_accuracy: 0.7902\n",
            "Epoch 325/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5817 - accuracy: 0.8057 - val_loss: 0.5678 - val_accuracy: 0.8117\n",
            "Epoch 326/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5713 - accuracy: 0.8078 - val_loss: 0.5765 - val_accuracy: 0.8117\n",
            "Epoch 327/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5745 - accuracy: 0.8095 - val_loss: 0.5687 - val_accuracy: 0.8153\n",
            "Epoch 328/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5675 - accuracy: 0.8083 - val_loss: 0.5699 - val_accuracy: 0.8236\n",
            "Epoch 329/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5729 - accuracy: 0.8090 - val_loss: 0.5784 - val_accuracy: 0.8069\n",
            "Epoch 330/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5882 - accuracy: 0.8007 - val_loss: 0.5892 - val_accuracy: 0.8105\n",
            "Epoch 331/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5746 - accuracy: 0.8040 - val_loss: 0.6268 - val_accuracy: 0.7688\n",
            "Epoch 332/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.6076 - accuracy: 0.7849 - val_loss: 0.5734 - val_accuracy: 0.8129\n",
            "Epoch 333/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5856 - accuracy: 0.8002 - val_loss: 0.5853 - val_accuracy: 0.8033\n",
            "Epoch 334/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5844 - accuracy: 0.7957 - val_loss: 0.5825 - val_accuracy: 0.8010\n",
            "Epoch 335/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5774 - accuracy: 0.8028 - val_loss: 0.6078 - val_accuracy: 0.7902\n",
            "Epoch 336/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5792 - accuracy: 0.8026 - val_loss: 0.6279 - val_accuracy: 0.7759\n",
            "Epoch 337/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5995 - accuracy: 0.7938 - val_loss: 0.6354 - val_accuracy: 0.7628\n",
            "Epoch 338/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5848 - accuracy: 0.7983 - val_loss: 0.6324 - val_accuracy: 0.7616\n",
            "Epoch 339/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5861 - accuracy: 0.7961 - val_loss: 0.5669 - val_accuracy: 0.8129\n",
            "Epoch 340/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5738 - accuracy: 0.8052 - val_loss: 0.5765 - val_accuracy: 0.7962\n",
            "Epoch 341/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5652 - accuracy: 0.8140 - val_loss: 0.5688 - val_accuracy: 0.8045\n",
            "Epoch 342/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5616 - accuracy: 0.8102 - val_loss: 0.5751 - val_accuracy: 0.8057\n",
            "Epoch 343/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5629 - accuracy: 0.8090 - val_loss: 0.5664 - val_accuracy: 0.8141\n",
            "Epoch 344/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5699 - accuracy: 0.8021 - val_loss: 0.5984 - val_accuracy: 0.7843\n",
            "Epoch 345/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.5788 - accuracy: 0.8023 - val_loss: 0.5611 - val_accuracy: 0.8296\n",
            "Epoch 346/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5683 - accuracy: 0.8050 - val_loss: 0.5771 - val_accuracy: 0.7986\n",
            "Epoch 347/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5711 - accuracy: 0.8061 - val_loss: 0.5680 - val_accuracy: 0.8105\n",
            "Epoch 348/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5572 - accuracy: 0.8126 - val_loss: 0.5558 - val_accuracy: 0.8236\n",
            "Epoch 349/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5541 - accuracy: 0.8188 - val_loss: 0.5550 - val_accuracy: 0.8200\n",
            "Epoch 350/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5533 - accuracy: 0.8131 - val_loss: 0.5575 - val_accuracy: 0.8093\n",
            "Epoch 351/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5480 - accuracy: 0.8226 - val_loss: 0.5460 - val_accuracy: 0.8236\n",
            "Epoch 352/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5482 - accuracy: 0.8142 - val_loss: 0.5539 - val_accuracy: 0.8236\n",
            "Epoch 353/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5446 - accuracy: 0.8207 - val_loss: 0.5470 - val_accuracy: 0.8176\n",
            "Epoch 354/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5387 - accuracy: 0.8259 - val_loss: 0.5543 - val_accuracy: 0.8153\n",
            "Epoch 355/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5454 - accuracy: 0.8181 - val_loss: 0.5316 - val_accuracy: 0.8296\n",
            "Epoch 356/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.5375 - accuracy: 0.8223 - val_loss: 0.5428 - val_accuracy: 0.8296\n",
            "Epoch 357/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5373 - accuracy: 0.8226 - val_loss: 0.5446 - val_accuracy: 0.8117\n",
            "Epoch 358/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5513 - accuracy: 0.8123 - val_loss: 0.5884 - val_accuracy: 0.7867\n",
            "Epoch 359/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5599 - accuracy: 0.8095 - val_loss: 0.5486 - val_accuracy: 0.8164\n",
            "Epoch 360/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5470 - accuracy: 0.8173 - val_loss: 0.5555 - val_accuracy: 0.8260\n",
            "Epoch 361/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5467 - accuracy: 0.8169 - val_loss: 0.5753 - val_accuracy: 0.7998\n",
            "Epoch 362/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5427 - accuracy: 0.8223 - val_loss: 0.5640 - val_accuracy: 0.8057\n",
            "Epoch 363/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5462 - accuracy: 0.8171 - val_loss: 0.5403 - val_accuracy: 0.8248\n",
            "Epoch 364/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5472 - accuracy: 0.8119 - val_loss: 0.5554 - val_accuracy: 0.8093\n",
            "Epoch 365/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5499 - accuracy: 0.8171 - val_loss: 0.5697 - val_accuracy: 0.8045\n",
            "Epoch 366/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5433 - accuracy: 0.8154 - val_loss: 0.5707 - val_accuracy: 0.7962\n",
            "Epoch 367/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5550 - accuracy: 0.8102 - val_loss: 0.5498 - val_accuracy: 0.8284\n",
            "Epoch 368/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5436 - accuracy: 0.8223 - val_loss: 0.5613 - val_accuracy: 0.8069\n",
            "Epoch 369/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5422 - accuracy: 0.8178 - val_loss: 0.5826 - val_accuracy: 0.7914\n",
            "Epoch 370/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5421 - accuracy: 0.8169 - val_loss: 0.5643 - val_accuracy: 0.8081\n",
            "Epoch 371/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5535 - accuracy: 0.8135 - val_loss: 0.5314 - val_accuracy: 0.8319\n",
            "Epoch 372/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5519 - accuracy: 0.8114 - val_loss: 0.5770 - val_accuracy: 0.7998\n",
            "Epoch 373/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5514 - accuracy: 0.8116 - val_loss: 0.5347 - val_accuracy: 0.8284\n",
            "Epoch 374/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5272 - accuracy: 0.8250 - val_loss: 0.5223 - val_accuracy: 0.8296\n",
            "Epoch 375/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5283 - accuracy: 0.8257 - val_loss: 0.5493 - val_accuracy: 0.8188\n",
            "Epoch 376/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5343 - accuracy: 0.8219 - val_loss: 0.5716 - val_accuracy: 0.7855\n",
            "Epoch 377/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5618 - accuracy: 0.8050 - val_loss: 0.6055 - val_accuracy: 0.7807\n",
            "Epoch 378/1500\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5643 - accuracy: 0.8019 - val_loss: 0.5734 - val_accuracy: 0.7962\n",
            "Epoch 379/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5418 - accuracy: 0.8169 - val_loss: 0.5587 - val_accuracy: 0.8010\n",
            "Epoch 380/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5478 - accuracy: 0.8095 - val_loss: 0.5312 - val_accuracy: 0.8296\n",
            "Epoch 381/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5379 - accuracy: 0.8152 - val_loss: 0.5365 - val_accuracy: 0.8176\n",
            "Epoch 382/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5376 - accuracy: 0.8154 - val_loss: 0.5298 - val_accuracy: 0.8319\n",
            "Epoch 383/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5397 - accuracy: 0.8204 - val_loss: 0.5460 - val_accuracy: 0.8045\n",
            "Epoch 384/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.5496 - accuracy: 0.8116 - val_loss: 0.5387 - val_accuracy: 0.8200\n",
            "Epoch 385/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5246 - accuracy: 0.8214 - val_loss: 0.5186 - val_accuracy: 0.8355\n",
            "Epoch 386/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5174 - accuracy: 0.8281 - val_loss: 0.5397 - val_accuracy: 0.8129\n",
            "Epoch 387/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5264 - accuracy: 0.8266 - val_loss: 0.5230 - val_accuracy: 0.8188\n",
            "Epoch 388/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5212 - accuracy: 0.8271 - val_loss: 0.5217 - val_accuracy: 0.8308\n",
            "Epoch 389/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5157 - accuracy: 0.8285 - val_loss: 0.5089 - val_accuracy: 0.8367\n",
            "Epoch 390/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5100 - accuracy: 0.8340 - val_loss: 0.5093 - val_accuracy: 0.8367\n",
            "Epoch 391/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5130 - accuracy: 0.8316 - val_loss: 0.5175 - val_accuracy: 0.8415\n",
            "Epoch 392/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5200 - accuracy: 0.8266 - val_loss: 0.5148 - val_accuracy: 0.8331\n",
            "Epoch 393/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5087 - accuracy: 0.8378 - val_loss: 0.5474 - val_accuracy: 0.8010\n",
            "Epoch 394/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5208 - accuracy: 0.8290 - val_loss: 0.5258 - val_accuracy: 0.8296\n",
            "Epoch 395/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5094 - accuracy: 0.8335 - val_loss: 0.5152 - val_accuracy: 0.8296\n",
            "Epoch 396/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5110 - accuracy: 0.8331 - val_loss: 0.5326 - val_accuracy: 0.8224\n",
            "Epoch 397/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.5246 - accuracy: 0.8211 - val_loss: 0.5074 - val_accuracy: 0.8355\n",
            "Epoch 398/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5411 - accuracy: 0.8107 - val_loss: 0.5227 - val_accuracy: 0.8200\n",
            "Epoch 399/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5078 - accuracy: 0.8350 - val_loss: 0.5012 - val_accuracy: 0.8415\n",
            "Epoch 400/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5047 - accuracy: 0.8390 - val_loss: 0.4961 - val_accuracy: 0.8403\n",
            "Epoch 401/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5107 - accuracy: 0.8302 - val_loss: 0.5504 - val_accuracy: 0.8129\n",
            "Epoch 402/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5379 - accuracy: 0.8154 - val_loss: 0.5636 - val_accuracy: 0.8069\n",
            "Epoch 403/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5344 - accuracy: 0.8192 - val_loss: 0.5113 - val_accuracy: 0.8403\n",
            "Epoch 404/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5274 - accuracy: 0.8259 - val_loss: 0.4995 - val_accuracy: 0.8439\n",
            "Epoch 405/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5058 - accuracy: 0.8335 - val_loss: 0.5177 - val_accuracy: 0.8308\n",
            "Epoch 406/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5085 - accuracy: 0.8352 - val_loss: 0.5073 - val_accuracy: 0.8379\n",
            "Epoch 407/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5059 - accuracy: 0.8300 - val_loss: 0.5087 - val_accuracy: 0.8474\n",
            "Epoch 408/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4978 - accuracy: 0.8404 - val_loss: 0.4936 - val_accuracy: 0.8379\n",
            "Epoch 409/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4992 - accuracy: 0.8362 - val_loss: 0.5484 - val_accuracy: 0.8164\n",
            "Epoch 410/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5210 - accuracy: 0.8300 - val_loss: 0.5618 - val_accuracy: 0.7962\n",
            "Epoch 411/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.5141 - accuracy: 0.8209 - val_loss: 0.5387 - val_accuracy: 0.8093\n",
            "Epoch 412/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5142 - accuracy: 0.8261 - val_loss: 0.5032 - val_accuracy: 0.8296\n",
            "Epoch 413/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5077 - accuracy: 0.8369 - val_loss: 0.5015 - val_accuracy: 0.8415\n",
            "Epoch 414/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5037 - accuracy: 0.8309 - val_loss: 0.4902 - val_accuracy: 0.8427\n",
            "Epoch 415/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4959 - accuracy: 0.8352 - val_loss: 0.4984 - val_accuracy: 0.8403\n",
            "Epoch 416/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4949 - accuracy: 0.8364 - val_loss: 0.4964 - val_accuracy: 0.8439\n",
            "Epoch 417/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5002 - accuracy: 0.8364 - val_loss: 0.5134 - val_accuracy: 0.8296\n",
            "Epoch 418/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4960 - accuracy: 0.8373 - val_loss: 0.4973 - val_accuracy: 0.8474\n",
            "Epoch 419/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4916 - accuracy: 0.8392 - val_loss: 0.4855 - val_accuracy: 0.8546\n",
            "Epoch 420/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4950 - accuracy: 0.8366 - val_loss: 0.4875 - val_accuracy: 0.8510\n",
            "Epoch 421/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4920 - accuracy: 0.8412 - val_loss: 0.5035 - val_accuracy: 0.8367\n",
            "Epoch 422/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4968 - accuracy: 0.8335 - val_loss: 0.4869 - val_accuracy: 0.8439\n",
            "Epoch 423/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4894 - accuracy: 0.8376 - val_loss: 0.4852 - val_accuracy: 0.8522\n",
            "Epoch 424/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4871 - accuracy: 0.8433 - val_loss: 0.5015 - val_accuracy: 0.8379\n",
            "Epoch 425/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4955 - accuracy: 0.8385 - val_loss: 0.5057 - val_accuracy: 0.8308\n",
            "Epoch 426/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.5077 - accuracy: 0.8309 - val_loss: 0.5020 - val_accuracy: 0.8379\n",
            "Epoch 427/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4842 - accuracy: 0.8476 - val_loss: 0.4815 - val_accuracy: 0.8391\n",
            "Epoch 428/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4880 - accuracy: 0.8421 - val_loss: 0.4850 - val_accuracy: 0.8462\n",
            "Epoch 429/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4918 - accuracy: 0.8426 - val_loss: 0.4917 - val_accuracy: 0.8498\n",
            "Epoch 430/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4959 - accuracy: 0.8383 - val_loss: 0.5253 - val_accuracy: 0.8129\n",
            "Epoch 431/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5077 - accuracy: 0.8328 - val_loss: 0.5005 - val_accuracy: 0.8379\n",
            "Epoch 432/1500\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5212 - accuracy: 0.8197 - val_loss: 0.4879 - val_accuracy: 0.8415\n",
            "Epoch 433/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5041 - accuracy: 0.8309 - val_loss: 0.5843 - val_accuracy: 0.7974\n",
            "Epoch 434/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5349 - accuracy: 0.8135 - val_loss: 0.5317 - val_accuracy: 0.8224\n",
            "Epoch 435/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.5064 - accuracy: 0.8283 - val_loss: 0.4820 - val_accuracy: 0.8486\n",
            "Epoch 436/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4960 - accuracy: 0.8352 - val_loss: 0.4995 - val_accuracy: 0.8296\n",
            "Epoch 437/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4986 - accuracy: 0.8331 - val_loss: 0.5082 - val_accuracy: 0.8284\n",
            "Epoch 438/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5128 - accuracy: 0.8283 - val_loss: 0.5010 - val_accuracy: 0.8331\n",
            "Epoch 439/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4984 - accuracy: 0.8292 - val_loss: 0.4854 - val_accuracy: 0.8498\n",
            "Epoch 440/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4842 - accuracy: 0.8412 - val_loss: 0.4729 - val_accuracy: 0.8462\n",
            "Epoch 441/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4924 - accuracy: 0.8376 - val_loss: 0.4952 - val_accuracy: 0.8308\n",
            "Epoch 442/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4969 - accuracy: 0.8290 - val_loss: 0.5012 - val_accuracy: 0.8403\n",
            "Epoch 443/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4942 - accuracy: 0.8342 - val_loss: 0.4917 - val_accuracy: 0.8319\n",
            "Epoch 444/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4839 - accuracy: 0.8366 - val_loss: 0.4784 - val_accuracy: 0.8570\n",
            "Epoch 445/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4798 - accuracy: 0.8419 - val_loss: 0.4890 - val_accuracy: 0.8379\n",
            "Epoch 446/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4821 - accuracy: 0.8407 - val_loss: 0.4829 - val_accuracy: 0.8498\n",
            "Epoch 447/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4790 - accuracy: 0.8438 - val_loss: 0.4679 - val_accuracy: 0.8439\n",
            "Epoch 448/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4806 - accuracy: 0.8404 - val_loss: 0.4768 - val_accuracy: 0.8415\n",
            "Epoch 449/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4869 - accuracy: 0.8378 - val_loss: 0.4793 - val_accuracy: 0.8462\n",
            "Epoch 450/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4824 - accuracy: 0.8385 - val_loss: 0.4748 - val_accuracy: 0.8558\n",
            "Epoch 451/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4711 - accuracy: 0.8431 - val_loss: 0.4900 - val_accuracy: 0.8439\n",
            "Epoch 452/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4800 - accuracy: 0.8433 - val_loss: 0.4691 - val_accuracy: 0.8498\n",
            "Epoch 453/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4848 - accuracy: 0.8359 - val_loss: 0.4888 - val_accuracy: 0.8415\n",
            "Epoch 454/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4950 - accuracy: 0.8323 - val_loss: 0.4782 - val_accuracy: 0.8439\n",
            "Epoch 455/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4798 - accuracy: 0.8390 - val_loss: 0.5003 - val_accuracy: 0.8355\n",
            "Epoch 456/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4911 - accuracy: 0.8312 - val_loss: 0.5017 - val_accuracy: 0.8308\n",
            "Epoch 457/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4843 - accuracy: 0.8366 - val_loss: 0.4768 - val_accuracy: 0.8534\n",
            "Epoch 458/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4790 - accuracy: 0.8400 - val_loss: 0.4644 - val_accuracy: 0.8474\n",
            "Epoch 459/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4738 - accuracy: 0.8464 - val_loss: 0.4682 - val_accuracy: 0.8534\n",
            "Epoch 460/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4745 - accuracy: 0.8426 - val_loss: 0.4717 - val_accuracy: 0.8558\n",
            "Epoch 461/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4727 - accuracy: 0.8512 - val_loss: 0.4625 - val_accuracy: 0.8605\n",
            "Epoch 462/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4733 - accuracy: 0.8454 - val_loss: 0.4655 - val_accuracy: 0.8594\n",
            "Epoch 463/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4655 - accuracy: 0.8495 - val_loss: 0.4534 - val_accuracy: 0.8582\n",
            "Epoch 464/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4710 - accuracy: 0.8416 - val_loss: 0.4695 - val_accuracy: 0.8534\n",
            "Epoch 465/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4681 - accuracy: 0.8502 - val_loss: 0.4838 - val_accuracy: 0.8391\n",
            "Epoch 466/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4770 - accuracy: 0.8412 - val_loss: 0.4824 - val_accuracy: 0.8534\n",
            "Epoch 467/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4699 - accuracy: 0.8457 - val_loss: 0.4788 - val_accuracy: 0.8427\n",
            "Epoch 468/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4661 - accuracy: 0.8478 - val_loss: 0.4615 - val_accuracy: 0.8617\n",
            "Epoch 469/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4709 - accuracy: 0.8469 - val_loss: 0.4649 - val_accuracy: 0.8462\n",
            "Epoch 470/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4726 - accuracy: 0.8416 - val_loss: 0.4684 - val_accuracy: 0.8486\n",
            "Epoch 471/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4648 - accuracy: 0.8502 - val_loss: 0.4613 - val_accuracy: 0.8570\n",
            "Epoch 472/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4663 - accuracy: 0.8435 - val_loss: 0.4592 - val_accuracy: 0.8510\n",
            "Epoch 473/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4600 - accuracy: 0.8478 - val_loss: 0.4541 - val_accuracy: 0.8629\n",
            "Epoch 474/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4537 - accuracy: 0.8504 - val_loss: 0.4546 - val_accuracy: 0.8534\n",
            "Epoch 475/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4579 - accuracy: 0.8495 - val_loss: 0.4514 - val_accuracy: 0.8617\n",
            "Epoch 476/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4635 - accuracy: 0.8485 - val_loss: 0.4649 - val_accuracy: 0.8546\n",
            "Epoch 477/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4681 - accuracy: 0.8469 - val_loss: 0.5282 - val_accuracy: 0.8129\n",
            "Epoch 478/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4961 - accuracy: 0.8276 - val_loss: 0.4716 - val_accuracy: 0.8510\n",
            "Epoch 479/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4819 - accuracy: 0.8402 - val_loss: 0.4843 - val_accuracy: 0.8319\n",
            "Epoch 480/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4899 - accuracy: 0.8278 - val_loss: 0.4723 - val_accuracy: 0.8403\n",
            "Epoch 481/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4706 - accuracy: 0.8412 - val_loss: 0.4637 - val_accuracy: 0.8510\n",
            "Epoch 482/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4731 - accuracy: 0.8407 - val_loss: 0.4721 - val_accuracy: 0.8462\n",
            "Epoch 483/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4793 - accuracy: 0.8428 - val_loss: 0.5561 - val_accuracy: 0.8081\n",
            "Epoch 484/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5049 - accuracy: 0.8214 - val_loss: 0.4974 - val_accuracy: 0.8308\n",
            "Epoch 485/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4790 - accuracy: 0.8390 - val_loss: 0.4808 - val_accuracy: 0.8462\n",
            "Epoch 486/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4673 - accuracy: 0.8442 - val_loss: 0.4554 - val_accuracy: 0.8605\n",
            "Epoch 487/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4562 - accuracy: 0.8514 - val_loss: 0.4506 - val_accuracy: 0.8498\n",
            "Epoch 488/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4504 - accuracy: 0.8552 - val_loss: 0.4574 - val_accuracy: 0.8427\n",
            "Epoch 489/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4722 - accuracy: 0.8426 - val_loss: 0.4577 - val_accuracy: 0.8534\n",
            "Epoch 490/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4675 - accuracy: 0.8435 - val_loss: 0.4414 - val_accuracy: 0.8582\n",
            "Epoch 491/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4631 - accuracy: 0.8457 - val_loss: 0.5023 - val_accuracy: 0.8272\n",
            "Epoch 492/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4733 - accuracy: 0.8359 - val_loss: 0.4782 - val_accuracy: 0.8534\n",
            "Epoch 493/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4684 - accuracy: 0.8371 - val_loss: 0.4499 - val_accuracy: 0.8605\n",
            "Epoch 494/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4495 - accuracy: 0.8492 - val_loss: 0.4345 - val_accuracy: 0.8689\n",
            "Epoch 495/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4529 - accuracy: 0.8557 - val_loss: 0.4741 - val_accuracy: 0.8439\n",
            "Epoch 496/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4609 - accuracy: 0.8438 - val_loss: 0.4632 - val_accuracy: 0.8510\n",
            "Epoch 497/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4537 - accuracy: 0.8509 - val_loss: 0.4615 - val_accuracy: 0.8439\n",
            "Epoch 498/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4518 - accuracy: 0.8526 - val_loss: 0.4497 - val_accuracy: 0.8558\n",
            "Epoch 499/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4537 - accuracy: 0.8507 - val_loss: 0.4416 - val_accuracy: 0.8594\n",
            "Epoch 500/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4527 - accuracy: 0.8526 - val_loss: 0.4452 - val_accuracy: 0.8558\n",
            "Epoch 501/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4484 - accuracy: 0.8526 - val_loss: 0.4480 - val_accuracy: 0.8629\n",
            "Epoch 502/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4530 - accuracy: 0.8481 - val_loss: 0.4733 - val_accuracy: 0.8391\n",
            "Epoch 503/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4509 - accuracy: 0.8483 - val_loss: 0.4408 - val_accuracy: 0.8641\n",
            "Epoch 504/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4458 - accuracy: 0.8571 - val_loss: 0.4773 - val_accuracy: 0.8248\n",
            "Epoch 505/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4705 - accuracy: 0.8383 - val_loss: 0.4370 - val_accuracy: 0.8546\n",
            "Epoch 506/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4599 - accuracy: 0.8466 - val_loss: 0.4473 - val_accuracy: 0.8605\n",
            "Epoch 507/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4538 - accuracy: 0.8488 - val_loss: 0.4542 - val_accuracy: 0.8546\n",
            "Epoch 508/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4508 - accuracy: 0.8512 - val_loss: 0.4390 - val_accuracy: 0.8617\n",
            "Epoch 509/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4410 - accuracy: 0.8593 - val_loss: 0.4447 - val_accuracy: 0.8570\n",
            "Epoch 510/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4481 - accuracy: 0.8531 - val_loss: 0.4546 - val_accuracy: 0.8510\n",
            "Epoch 511/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4488 - accuracy: 0.8495 - val_loss: 0.4538 - val_accuracy: 0.8594\n",
            "Epoch 512/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4475 - accuracy: 0.8538 - val_loss: 0.4428 - val_accuracy: 0.8522\n",
            "Epoch 513/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4449 - accuracy: 0.8545 - val_loss: 0.4584 - val_accuracy: 0.8403\n",
            "Epoch 514/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4600 - accuracy: 0.8438 - val_loss: 0.4699 - val_accuracy: 0.8462\n",
            "Epoch 515/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4537 - accuracy: 0.8514 - val_loss: 0.4592 - val_accuracy: 0.8486\n",
            "Epoch 516/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4697 - accuracy: 0.8392 - val_loss: 0.4816 - val_accuracy: 0.8236\n",
            "Epoch 517/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4547 - accuracy: 0.8519 - val_loss: 0.4398 - val_accuracy: 0.8582\n",
            "Epoch 518/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4460 - accuracy: 0.8500 - val_loss: 0.4341 - val_accuracy: 0.8570\n",
            "Epoch 519/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4468 - accuracy: 0.8500 - val_loss: 0.4536 - val_accuracy: 0.8510\n",
            "Epoch 520/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4468 - accuracy: 0.8516 - val_loss: 0.4438 - val_accuracy: 0.8582\n",
            "Epoch 521/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4468 - accuracy: 0.8504 - val_loss: 0.4407 - val_accuracy: 0.8701\n",
            "Epoch 522/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4347 - accuracy: 0.8588 - val_loss: 0.4478 - val_accuracy: 0.8534\n",
            "Epoch 523/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4393 - accuracy: 0.8602 - val_loss: 0.4420 - val_accuracy: 0.8605\n",
            "Epoch 524/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4417 - accuracy: 0.8607 - val_loss: 0.4646 - val_accuracy: 0.8427\n",
            "Epoch 525/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4462 - accuracy: 0.8519 - val_loss: 0.4699 - val_accuracy: 0.8379\n",
            "Epoch 526/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4516 - accuracy: 0.8507 - val_loss: 0.4352 - val_accuracy: 0.8689\n",
            "Epoch 527/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4540 - accuracy: 0.8466 - val_loss: 0.4894 - val_accuracy: 0.8296\n",
            "Epoch 528/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4508 - accuracy: 0.8500 - val_loss: 0.4382 - val_accuracy: 0.8653\n",
            "Epoch 529/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4323 - accuracy: 0.8547 - val_loss: 0.4443 - val_accuracy: 0.8570\n",
            "Epoch 530/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4322 - accuracy: 0.8593 - val_loss: 0.4407 - val_accuracy: 0.8641\n",
            "Epoch 531/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4379 - accuracy: 0.8554 - val_loss: 0.4322 - val_accuracy: 0.8641\n",
            "Epoch 532/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4495 - accuracy: 0.8521 - val_loss: 0.4522 - val_accuracy: 0.8439\n",
            "Epoch 533/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4406 - accuracy: 0.8543 - val_loss: 0.4580 - val_accuracy: 0.8486\n",
            "Epoch 534/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4643 - accuracy: 0.8440 - val_loss: 0.4625 - val_accuracy: 0.8522\n",
            "Epoch 535/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4755 - accuracy: 0.8369 - val_loss: 0.4426 - val_accuracy: 0.8558\n",
            "Epoch 536/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4537 - accuracy: 0.8516 - val_loss: 0.4703 - val_accuracy: 0.8415\n",
            "Epoch 537/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4532 - accuracy: 0.8490 - val_loss: 0.4347 - val_accuracy: 0.8641\n",
            "Epoch 538/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4340 - accuracy: 0.8585 - val_loss: 0.4265 - val_accuracy: 0.8605\n",
            "Epoch 539/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4332 - accuracy: 0.8585 - val_loss: 0.4241 - val_accuracy: 0.8701\n",
            "Epoch 540/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4294 - accuracy: 0.8609 - val_loss: 0.4299 - val_accuracy: 0.8546\n",
            "Epoch 541/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4357 - accuracy: 0.8526 - val_loss: 0.4129 - val_accuracy: 0.8653\n",
            "Epoch 542/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4333 - accuracy: 0.8566 - val_loss: 0.4517 - val_accuracy: 0.8439\n",
            "Epoch 543/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4451 - accuracy: 0.8457 - val_loss: 0.4254 - val_accuracy: 0.8558\n",
            "Epoch 544/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4304 - accuracy: 0.8547 - val_loss: 0.4269 - val_accuracy: 0.8582\n",
            "Epoch 545/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4306 - accuracy: 0.8564 - val_loss: 0.4250 - val_accuracy: 0.8713\n",
            "Epoch 546/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4199 - accuracy: 0.8607 - val_loss: 0.4120 - val_accuracy: 0.8772\n",
            "Epoch 547/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4227 - accuracy: 0.8638 - val_loss: 0.4173 - val_accuracy: 0.8689\n",
            "Epoch 548/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4277 - accuracy: 0.8609 - val_loss: 0.4263 - val_accuracy: 0.8677\n",
            "Epoch 549/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4330 - accuracy: 0.8590 - val_loss: 0.4494 - val_accuracy: 0.8427\n",
            "Epoch 550/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4307 - accuracy: 0.8588 - val_loss: 0.4353 - val_accuracy: 0.8689\n",
            "Epoch 551/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4342 - accuracy: 0.8593 - val_loss: 0.4648 - val_accuracy: 0.8331\n",
            "Epoch 552/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4482 - accuracy: 0.8495 - val_loss: 0.4655 - val_accuracy: 0.8510\n",
            "Epoch 553/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4561 - accuracy: 0.8385 - val_loss: 0.4250 - val_accuracy: 0.8725\n",
            "Epoch 554/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4395 - accuracy: 0.8521 - val_loss: 0.4434 - val_accuracy: 0.8439\n",
            "Epoch 555/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4554 - accuracy: 0.8469 - val_loss: 0.4463 - val_accuracy: 0.8510\n",
            "Epoch 556/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4472 - accuracy: 0.8504 - val_loss: 0.4240 - val_accuracy: 0.8629\n",
            "Epoch 557/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4272 - accuracy: 0.8585 - val_loss: 0.4210 - val_accuracy: 0.8689\n",
            "Epoch 558/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4382 - accuracy: 0.8523 - val_loss: 0.4306 - val_accuracy: 0.8629\n",
            "Epoch 559/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4323 - accuracy: 0.8562 - val_loss: 0.4337 - val_accuracy: 0.8534\n",
            "Epoch 560/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4343 - accuracy: 0.8609 - val_loss: 0.4255 - val_accuracy: 0.8725\n",
            "Epoch 561/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4430 - accuracy: 0.8569 - val_loss: 0.4430 - val_accuracy: 0.8510\n",
            "Epoch 562/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4406 - accuracy: 0.8535 - val_loss: 0.4354 - val_accuracy: 0.8558\n",
            "Epoch 563/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4304 - accuracy: 0.8562 - val_loss: 0.4349 - val_accuracy: 0.8534\n",
            "Epoch 564/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4257 - accuracy: 0.8602 - val_loss: 0.4125 - val_accuracy: 0.8653\n",
            "Epoch 565/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4270 - accuracy: 0.8623 - val_loss: 0.4411 - val_accuracy: 0.8510\n",
            "Epoch 566/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4407 - accuracy: 0.8490 - val_loss: 0.4214 - val_accuracy: 0.8653\n",
            "Epoch 567/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4338 - accuracy: 0.8523 - val_loss: 0.4381 - val_accuracy: 0.8617\n",
            "Epoch 568/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4262 - accuracy: 0.8600 - val_loss: 0.4478 - val_accuracy: 0.8439\n",
            "Epoch 569/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4289 - accuracy: 0.8566 - val_loss: 0.4236 - val_accuracy: 0.8617\n",
            "Epoch 570/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4248 - accuracy: 0.8573 - val_loss: 0.4017 - val_accuracy: 0.8796\n",
            "Epoch 571/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4178 - accuracy: 0.8626 - val_loss: 0.4658 - val_accuracy: 0.8379\n",
            "Epoch 572/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4331 - accuracy: 0.8526 - val_loss: 0.4233 - val_accuracy: 0.8594\n",
            "Epoch 573/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4244 - accuracy: 0.8573 - val_loss: 0.4552 - val_accuracy: 0.8474\n",
            "Epoch 574/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.4291 - accuracy: 0.8571 - val_loss: 0.4191 - val_accuracy: 0.8653\n",
            "Epoch 575/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4169 - accuracy: 0.8638 - val_loss: 0.4109 - val_accuracy: 0.8749\n",
            "Epoch 576/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4137 - accuracy: 0.8681 - val_loss: 0.4292 - val_accuracy: 0.8474\n",
            "Epoch 577/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4316 - accuracy: 0.8535 - val_loss: 0.4261 - val_accuracy: 0.8689\n",
            "Epoch 578/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4220 - accuracy: 0.8566 - val_loss: 0.4052 - val_accuracy: 0.8617\n",
            "Epoch 579/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4112 - accuracy: 0.8600 - val_loss: 0.4042 - val_accuracy: 0.8784\n",
            "Epoch 580/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4168 - accuracy: 0.8635 - val_loss: 0.4091 - val_accuracy: 0.8701\n",
            "Epoch 581/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4106 - accuracy: 0.8693 - val_loss: 0.4051 - val_accuracy: 0.8713\n",
            "Epoch 582/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4275 - accuracy: 0.8550 - val_loss: 0.4223 - val_accuracy: 0.8617\n",
            "Epoch 583/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4191 - accuracy: 0.8571 - val_loss: 0.4028 - val_accuracy: 0.8737\n",
            "Epoch 584/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4148 - accuracy: 0.8633 - val_loss: 0.4221 - val_accuracy: 0.8689\n",
            "Epoch 585/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4340 - accuracy: 0.8557 - val_loss: 0.4662 - val_accuracy: 0.8427\n",
            "Epoch 586/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4381 - accuracy: 0.8523 - val_loss: 0.4259 - val_accuracy: 0.8641\n",
            "Epoch 587/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.4280 - accuracy: 0.8590 - val_loss: 0.4119 - val_accuracy: 0.8653\n",
            "Epoch 588/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4272 - accuracy: 0.8540 - val_loss: 0.4484 - val_accuracy: 0.8403\n",
            "Epoch 589/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4235 - accuracy: 0.8585 - val_loss: 0.4346 - val_accuracy: 0.8582\n",
            "Epoch 590/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4276 - accuracy: 0.8533 - val_loss: 0.4362 - val_accuracy: 0.8439\n",
            "Epoch 591/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4223 - accuracy: 0.8559 - val_loss: 0.4254 - val_accuracy: 0.8689\n",
            "Epoch 592/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4242 - accuracy: 0.8538 - val_loss: 0.4014 - val_accuracy: 0.8677\n",
            "Epoch 593/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4188 - accuracy: 0.8633 - val_loss: 0.3994 - val_accuracy: 0.8689\n",
            "Epoch 594/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4141 - accuracy: 0.8604 - val_loss: 0.4114 - val_accuracy: 0.8665\n",
            "Epoch 595/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4151 - accuracy: 0.8647 - val_loss: 0.3983 - val_accuracy: 0.8772\n",
            "Epoch 596/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4248 - accuracy: 0.8600 - val_loss: 0.4432 - val_accuracy: 0.8439\n",
            "Epoch 597/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4375 - accuracy: 0.8528 - val_loss: 0.3979 - val_accuracy: 0.8689\n",
            "Epoch 598/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4269 - accuracy: 0.8540 - val_loss: 0.4329 - val_accuracy: 0.8534\n",
            "Epoch 599/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4268 - accuracy: 0.8607 - val_loss: 0.4208 - val_accuracy: 0.8617\n",
            "Epoch 600/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4059 - accuracy: 0.8690 - val_loss: 0.3992 - val_accuracy: 0.8760\n",
            "Epoch 601/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4115 - accuracy: 0.8619 - val_loss: 0.4211 - val_accuracy: 0.8558\n",
            "Epoch 602/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4145 - accuracy: 0.8643 - val_loss: 0.3998 - val_accuracy: 0.8641\n",
            "Epoch 603/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4023 - accuracy: 0.8623 - val_loss: 0.3915 - val_accuracy: 0.8725\n",
            "Epoch 604/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4064 - accuracy: 0.8614 - val_loss: 0.4361 - val_accuracy: 0.8522\n",
            "Epoch 605/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4282 - accuracy: 0.8526 - val_loss: 0.4222 - val_accuracy: 0.8677\n",
            "Epoch 606/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4218 - accuracy: 0.8581 - val_loss: 0.3930 - val_accuracy: 0.8713\n",
            "Epoch 607/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4081 - accuracy: 0.8640 - val_loss: 0.4053 - val_accuracy: 0.8689\n",
            "Epoch 608/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4083 - accuracy: 0.8643 - val_loss: 0.4188 - val_accuracy: 0.8594\n",
            "Epoch 609/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4142 - accuracy: 0.8588 - val_loss: 0.4214 - val_accuracy: 0.8629\n",
            "Epoch 610/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4099 - accuracy: 0.8614 - val_loss: 0.4024 - val_accuracy: 0.8737\n",
            "Epoch 611/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4171 - accuracy: 0.8602 - val_loss: 0.4134 - val_accuracy: 0.8570\n",
            "Epoch 612/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4160 - accuracy: 0.8595 - val_loss: 0.4372 - val_accuracy: 0.8522\n",
            "Epoch 613/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4126 - accuracy: 0.8607 - val_loss: 0.4036 - val_accuracy: 0.8665\n",
            "Epoch 614/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.4168 - accuracy: 0.8550 - val_loss: 0.4004 - val_accuracy: 0.8713\n",
            "Epoch 615/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4188 - accuracy: 0.8585 - val_loss: 0.4058 - val_accuracy: 0.8772\n",
            "Epoch 616/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4155 - accuracy: 0.8619 - val_loss: 0.4275 - val_accuracy: 0.8582\n",
            "Epoch 617/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4114 - accuracy: 0.8576 - val_loss: 0.4307 - val_accuracy: 0.8594\n",
            "Epoch 618/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4124 - accuracy: 0.8631 - val_loss: 0.4036 - val_accuracy: 0.8713\n",
            "Epoch 619/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4177 - accuracy: 0.8581 - val_loss: 0.4446 - val_accuracy: 0.8546\n",
            "Epoch 620/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4168 - accuracy: 0.8581 - val_loss: 0.4152 - val_accuracy: 0.8594\n",
            "Epoch 621/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4033 - accuracy: 0.8685 - val_loss: 0.4274 - val_accuracy: 0.8486\n",
            "Epoch 622/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4070 - accuracy: 0.8657 - val_loss: 0.3993 - val_accuracy: 0.8629\n",
            "Epoch 623/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.4083 - accuracy: 0.8616 - val_loss: 0.3939 - val_accuracy: 0.8701\n",
            "Epoch 624/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4007 - accuracy: 0.8716 - val_loss: 0.4143 - val_accuracy: 0.8677\n",
            "Epoch 625/1500\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.4066 - accuracy: 0.8650 - val_loss: 0.4101 - val_accuracy: 0.8617\n",
            "Epoch 626/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4200 - accuracy: 0.8595 - val_loss: 0.3922 - val_accuracy: 0.8760\n",
            "Epoch 627/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3986 - accuracy: 0.8693 - val_loss: 0.4001 - val_accuracy: 0.8653\n",
            "Epoch 628/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3963 - accuracy: 0.8707 - val_loss: 0.3916 - val_accuracy: 0.8737\n",
            "Epoch 629/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.3965 - accuracy: 0.8724 - val_loss: 0.4220 - val_accuracy: 0.8582\n",
            "Epoch 630/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4079 - accuracy: 0.8640 - val_loss: 0.4108 - val_accuracy: 0.8594\n",
            "Epoch 631/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4131 - accuracy: 0.8581 - val_loss: 0.4022 - val_accuracy: 0.8617\n",
            "Epoch 632/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4113 - accuracy: 0.8593 - val_loss: 0.4899 - val_accuracy: 0.8188\n",
            "Epoch 633/1500\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.4466 - accuracy: 0.8454 - val_loss: 0.4087 - val_accuracy: 0.8641\n",
            "Epoch 634/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4063 - accuracy: 0.8664 - val_loss: 0.3953 - val_accuracy: 0.8796\n",
            "Epoch 635/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4160 - accuracy: 0.8595 - val_loss: 0.4052 - val_accuracy: 0.8641\n",
            "Epoch 636/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4017 - accuracy: 0.8645 - val_loss: 0.3926 - val_accuracy: 0.8760\n",
            "Epoch 637/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.3981 - accuracy: 0.8673 - val_loss: 0.4592 - val_accuracy: 0.8343\n",
            "Epoch 638/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4195 - accuracy: 0.8545 - val_loss: 0.4258 - val_accuracy: 0.8522\n",
            "Epoch 639/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4107 - accuracy: 0.8581 - val_loss: 0.3846 - val_accuracy: 0.8749\n",
            "Epoch 640/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4038 - accuracy: 0.8640 - val_loss: 0.4166 - val_accuracy: 0.8629\n",
            "Epoch 641/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4087 - accuracy: 0.8597 - val_loss: 0.3944 - val_accuracy: 0.8856\n",
            "Epoch 642/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4018 - accuracy: 0.8633 - val_loss: 0.3905 - val_accuracy: 0.8725\n",
            "Epoch 643/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4033 - accuracy: 0.8645 - val_loss: 0.3897 - val_accuracy: 0.8665\n",
            "Epoch 644/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3898 - accuracy: 0.8747 - val_loss: 0.4194 - val_accuracy: 0.8582\n",
            "Epoch 645/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4113 - accuracy: 0.8573 - val_loss: 0.3950 - val_accuracy: 0.8677\n",
            "Epoch 646/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4000 - accuracy: 0.8716 - val_loss: 0.4145 - val_accuracy: 0.8701\n",
            "Epoch 647/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4124 - accuracy: 0.8583 - val_loss: 0.4115 - val_accuracy: 0.8605\n",
            "Epoch 648/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4044 - accuracy: 0.8628 - val_loss: 0.4101 - val_accuracy: 0.8522\n",
            "Epoch 649/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4009 - accuracy: 0.8652 - val_loss: 0.4156 - val_accuracy: 0.8558\n",
            "Epoch 650/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4006 - accuracy: 0.8650 - val_loss: 0.3844 - val_accuracy: 0.8808\n",
            "Epoch 651/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3953 - accuracy: 0.8664 - val_loss: 0.3926 - val_accuracy: 0.8725\n",
            "Epoch 652/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3921 - accuracy: 0.8678 - val_loss: 0.3914 - val_accuracy: 0.8701\n",
            "Epoch 653/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.4123 - accuracy: 0.8621 - val_loss: 0.4116 - val_accuracy: 0.8749\n",
            "Epoch 654/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3978 - accuracy: 0.8673 - val_loss: 0.3786 - val_accuracy: 0.8856\n",
            "Epoch 655/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4020 - accuracy: 0.8602 - val_loss: 0.3762 - val_accuracy: 0.8796\n",
            "Epoch 656/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3910 - accuracy: 0.8676 - val_loss: 0.3773 - val_accuracy: 0.8844\n",
            "Epoch 657/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.3917 - accuracy: 0.8712 - val_loss: 0.3793 - val_accuracy: 0.8689\n",
            "Epoch 658/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3859 - accuracy: 0.8721 - val_loss: 0.3749 - val_accuracy: 0.8868\n",
            "Epoch 659/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3850 - accuracy: 0.8726 - val_loss: 0.3823 - val_accuracy: 0.8880\n",
            "Epoch 660/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3905 - accuracy: 0.8693 - val_loss: 0.3861 - val_accuracy: 0.8641\n",
            "Epoch 661/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.3948 - accuracy: 0.8704 - val_loss: 0.3843 - val_accuracy: 0.8749\n",
            "Epoch 662/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3955 - accuracy: 0.8666 - val_loss: 0.3797 - val_accuracy: 0.8760\n",
            "Epoch 663/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4051 - accuracy: 0.8588 - val_loss: 0.4297 - val_accuracy: 0.8439\n",
            "Epoch 664/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4021 - accuracy: 0.8673 - val_loss: 0.3867 - val_accuracy: 0.8808\n",
            "Epoch 665/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4173 - accuracy: 0.8585 - val_loss: 0.3979 - val_accuracy: 0.8701\n",
            "Epoch 666/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3975 - accuracy: 0.8638 - val_loss: 0.3844 - val_accuracy: 0.8784\n",
            "Epoch 667/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3880 - accuracy: 0.8697 - val_loss: 0.3848 - val_accuracy: 0.8653\n",
            "Epoch 668/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3873 - accuracy: 0.8695 - val_loss: 0.3760 - val_accuracy: 0.8832\n",
            "Epoch 669/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.3979 - accuracy: 0.8647 - val_loss: 0.3911 - val_accuracy: 0.8701\n",
            "Epoch 670/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3926 - accuracy: 0.8666 - val_loss: 0.4136 - val_accuracy: 0.8605\n",
            "Epoch 671/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3950 - accuracy: 0.8697 - val_loss: 0.3690 - val_accuracy: 0.8856\n",
            "Epoch 672/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.3845 - accuracy: 0.8724 - val_loss: 0.4227 - val_accuracy: 0.8522\n",
            "Epoch 673/1500\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 0.3980 - accuracy: 0.8654 - val_loss: 0.3886 - val_accuracy: 0.8749\n",
            "Epoch 674/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3947 - accuracy: 0.8671 - val_loss: 0.3799 - val_accuracy: 0.8772\n",
            "Epoch 675/1500\n",
            "9/9 [==============================] - 1s 140ms/step - loss: 0.3850 - accuracy: 0.8697 - val_loss: 0.3846 - val_accuracy: 0.8796\n",
            "Epoch 676/1500\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.3915 - accuracy: 0.8707 - val_loss: 0.3789 - val_accuracy: 0.8844\n",
            "Epoch 677/1500\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.3783 - accuracy: 0.8762 - val_loss: 0.3690 - val_accuracy: 0.8796\n",
            "Epoch 678/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3816 - accuracy: 0.8721 - val_loss: 0.3949 - val_accuracy: 0.8546\n",
            "Epoch 679/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3950 - accuracy: 0.8597 - val_loss: 0.3814 - val_accuracy: 0.8808\n",
            "Epoch 680/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3853 - accuracy: 0.8731 - val_loss: 0.3903 - val_accuracy: 0.8641\n",
            "Epoch 681/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3813 - accuracy: 0.8757 - val_loss: 0.3706 - val_accuracy: 0.8880\n",
            "Epoch 682/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3870 - accuracy: 0.8685 - val_loss: 0.4009 - val_accuracy: 0.8617\n",
            "Epoch 683/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3979 - accuracy: 0.8647 - val_loss: 0.3724 - val_accuracy: 0.8868\n",
            "Epoch 684/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3947 - accuracy: 0.8688 - val_loss: 0.4147 - val_accuracy: 0.8427\n",
            "Epoch 685/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4185 - accuracy: 0.8595 - val_loss: 0.3867 - val_accuracy: 0.8713\n",
            "Epoch 686/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4037 - accuracy: 0.8623 - val_loss: 0.3740 - val_accuracy: 0.8856\n",
            "Epoch 687/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3844 - accuracy: 0.8688 - val_loss: 0.3955 - val_accuracy: 0.8749\n",
            "Epoch 688/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3931 - accuracy: 0.8683 - val_loss: 0.3683 - val_accuracy: 0.8772\n",
            "Epoch 689/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3926 - accuracy: 0.8669 - val_loss: 0.3856 - val_accuracy: 0.8641\n",
            "Epoch 690/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3926 - accuracy: 0.8643 - val_loss: 0.3966 - val_accuracy: 0.8713\n",
            "Epoch 691/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4106 - accuracy: 0.8588 - val_loss: 0.4197 - val_accuracy: 0.8570\n",
            "Epoch 692/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3992 - accuracy: 0.8643 - val_loss: 0.4526 - val_accuracy: 0.8379\n",
            "Epoch 693/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.4235 - accuracy: 0.8526 - val_loss: 0.4683 - val_accuracy: 0.8236\n",
            "Epoch 694/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4247 - accuracy: 0.8554 - val_loss: 0.4212 - val_accuracy: 0.8510\n",
            "Epoch 695/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4116 - accuracy: 0.8564 - val_loss: 0.3990 - val_accuracy: 0.8486\n",
            "Epoch 696/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4233 - accuracy: 0.8557 - val_loss: 0.4014 - val_accuracy: 0.8594\n",
            "Epoch 697/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4136 - accuracy: 0.8512 - val_loss: 0.3847 - val_accuracy: 0.8713\n",
            "Epoch 698/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3952 - accuracy: 0.8621 - val_loss: 0.3802 - val_accuracy: 0.8725\n",
            "Epoch 699/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3939 - accuracy: 0.8652 - val_loss: 0.4015 - val_accuracy: 0.8629\n",
            "Epoch 700/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.3966 - accuracy: 0.8652 - val_loss: 0.3861 - val_accuracy: 0.8772\n",
            "Epoch 701/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3878 - accuracy: 0.8716 - val_loss: 0.3699 - val_accuracy: 0.8832\n",
            "Epoch 702/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3779 - accuracy: 0.8731 - val_loss: 0.3772 - val_accuracy: 0.8725\n",
            "Epoch 703/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3838 - accuracy: 0.8712 - val_loss: 0.3991 - val_accuracy: 0.8629\n",
            "Epoch 704/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3785 - accuracy: 0.8697 - val_loss: 0.3657 - val_accuracy: 0.8772\n",
            "Epoch 705/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.3804 - accuracy: 0.8724 - val_loss: 0.3921 - val_accuracy: 0.8653\n",
            "Epoch 706/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3852 - accuracy: 0.8666 - val_loss: 0.4004 - val_accuracy: 0.8570\n",
            "Epoch 707/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3838 - accuracy: 0.8724 - val_loss: 0.4238 - val_accuracy: 0.8522\n",
            "Epoch 708/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.4118 - accuracy: 0.8571 - val_loss: 0.4236 - val_accuracy: 0.8546\n",
            "Epoch 709/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3929 - accuracy: 0.8697 - val_loss: 0.3768 - val_accuracy: 0.8725\n",
            "Epoch 710/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3787 - accuracy: 0.8731 - val_loss: 0.3712 - val_accuracy: 0.8784\n",
            "Epoch 711/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3728 - accuracy: 0.8752 - val_loss: 0.3948 - val_accuracy: 0.8558\n",
            "Epoch 712/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3917 - accuracy: 0.8654 - val_loss: 0.3911 - val_accuracy: 0.8689\n",
            "Epoch 713/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3942 - accuracy: 0.8678 - val_loss: 0.4012 - val_accuracy: 0.8594\n",
            "Epoch 714/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3806 - accuracy: 0.8709 - val_loss: 0.3732 - val_accuracy: 0.8808\n",
            "Epoch 715/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3794 - accuracy: 0.8704 - val_loss: 0.3917 - val_accuracy: 0.8665\n",
            "Epoch 716/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3917 - accuracy: 0.8643 - val_loss: 0.3864 - val_accuracy: 0.8689\n",
            "Epoch 717/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3869 - accuracy: 0.8635 - val_loss: 0.3746 - val_accuracy: 0.8760\n",
            "Epoch 718/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3748 - accuracy: 0.8747 - val_loss: 0.3669 - val_accuracy: 0.8808\n",
            "Epoch 719/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3762 - accuracy: 0.8731 - val_loss: 0.3763 - val_accuracy: 0.8737\n",
            "Epoch 720/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3838 - accuracy: 0.8683 - val_loss: 0.3848 - val_accuracy: 0.8677\n",
            "Epoch 721/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3873 - accuracy: 0.8685 - val_loss: 0.3805 - val_accuracy: 0.8665\n",
            "Epoch 722/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3874 - accuracy: 0.8659 - val_loss: 0.3750 - val_accuracy: 0.8784\n",
            "Epoch 723/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3864 - accuracy: 0.8643 - val_loss: 0.3762 - val_accuracy: 0.8737\n",
            "Epoch 724/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3816 - accuracy: 0.8645 - val_loss: 0.3975 - val_accuracy: 0.8677\n",
            "Epoch 725/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3937 - accuracy: 0.8597 - val_loss: 0.4276 - val_accuracy: 0.8474\n",
            "Epoch 726/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3958 - accuracy: 0.8619 - val_loss: 0.3830 - val_accuracy: 0.8605\n",
            "Epoch 727/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3891 - accuracy: 0.8647 - val_loss: 0.3704 - val_accuracy: 0.8725\n",
            "Epoch 728/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3907 - accuracy: 0.8657 - val_loss: 0.3836 - val_accuracy: 0.8701\n",
            "Epoch 729/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3939 - accuracy: 0.8633 - val_loss: 0.4009 - val_accuracy: 0.8594\n",
            "Epoch 730/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3840 - accuracy: 0.8681 - val_loss: 0.3743 - val_accuracy: 0.8725\n",
            "Epoch 731/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3800 - accuracy: 0.8697 - val_loss: 0.3501 - val_accuracy: 0.8880\n",
            "Epoch 732/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3654 - accuracy: 0.8769 - val_loss: 0.3632 - val_accuracy: 0.8832\n",
            "Epoch 733/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3657 - accuracy: 0.8785 - val_loss: 0.3527 - val_accuracy: 0.8903\n",
            "Epoch 734/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3677 - accuracy: 0.8774 - val_loss: 0.3653 - val_accuracy: 0.8784\n",
            "Epoch 735/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3707 - accuracy: 0.8774 - val_loss: 0.3714 - val_accuracy: 0.8701\n",
            "Epoch 736/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3763 - accuracy: 0.8697 - val_loss: 0.3661 - val_accuracy: 0.8808\n",
            "Epoch 737/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3664 - accuracy: 0.8759 - val_loss: 0.3668 - val_accuracy: 0.8796\n",
            "Epoch 738/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3663 - accuracy: 0.8764 - val_loss: 0.3760 - val_accuracy: 0.8689\n",
            "Epoch 739/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3688 - accuracy: 0.8781 - val_loss: 0.3506 - val_accuracy: 0.8832\n",
            "Epoch 740/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3665 - accuracy: 0.8783 - val_loss: 0.3599 - val_accuracy: 0.8808\n",
            "Epoch 741/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3668 - accuracy: 0.8728 - val_loss: 0.3546 - val_accuracy: 0.8880\n",
            "Epoch 742/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3638 - accuracy: 0.8790 - val_loss: 0.4423 - val_accuracy: 0.8379\n",
            "Epoch 743/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4091 - accuracy: 0.8562 - val_loss: 0.3787 - val_accuracy: 0.8772\n",
            "Epoch 744/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3758 - accuracy: 0.8724 - val_loss: 0.3832 - val_accuracy: 0.8653\n",
            "Epoch 745/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3744 - accuracy: 0.8750 - val_loss: 0.3596 - val_accuracy: 0.8832\n",
            "Epoch 746/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3667 - accuracy: 0.8774 - val_loss: 0.3893 - val_accuracy: 0.8594\n",
            "Epoch 747/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3726 - accuracy: 0.8745 - val_loss: 0.3534 - val_accuracy: 0.8701\n",
            "Epoch 748/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3668 - accuracy: 0.8752 - val_loss: 0.3525 - val_accuracy: 0.8808\n",
            "Epoch 749/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3754 - accuracy: 0.8712 - val_loss: 0.4136 - val_accuracy: 0.8451\n",
            "Epoch 750/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3991 - accuracy: 0.8597 - val_loss: 0.4331 - val_accuracy: 0.8486\n",
            "Epoch 751/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.4118 - accuracy: 0.8514 - val_loss: 0.3810 - val_accuracy: 0.8570\n",
            "Epoch 752/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3809 - accuracy: 0.8643 - val_loss: 0.3563 - val_accuracy: 0.8808\n",
            "Epoch 753/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3662 - accuracy: 0.8809 - val_loss: 0.3824 - val_accuracy: 0.8725\n",
            "Epoch 754/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.3676 - accuracy: 0.8728 - val_loss: 0.3738 - val_accuracy: 0.8725\n",
            "Epoch 755/1500\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.3701 - accuracy: 0.8783 - val_loss: 0.3704 - val_accuracy: 0.8796\n",
            "Epoch 756/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3774 - accuracy: 0.8740 - val_loss: 0.3836 - val_accuracy: 0.8558\n",
            "Epoch 757/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3727 - accuracy: 0.8726 - val_loss: 0.3920 - val_accuracy: 0.8725\n",
            "Epoch 758/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3788 - accuracy: 0.8707 - val_loss: 0.3677 - val_accuracy: 0.8749\n",
            "Epoch 759/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3686 - accuracy: 0.8721 - val_loss: 0.3740 - val_accuracy: 0.8713\n",
            "Epoch 760/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3719 - accuracy: 0.8697 - val_loss: 0.3529 - val_accuracy: 0.8903\n",
            "Epoch 761/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3658 - accuracy: 0.8788 - val_loss: 0.3565 - val_accuracy: 0.8796\n",
            "Epoch 762/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3550 - accuracy: 0.8826 - val_loss: 0.3602 - val_accuracy: 0.8808\n",
            "Epoch 763/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3576 - accuracy: 0.8764 - val_loss: 0.3943 - val_accuracy: 0.8665\n",
            "Epoch 764/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3985 - accuracy: 0.8628 - val_loss: 0.3913 - val_accuracy: 0.8629\n",
            "Epoch 765/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3845 - accuracy: 0.8626 - val_loss: 0.3784 - val_accuracy: 0.8737\n",
            "Epoch 766/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3655 - accuracy: 0.8757 - val_loss: 0.3712 - val_accuracy: 0.8713\n",
            "Epoch 767/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3793 - accuracy: 0.8685 - val_loss: 0.3861 - val_accuracy: 0.8725\n",
            "Epoch 768/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3872 - accuracy: 0.8685 - val_loss: 0.3737 - val_accuracy: 0.8772\n",
            "Epoch 769/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3896 - accuracy: 0.8685 - val_loss: 0.3453 - val_accuracy: 0.8927\n",
            "Epoch 770/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3699 - accuracy: 0.8802 - val_loss: 0.3939 - val_accuracy: 0.8582\n",
            "Epoch 771/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3844 - accuracy: 0.8695 - val_loss: 0.3662 - val_accuracy: 0.8665\n",
            "Epoch 772/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3794 - accuracy: 0.8685 - val_loss: 0.3550 - val_accuracy: 0.8820\n",
            "Epoch 773/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3692 - accuracy: 0.8721 - val_loss: 0.3566 - val_accuracy: 0.8772\n",
            "Epoch 774/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3652 - accuracy: 0.8800 - val_loss: 0.3634 - val_accuracy: 0.8796\n",
            "Epoch 775/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3585 - accuracy: 0.8795 - val_loss: 0.3712 - val_accuracy: 0.8725\n",
            "Epoch 776/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3614 - accuracy: 0.8771 - val_loss: 0.3537 - val_accuracy: 0.8820\n",
            "Epoch 777/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3831 - accuracy: 0.8657 - val_loss: 0.3635 - val_accuracy: 0.8844\n",
            "Epoch 778/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3757 - accuracy: 0.8685 - val_loss: 0.3575 - val_accuracy: 0.8737\n",
            "Epoch 779/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3592 - accuracy: 0.8783 - val_loss: 0.3633 - val_accuracy: 0.8725\n",
            "Epoch 780/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3594 - accuracy: 0.8774 - val_loss: 0.4056 - val_accuracy: 0.8570\n",
            "Epoch 781/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3749 - accuracy: 0.8704 - val_loss: 0.3801 - val_accuracy: 0.8760\n",
            "Epoch 782/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3803 - accuracy: 0.8640 - val_loss: 0.3648 - val_accuracy: 0.8856\n",
            "Epoch 783/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3680 - accuracy: 0.8704 - val_loss: 0.3580 - val_accuracy: 0.8772\n",
            "Epoch 784/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3659 - accuracy: 0.8735 - val_loss: 0.3585 - val_accuracy: 0.8677\n",
            "Epoch 785/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3733 - accuracy: 0.8666 - val_loss: 0.3661 - val_accuracy: 0.8772\n",
            "Epoch 786/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3731 - accuracy: 0.8754 - val_loss: 0.3772 - val_accuracy: 0.8677\n",
            "Epoch 787/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3696 - accuracy: 0.8707 - val_loss: 0.3772 - val_accuracy: 0.8641\n",
            "Epoch 788/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3737 - accuracy: 0.8693 - val_loss: 0.3980 - val_accuracy: 0.8629\n",
            "Epoch 789/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3700 - accuracy: 0.8700 - val_loss: 0.3490 - val_accuracy: 0.8820\n",
            "Epoch 790/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3644 - accuracy: 0.8754 - val_loss: 0.4126 - val_accuracy: 0.8427\n",
            "Epoch 791/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3897 - accuracy: 0.8638 - val_loss: 0.3695 - val_accuracy: 0.8713\n",
            "Epoch 792/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3724 - accuracy: 0.8721 - val_loss: 0.3587 - val_accuracy: 0.8772\n",
            "Epoch 793/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3627 - accuracy: 0.8733 - val_loss: 0.3527 - val_accuracy: 0.8880\n",
            "Epoch 794/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3603 - accuracy: 0.8769 - val_loss: 0.3560 - val_accuracy: 0.8796\n",
            "Epoch 795/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3732 - accuracy: 0.8697 - val_loss: 0.3709 - val_accuracy: 0.8749\n",
            "Epoch 796/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3684 - accuracy: 0.8740 - val_loss: 0.3581 - val_accuracy: 0.8808\n",
            "Epoch 797/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3634 - accuracy: 0.8759 - val_loss: 0.3507 - val_accuracy: 0.8844\n",
            "Epoch 798/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3548 - accuracy: 0.8819 - val_loss: 0.3503 - val_accuracy: 0.8856\n",
            "Epoch 799/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3513 - accuracy: 0.8819 - val_loss: 0.3439 - val_accuracy: 0.8892\n",
            "Epoch 800/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3552 - accuracy: 0.8783 - val_loss: 0.3600 - val_accuracy: 0.8677\n",
            "Epoch 801/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3592 - accuracy: 0.8731 - val_loss: 0.3460 - val_accuracy: 0.8820\n",
            "Epoch 802/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3542 - accuracy: 0.8804 - val_loss: 0.3663 - val_accuracy: 0.8701\n",
            "Epoch 803/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3684 - accuracy: 0.8771 - val_loss: 0.3552 - val_accuracy: 0.8713\n",
            "Epoch 804/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3878 - accuracy: 0.8666 - val_loss: 0.3616 - val_accuracy: 0.8760\n",
            "Epoch 805/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3897 - accuracy: 0.8647 - val_loss: 0.3798 - val_accuracy: 0.8582\n",
            "Epoch 806/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3679 - accuracy: 0.8719 - val_loss: 0.3917 - val_accuracy: 0.8629\n",
            "Epoch 807/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3724 - accuracy: 0.8671 - val_loss: 0.3481 - val_accuracy: 0.8856\n",
            "Epoch 808/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3712 - accuracy: 0.8764 - val_loss: 0.3667 - val_accuracy: 0.8749\n",
            "Epoch 809/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3640 - accuracy: 0.8743 - val_loss: 0.3561 - val_accuracy: 0.8820\n",
            "Epoch 810/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3620 - accuracy: 0.8757 - val_loss: 0.3558 - val_accuracy: 0.8760\n",
            "Epoch 811/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3546 - accuracy: 0.8816 - val_loss: 0.3554 - val_accuracy: 0.8796\n",
            "Epoch 812/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3597 - accuracy: 0.8762 - val_loss: 0.3689 - val_accuracy: 0.8725\n",
            "Epoch 813/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3675 - accuracy: 0.8719 - val_loss: 0.3550 - val_accuracy: 0.8832\n",
            "Epoch 814/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3699 - accuracy: 0.8681 - val_loss: 0.3517 - val_accuracy: 0.8868\n",
            "Epoch 815/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3641 - accuracy: 0.8764 - val_loss: 0.3765 - val_accuracy: 0.8605\n",
            "Epoch 816/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3765 - accuracy: 0.8638 - val_loss: 0.4042 - val_accuracy: 0.8439\n",
            "Epoch 817/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3813 - accuracy: 0.8621 - val_loss: 0.3781 - val_accuracy: 0.8594\n",
            "Epoch 818/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3705 - accuracy: 0.8750 - val_loss: 0.4148 - val_accuracy: 0.8641\n",
            "Epoch 819/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3802 - accuracy: 0.8645 - val_loss: 0.3526 - val_accuracy: 0.8832\n",
            "Epoch 820/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3686 - accuracy: 0.8728 - val_loss: 0.4034 - val_accuracy: 0.8582\n",
            "Epoch 821/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4702 - accuracy: 0.8452 - val_loss: 0.4102 - val_accuracy: 0.8474\n",
            "Epoch 822/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.4030 - accuracy: 0.8545 - val_loss: 0.3660 - val_accuracy: 0.8772\n",
            "Epoch 823/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3710 - accuracy: 0.8785 - val_loss: 0.3381 - val_accuracy: 0.8856\n",
            "Epoch 824/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3630 - accuracy: 0.8776 - val_loss: 0.3506 - val_accuracy: 0.8784\n",
            "Epoch 825/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3611 - accuracy: 0.8812 - val_loss: 0.3417 - val_accuracy: 0.8880\n",
            "Epoch 826/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3577 - accuracy: 0.8733 - val_loss: 0.3570 - val_accuracy: 0.8820\n",
            "Epoch 827/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3609 - accuracy: 0.8774 - val_loss: 0.3306 - val_accuracy: 0.8939\n",
            "Epoch 828/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3502 - accuracy: 0.8852 - val_loss: 0.3464 - val_accuracy: 0.8844\n",
            "Epoch 829/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3576 - accuracy: 0.8790 - val_loss: 0.3610 - val_accuracy: 0.8772\n",
            "Epoch 830/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3765 - accuracy: 0.8743 - val_loss: 0.3526 - val_accuracy: 0.8737\n",
            "Epoch 831/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3735 - accuracy: 0.8704 - val_loss: 0.3610 - val_accuracy: 0.8713\n",
            "Epoch 832/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3501 - accuracy: 0.8835 - val_loss: 0.3589 - val_accuracy: 0.8760\n",
            "Epoch 833/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3512 - accuracy: 0.8807 - val_loss: 0.3456 - val_accuracy: 0.8808\n",
            "Epoch 834/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3664 - accuracy: 0.8750 - val_loss: 0.3369 - val_accuracy: 0.8915\n",
            "Epoch 835/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3546 - accuracy: 0.8776 - val_loss: 0.3543 - val_accuracy: 0.8760\n",
            "Epoch 836/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3549 - accuracy: 0.8754 - val_loss: 0.3499 - val_accuracy: 0.8784\n",
            "Epoch 837/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3504 - accuracy: 0.8819 - val_loss: 0.3277 - val_accuracy: 0.8927\n",
            "Epoch 838/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3448 - accuracy: 0.8850 - val_loss: 0.3373 - val_accuracy: 0.8951\n",
            "Epoch 839/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3521 - accuracy: 0.8766 - val_loss: 0.3656 - val_accuracy: 0.8701\n",
            "Epoch 840/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3674 - accuracy: 0.8759 - val_loss: 0.3441 - val_accuracy: 0.8844\n",
            "Epoch 841/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3523 - accuracy: 0.8793 - val_loss: 0.3434 - val_accuracy: 0.8772\n",
            "Epoch 842/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3835 - accuracy: 0.8650 - val_loss: 0.3725 - val_accuracy: 0.8594\n",
            "Epoch 843/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3774 - accuracy: 0.8693 - val_loss: 0.3450 - val_accuracy: 0.8832\n",
            "Epoch 844/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3782 - accuracy: 0.8654 - val_loss: 0.4288 - val_accuracy: 0.8582\n",
            "Epoch 845/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3835 - accuracy: 0.8643 - val_loss: 0.3906 - val_accuracy: 0.8629\n",
            "Epoch 846/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3626 - accuracy: 0.8795 - val_loss: 0.3612 - val_accuracy: 0.8737\n",
            "Epoch 847/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3480 - accuracy: 0.8800 - val_loss: 0.3672 - val_accuracy: 0.8689\n",
            "Epoch 848/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3586 - accuracy: 0.8785 - val_loss: 0.3410 - val_accuracy: 0.8939\n",
            "Epoch 849/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3440 - accuracy: 0.8816 - val_loss: 0.3354 - val_accuracy: 0.8880\n",
            "Epoch 850/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3421 - accuracy: 0.8857 - val_loss: 0.3365 - val_accuracy: 0.8760\n",
            "Epoch 851/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3458 - accuracy: 0.8847 - val_loss: 0.3552 - val_accuracy: 0.8832\n",
            "Epoch 852/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3694 - accuracy: 0.8700 - val_loss: 0.3521 - val_accuracy: 0.8844\n",
            "Epoch 853/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3721 - accuracy: 0.8721 - val_loss: 0.4137 - val_accuracy: 0.8498\n",
            "Epoch 854/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3805 - accuracy: 0.8616 - val_loss: 0.3943 - val_accuracy: 0.8546\n",
            "Epoch 855/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3652 - accuracy: 0.8702 - val_loss: 0.4166 - val_accuracy: 0.8427\n",
            "Epoch 856/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3745 - accuracy: 0.8676 - val_loss: 0.3616 - val_accuracy: 0.8784\n",
            "Epoch 857/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3672 - accuracy: 0.8690 - val_loss: 0.3480 - val_accuracy: 0.8820\n",
            "Epoch 858/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3474 - accuracy: 0.8809 - val_loss: 0.3376 - val_accuracy: 0.8844\n",
            "Epoch 859/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3481 - accuracy: 0.8774 - val_loss: 0.3399 - val_accuracy: 0.8832\n",
            "Epoch 860/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3383 - accuracy: 0.8850 - val_loss: 0.3253 - val_accuracy: 0.8927\n",
            "Epoch 861/1500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.3385 - accuracy: 0.8843 - val_loss: 0.3381 - val_accuracy: 0.8868\n",
            "Epoch 862/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3523 - accuracy: 0.8769 - val_loss: 0.3476 - val_accuracy: 0.8784\n",
            "Epoch 863/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3596 - accuracy: 0.8754 - val_loss: 0.3543 - val_accuracy: 0.8725\n",
            "Epoch 864/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3477 - accuracy: 0.8824 - val_loss: 0.3316 - val_accuracy: 0.8939\n",
            "Epoch 865/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3398 - accuracy: 0.8816 - val_loss: 0.3470 - val_accuracy: 0.8772\n",
            "Epoch 866/1500\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.3485 - accuracy: 0.8793 - val_loss: 0.3703 - val_accuracy: 0.8594\n",
            "Epoch 867/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3557 - accuracy: 0.8745 - val_loss: 0.3482 - val_accuracy: 0.8832\n",
            "Epoch 868/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3514 - accuracy: 0.8762 - val_loss: 0.3334 - val_accuracy: 0.8927\n",
            "Epoch 869/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3476 - accuracy: 0.8812 - val_loss: 0.3430 - val_accuracy: 0.8927\n",
            "Epoch 870/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3540 - accuracy: 0.8845 - val_loss: 0.3310 - val_accuracy: 0.8951\n",
            "Epoch 871/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3486 - accuracy: 0.8802 - val_loss: 0.3468 - val_accuracy: 0.8784\n",
            "Epoch 872/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3413 - accuracy: 0.8850 - val_loss: 0.3379 - val_accuracy: 0.8820\n",
            "Epoch 873/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3333 - accuracy: 0.8869 - val_loss: 0.3400 - val_accuracy: 0.8856\n",
            "Epoch 874/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3337 - accuracy: 0.8859 - val_loss: 0.3432 - val_accuracy: 0.8820\n",
            "Epoch 875/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3558 - accuracy: 0.8783 - val_loss: 0.3429 - val_accuracy: 0.8832\n",
            "Epoch 876/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3462 - accuracy: 0.8809 - val_loss: 0.3523 - val_accuracy: 0.8772\n",
            "Epoch 877/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3425 - accuracy: 0.8802 - val_loss: 0.3395 - val_accuracy: 0.8832\n",
            "Epoch 878/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3406 - accuracy: 0.8871 - val_loss: 0.3292 - val_accuracy: 0.8903\n",
            "Epoch 879/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3401 - accuracy: 0.8874 - val_loss: 0.3339 - val_accuracy: 0.8844\n",
            "Epoch 880/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3345 - accuracy: 0.8871 - val_loss: 0.3298 - val_accuracy: 0.8939\n",
            "Epoch 881/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3392 - accuracy: 0.8852 - val_loss: 0.3312 - val_accuracy: 0.8856\n",
            "Epoch 882/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3436 - accuracy: 0.8793 - val_loss: 0.3312 - val_accuracy: 0.8903\n",
            "Epoch 883/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3401 - accuracy: 0.8793 - val_loss: 0.3300 - val_accuracy: 0.8903\n",
            "Epoch 884/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3400 - accuracy: 0.8840 - val_loss: 0.3667 - val_accuracy: 0.8641\n",
            "Epoch 885/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3506 - accuracy: 0.8735 - val_loss: 0.3400 - val_accuracy: 0.8808\n",
            "Epoch 886/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3535 - accuracy: 0.8754 - val_loss: 0.3351 - val_accuracy: 0.8856\n",
            "Epoch 887/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3498 - accuracy: 0.8759 - val_loss: 0.3515 - val_accuracy: 0.8808\n",
            "Epoch 888/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3473 - accuracy: 0.8859 - val_loss: 0.3390 - val_accuracy: 0.8880\n",
            "Epoch 889/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3432 - accuracy: 0.8852 - val_loss: 0.3476 - val_accuracy: 0.8880\n",
            "Epoch 890/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3406 - accuracy: 0.8821 - val_loss: 0.3222 - val_accuracy: 0.8951\n",
            "Epoch 891/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3445 - accuracy: 0.8793 - val_loss: 0.3344 - val_accuracy: 0.8820\n",
            "Epoch 892/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3453 - accuracy: 0.8797 - val_loss: 0.3575 - val_accuracy: 0.8689\n",
            "Epoch 893/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3505 - accuracy: 0.8762 - val_loss: 0.3433 - val_accuracy: 0.8820\n",
            "Epoch 894/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3453 - accuracy: 0.8831 - val_loss: 0.3615 - val_accuracy: 0.8677\n",
            "Epoch 895/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3424 - accuracy: 0.8821 - val_loss: 0.3560 - val_accuracy: 0.8689\n",
            "Epoch 896/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3459 - accuracy: 0.8785 - val_loss: 0.3358 - val_accuracy: 0.8868\n",
            "Epoch 897/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3449 - accuracy: 0.8797 - val_loss: 0.3642 - val_accuracy: 0.8665\n",
            "Epoch 898/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3470 - accuracy: 0.8738 - val_loss: 0.3417 - val_accuracy: 0.8737\n",
            "Epoch 899/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3369 - accuracy: 0.8831 - val_loss: 0.3308 - val_accuracy: 0.8880\n",
            "Epoch 900/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3350 - accuracy: 0.8850 - val_loss: 0.3520 - val_accuracy: 0.8737\n",
            "Epoch 901/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3453 - accuracy: 0.8797 - val_loss: 0.3466 - val_accuracy: 0.8772\n",
            "Epoch 902/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3492 - accuracy: 0.8745 - val_loss: 0.3887 - val_accuracy: 0.8582\n",
            "Epoch 903/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3656 - accuracy: 0.8740 - val_loss: 0.3965 - val_accuracy: 0.8522\n",
            "Epoch 904/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3746 - accuracy: 0.8721 - val_loss: 0.3499 - val_accuracy: 0.8772\n",
            "Epoch 905/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3591 - accuracy: 0.8728 - val_loss: 0.3404 - val_accuracy: 0.8844\n",
            "Epoch 906/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3445 - accuracy: 0.8807 - val_loss: 0.3503 - val_accuracy: 0.8772\n",
            "Epoch 907/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3493 - accuracy: 0.8824 - val_loss: 0.3926 - val_accuracy: 0.8629\n",
            "Epoch 908/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3771 - accuracy: 0.8702 - val_loss: 0.3321 - val_accuracy: 0.8892\n",
            "Epoch 909/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3631 - accuracy: 0.8740 - val_loss: 0.3379 - val_accuracy: 0.8796\n",
            "Epoch 910/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3414 - accuracy: 0.8826 - val_loss: 0.3375 - val_accuracy: 0.8760\n",
            "Epoch 911/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3322 - accuracy: 0.8881 - val_loss: 0.3362 - val_accuracy: 0.8772\n",
            "Epoch 912/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3319 - accuracy: 0.8840 - val_loss: 0.3369 - val_accuracy: 0.8880\n",
            "Epoch 913/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3466 - accuracy: 0.8795 - val_loss: 0.3304 - val_accuracy: 0.8868\n",
            "Epoch 914/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3376 - accuracy: 0.8862 - val_loss: 0.3355 - val_accuracy: 0.8844\n",
            "Epoch 915/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.3416 - accuracy: 0.8809 - val_loss: 0.3534 - val_accuracy: 0.8689\n",
            "Epoch 916/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3350 - accuracy: 0.8869 - val_loss: 0.3169 - val_accuracy: 0.8999\n",
            "Epoch 917/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3352 - accuracy: 0.8859 - val_loss: 0.3452 - val_accuracy: 0.8832\n",
            "Epoch 918/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3632 - accuracy: 0.8716 - val_loss: 0.3698 - val_accuracy: 0.8617\n",
            "Epoch 919/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3800 - accuracy: 0.8666 - val_loss: 0.4584 - val_accuracy: 0.8415\n",
            "Epoch 920/1500\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.4019 - accuracy: 0.8557 - val_loss: 0.3920 - val_accuracy: 0.8582\n",
            "Epoch 921/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3677 - accuracy: 0.8716 - val_loss: 0.3257 - val_accuracy: 0.8915\n",
            "Epoch 922/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3337 - accuracy: 0.8845 - val_loss: 0.3365 - val_accuracy: 0.8737\n",
            "Epoch 923/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3364 - accuracy: 0.8864 - val_loss: 0.3214 - val_accuracy: 0.8975\n",
            "Epoch 924/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3432 - accuracy: 0.8826 - val_loss: 0.3489 - val_accuracy: 0.8772\n",
            "Epoch 925/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3413 - accuracy: 0.8783 - val_loss: 0.3442 - val_accuracy: 0.8796\n",
            "Epoch 926/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3404 - accuracy: 0.8778 - val_loss: 0.3487 - val_accuracy: 0.8796\n",
            "Epoch 927/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3372 - accuracy: 0.8828 - val_loss: 0.3380 - val_accuracy: 0.8844\n",
            "Epoch 928/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3384 - accuracy: 0.8852 - val_loss: 0.3400 - val_accuracy: 0.8880\n",
            "Epoch 929/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3526 - accuracy: 0.8759 - val_loss: 0.3194 - val_accuracy: 0.8915\n",
            "Epoch 930/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3481 - accuracy: 0.8762 - val_loss: 0.3445 - val_accuracy: 0.8772\n",
            "Epoch 931/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3349 - accuracy: 0.8874 - val_loss: 0.3561 - val_accuracy: 0.8653\n",
            "Epoch 932/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3399 - accuracy: 0.8874 - val_loss: 0.3727 - val_accuracy: 0.8605\n",
            "Epoch 933/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3528 - accuracy: 0.8759 - val_loss: 0.3270 - val_accuracy: 0.8772\n",
            "Epoch 934/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3382 - accuracy: 0.8812 - val_loss: 0.3392 - val_accuracy: 0.8772\n",
            "Epoch 935/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3408 - accuracy: 0.8797 - val_loss: 0.3237 - val_accuracy: 0.8868\n",
            "Epoch 936/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3464 - accuracy: 0.8754 - val_loss: 0.3425 - val_accuracy: 0.8808\n",
            "Epoch 937/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3514 - accuracy: 0.8745 - val_loss: 0.3244 - val_accuracy: 0.8892\n",
            "Epoch 938/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3362 - accuracy: 0.8816 - val_loss: 0.3493 - val_accuracy: 0.8772\n",
            "Epoch 939/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3496 - accuracy: 0.8790 - val_loss: 0.3476 - val_accuracy: 0.8701\n",
            "Epoch 940/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3505 - accuracy: 0.8795 - val_loss: 0.3293 - val_accuracy: 0.8844\n",
            "Epoch 941/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3411 - accuracy: 0.8731 - val_loss: 0.3268 - val_accuracy: 0.8927\n",
            "Epoch 942/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3458 - accuracy: 0.8826 - val_loss: 0.3360 - val_accuracy: 0.8784\n",
            "Epoch 943/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3361 - accuracy: 0.8828 - val_loss: 0.3515 - val_accuracy: 0.8725\n",
            "Epoch 944/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3396 - accuracy: 0.8828 - val_loss: 0.3156 - val_accuracy: 0.8856\n",
            "Epoch 945/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3380 - accuracy: 0.8821 - val_loss: 0.3190 - val_accuracy: 0.8892\n",
            "Epoch 946/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3297 - accuracy: 0.8862 - val_loss: 0.3432 - val_accuracy: 0.8737\n",
            "Epoch 947/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3318 - accuracy: 0.8819 - val_loss: 0.3176 - val_accuracy: 0.8927\n",
            "Epoch 948/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3322 - accuracy: 0.8804 - val_loss: 0.3193 - val_accuracy: 0.8856\n",
            "Epoch 949/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3352 - accuracy: 0.8840 - val_loss: 0.3499 - val_accuracy: 0.8725\n",
            "Epoch 950/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3412 - accuracy: 0.8840 - val_loss: 0.3569 - val_accuracy: 0.8665\n",
            "Epoch 951/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3379 - accuracy: 0.8795 - val_loss: 0.3252 - val_accuracy: 0.8749\n",
            "Epoch 952/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3323 - accuracy: 0.8826 - val_loss: 0.3347 - val_accuracy: 0.8868\n",
            "Epoch 953/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3358 - accuracy: 0.8850 - val_loss: 0.3427 - val_accuracy: 0.8701\n",
            "Epoch 954/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3520 - accuracy: 0.8766 - val_loss: 0.3721 - val_accuracy: 0.8617\n",
            "Epoch 955/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3662 - accuracy: 0.8628 - val_loss: 0.3397 - val_accuracy: 0.8808\n",
            "Epoch 956/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3601 - accuracy: 0.8678 - val_loss: 0.3828 - val_accuracy: 0.8546\n",
            "Epoch 957/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3665 - accuracy: 0.8702 - val_loss: 0.3586 - val_accuracy: 0.8725\n",
            "Epoch 958/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3424 - accuracy: 0.8797 - val_loss: 0.3278 - val_accuracy: 0.8832\n",
            "Epoch 959/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3317 - accuracy: 0.8859 - val_loss: 0.3209 - val_accuracy: 0.8927\n",
            "Epoch 960/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3359 - accuracy: 0.8819 - val_loss: 0.3397 - val_accuracy: 0.8737\n",
            "Epoch 961/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3273 - accuracy: 0.8831 - val_loss: 0.3255 - val_accuracy: 0.8820\n",
            "Epoch 962/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3349 - accuracy: 0.8800 - val_loss: 0.3448 - val_accuracy: 0.8737\n",
            "Epoch 963/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3403 - accuracy: 0.8835 - val_loss: 0.3558 - val_accuracy: 0.8701\n",
            "Epoch 964/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3611 - accuracy: 0.8695 - val_loss: 0.3247 - val_accuracy: 0.8915\n",
            "Epoch 965/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3359 - accuracy: 0.8852 - val_loss: 0.3509 - val_accuracy: 0.8737\n",
            "Epoch 966/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3438 - accuracy: 0.8824 - val_loss: 0.3629 - val_accuracy: 0.8582\n",
            "Epoch 967/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3484 - accuracy: 0.8769 - val_loss: 0.3665 - val_accuracy: 0.8641\n",
            "Epoch 968/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3477 - accuracy: 0.8745 - val_loss: 0.3241 - val_accuracy: 0.8868\n",
            "Epoch 969/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3329 - accuracy: 0.8812 - val_loss: 0.3165 - val_accuracy: 0.8915\n",
            "Epoch 970/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3347 - accuracy: 0.8809 - val_loss: 0.3361 - val_accuracy: 0.8820\n",
            "Epoch 971/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3366 - accuracy: 0.8840 - val_loss: 0.3236 - val_accuracy: 0.8880\n",
            "Epoch 972/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3324 - accuracy: 0.8816 - val_loss: 0.3197 - val_accuracy: 0.8927\n",
            "Epoch 973/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3319 - accuracy: 0.8824 - val_loss: 0.3190 - val_accuracy: 0.8892\n",
            "Epoch 974/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3328 - accuracy: 0.8835 - val_loss: 0.3158 - val_accuracy: 0.8927\n",
            "Epoch 975/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3333 - accuracy: 0.8831 - val_loss: 0.3587 - val_accuracy: 0.8653\n",
            "Epoch 976/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3385 - accuracy: 0.8816 - val_loss: 0.3499 - val_accuracy: 0.8760\n",
            "Epoch 977/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3448 - accuracy: 0.8771 - val_loss: 0.3462 - val_accuracy: 0.8677\n",
            "Epoch 978/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3456 - accuracy: 0.8764 - val_loss: 0.3230 - val_accuracy: 0.8856\n",
            "Epoch 979/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3519 - accuracy: 0.8724 - val_loss: 0.3344 - val_accuracy: 0.8844\n",
            "Epoch 980/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3382 - accuracy: 0.8833 - val_loss: 0.3219 - val_accuracy: 0.8880\n",
            "Epoch 981/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3345 - accuracy: 0.8838 - val_loss: 0.3295 - val_accuracy: 0.8856\n",
            "Epoch 982/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3290 - accuracy: 0.8859 - val_loss: 0.3353 - val_accuracy: 0.8784\n",
            "Epoch 983/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3328 - accuracy: 0.8828 - val_loss: 0.3301 - val_accuracy: 0.8868\n",
            "Epoch 984/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3301 - accuracy: 0.8814 - val_loss: 0.3435 - val_accuracy: 0.8760\n",
            "Epoch 985/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3345 - accuracy: 0.8831 - val_loss: 0.3232 - val_accuracy: 0.8880\n",
            "Epoch 986/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3242 - accuracy: 0.8888 - val_loss: 0.3086 - val_accuracy: 0.8999\n",
            "Epoch 987/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3228 - accuracy: 0.8883 - val_loss: 0.3143 - val_accuracy: 0.8868\n",
            "Epoch 988/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3338 - accuracy: 0.8816 - val_loss: 0.3275 - val_accuracy: 0.8820\n",
            "Epoch 989/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3367 - accuracy: 0.8766 - val_loss: 0.3568 - val_accuracy: 0.8737\n",
            "Epoch 990/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3466 - accuracy: 0.8747 - val_loss: 0.3608 - val_accuracy: 0.8605\n",
            "Epoch 991/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3513 - accuracy: 0.8783 - val_loss: 0.3373 - val_accuracy: 0.8844\n",
            "Epoch 992/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3339 - accuracy: 0.8788 - val_loss: 0.3429 - val_accuracy: 0.8760\n",
            "Epoch 993/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3430 - accuracy: 0.8809 - val_loss: 0.3311 - val_accuracy: 0.8808\n",
            "Epoch 994/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3279 - accuracy: 0.8869 - val_loss: 0.3414 - val_accuracy: 0.8737\n",
            "Epoch 995/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3363 - accuracy: 0.8814 - val_loss: 0.4137 - val_accuracy: 0.8379\n",
            "Epoch 996/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3477 - accuracy: 0.8764 - val_loss: 0.3614 - val_accuracy: 0.8701\n",
            "Epoch 997/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3316 - accuracy: 0.8862 - val_loss: 0.3149 - val_accuracy: 0.8927\n",
            "Epoch 998/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3169 - accuracy: 0.8905 - val_loss: 0.3262 - val_accuracy: 0.8844\n",
            "Epoch 999/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3217 - accuracy: 0.8866 - val_loss: 0.3058 - val_accuracy: 0.8939\n",
            "Epoch 1000/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3185 - accuracy: 0.8902 - val_loss: 0.3506 - val_accuracy: 0.8653\n",
            "Epoch 1001/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3329 - accuracy: 0.8809 - val_loss: 0.3330 - val_accuracy: 0.8820\n",
            "Epoch 1002/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3404 - accuracy: 0.8802 - val_loss: 0.3157 - val_accuracy: 0.8808\n",
            "Epoch 1003/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3269 - accuracy: 0.8869 - val_loss: 0.3332 - val_accuracy: 0.8868\n",
            "Epoch 1004/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3393 - accuracy: 0.8788 - val_loss: 0.3731 - val_accuracy: 0.8594\n",
            "Epoch 1005/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3421 - accuracy: 0.8797 - val_loss: 0.3123 - val_accuracy: 0.8880\n",
            "Epoch 1006/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3471 - accuracy: 0.8804 - val_loss: 0.3814 - val_accuracy: 0.8725\n",
            "Epoch 1007/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3725 - accuracy: 0.8666 - val_loss: 0.3689 - val_accuracy: 0.8546\n",
            "Epoch 1008/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3567 - accuracy: 0.8695 - val_loss: 0.3617 - val_accuracy: 0.8689\n",
            "Epoch 1009/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3679 - accuracy: 0.8669 - val_loss: 0.3539 - val_accuracy: 0.8772\n",
            "Epoch 1010/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3602 - accuracy: 0.8688 - val_loss: 0.3371 - val_accuracy: 0.8820\n",
            "Epoch 1011/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3323 - accuracy: 0.8840 - val_loss: 0.3328 - val_accuracy: 0.8772\n",
            "Epoch 1012/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3226 - accuracy: 0.8854 - val_loss: 0.3112 - val_accuracy: 0.8903\n",
            "Epoch 1013/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3190 - accuracy: 0.8905 - val_loss: 0.3281 - val_accuracy: 0.8832\n",
            "Epoch 1014/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3367 - accuracy: 0.8802 - val_loss: 0.3463 - val_accuracy: 0.8737\n",
            "Epoch 1015/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3386 - accuracy: 0.8809 - val_loss: 0.3061 - val_accuracy: 0.8927\n",
            "Epoch 1016/1500\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.3247 - accuracy: 0.8881 - val_loss: 0.3214 - val_accuracy: 0.8760\n",
            "Epoch 1017/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3259 - accuracy: 0.8869 - val_loss: 0.3166 - val_accuracy: 0.8844\n",
            "Epoch 1018/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3221 - accuracy: 0.8905 - val_loss: 0.3065 - val_accuracy: 0.8975\n",
            "Epoch 1019/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3230 - accuracy: 0.8897 - val_loss: 0.3269 - val_accuracy: 0.8784\n",
            "Epoch 1020/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3285 - accuracy: 0.8824 - val_loss: 0.3210 - val_accuracy: 0.8915\n",
            "Epoch 1021/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3232 - accuracy: 0.8838 - val_loss: 0.3100 - val_accuracy: 0.8951\n",
            "Epoch 1022/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3158 - accuracy: 0.8902 - val_loss: 0.3222 - val_accuracy: 0.8856\n",
            "Epoch 1023/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3217 - accuracy: 0.8869 - val_loss: 0.3474 - val_accuracy: 0.8737\n",
            "Epoch 1024/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3284 - accuracy: 0.8809 - val_loss: 0.3569 - val_accuracy: 0.8737\n",
            "Epoch 1025/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3313 - accuracy: 0.8807 - val_loss: 0.3370 - val_accuracy: 0.8820\n",
            "Epoch 1026/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3284 - accuracy: 0.8864 - val_loss: 0.3308 - val_accuracy: 0.8713\n",
            "Epoch 1027/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3472 - accuracy: 0.8743 - val_loss: 0.3786 - val_accuracy: 0.8582\n",
            "Epoch 1028/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3565 - accuracy: 0.8700 - val_loss: 0.3368 - val_accuracy: 0.8820\n",
            "Epoch 1029/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3411 - accuracy: 0.8731 - val_loss: 0.3101 - val_accuracy: 0.8868\n",
            "Epoch 1030/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3338 - accuracy: 0.8812 - val_loss: 0.3398 - val_accuracy: 0.8701\n",
            "Epoch 1031/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3314 - accuracy: 0.8835 - val_loss: 0.3775 - val_accuracy: 0.8582\n",
            "Epoch 1032/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3355 - accuracy: 0.8804 - val_loss: 0.3162 - val_accuracy: 0.8915\n",
            "Epoch 1033/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3215 - accuracy: 0.8902 - val_loss: 0.3284 - val_accuracy: 0.8784\n",
            "Epoch 1034/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3150 - accuracy: 0.8905 - val_loss: 0.3464 - val_accuracy: 0.8749\n",
            "Epoch 1035/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3476 - accuracy: 0.8724 - val_loss: 0.3142 - val_accuracy: 0.8892\n",
            "Epoch 1036/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3302 - accuracy: 0.8824 - val_loss: 0.3591 - val_accuracy: 0.8737\n",
            "Epoch 1037/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3345 - accuracy: 0.8797 - val_loss: 0.3090 - val_accuracy: 0.8903\n",
            "Epoch 1038/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3096 - accuracy: 0.8938 - val_loss: 0.3038 - val_accuracy: 0.8927\n",
            "Epoch 1039/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3107 - accuracy: 0.8952 - val_loss: 0.2947 - val_accuracy: 0.9023\n",
            "Epoch 1040/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3138 - accuracy: 0.8924 - val_loss: 0.3076 - val_accuracy: 0.8951\n",
            "Epoch 1041/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3146 - accuracy: 0.8926 - val_loss: 0.3100 - val_accuracy: 0.8844\n",
            "Epoch 1042/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3135 - accuracy: 0.8897 - val_loss: 0.2951 - val_accuracy: 0.9070\n",
            "Epoch 1043/1500\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.3075 - accuracy: 0.8933 - val_loss: 0.3236 - val_accuracy: 0.8784\n",
            "Epoch 1044/1500\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.3157 - accuracy: 0.8902 - val_loss: 0.3006 - val_accuracy: 0.8951\n",
            "Epoch 1045/1500\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 0.3249 - accuracy: 0.8874 - val_loss: 0.3205 - val_accuracy: 0.8784\n",
            "Epoch 1046/1500\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.3246 - accuracy: 0.8833 - val_loss: 0.3134 - val_accuracy: 0.8903\n",
            "Epoch 1047/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3303 - accuracy: 0.8802 - val_loss: 0.3484 - val_accuracy: 0.8653\n",
            "Epoch 1048/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3422 - accuracy: 0.8764 - val_loss: 0.3285 - val_accuracy: 0.8832\n",
            "Epoch 1049/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3440 - accuracy: 0.8764 - val_loss: 0.3255 - val_accuracy: 0.8808\n",
            "Epoch 1050/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3305 - accuracy: 0.8804 - val_loss: 0.3288 - val_accuracy: 0.8784\n",
            "Epoch 1051/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3149 - accuracy: 0.8902 - val_loss: 0.3094 - val_accuracy: 0.8927\n",
            "Epoch 1052/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3159 - accuracy: 0.8847 - val_loss: 0.3256 - val_accuracy: 0.8796\n",
            "Epoch 1053/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3214 - accuracy: 0.8847 - val_loss: 0.3081 - val_accuracy: 0.8939\n",
            "Epoch 1054/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3220 - accuracy: 0.8897 - val_loss: 0.3366 - val_accuracy: 0.8808\n",
            "Epoch 1055/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3370 - accuracy: 0.8781 - val_loss: 0.3301 - val_accuracy: 0.8749\n",
            "Epoch 1056/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3296 - accuracy: 0.8812 - val_loss: 0.3120 - val_accuracy: 0.8820\n",
            "Epoch 1057/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3192 - accuracy: 0.8907 - val_loss: 0.3182 - val_accuracy: 0.8856\n",
            "Epoch 1058/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3271 - accuracy: 0.8866 - val_loss: 0.3154 - val_accuracy: 0.8844\n",
            "Epoch 1059/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3165 - accuracy: 0.8857 - val_loss: 0.2977 - val_accuracy: 0.9070\n",
            "Epoch 1060/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3207 - accuracy: 0.8874 - val_loss: 0.3165 - val_accuracy: 0.8856\n",
            "Epoch 1061/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3186 - accuracy: 0.8869 - val_loss: 0.3240 - val_accuracy: 0.8903\n",
            "Epoch 1062/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3241 - accuracy: 0.8835 - val_loss: 0.3075 - val_accuracy: 0.8880\n",
            "Epoch 1063/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3144 - accuracy: 0.8912 - val_loss: 0.3236 - val_accuracy: 0.8903\n",
            "Epoch 1064/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3202 - accuracy: 0.8835 - val_loss: 0.3101 - val_accuracy: 0.8868\n",
            "Epoch 1065/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3127 - accuracy: 0.8912 - val_loss: 0.3045 - val_accuracy: 0.8880\n",
            "Epoch 1066/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3259 - accuracy: 0.8888 - val_loss: 0.3282 - val_accuracy: 0.8808\n",
            "Epoch 1067/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3534 - accuracy: 0.8664 - val_loss: 0.3586 - val_accuracy: 0.8737\n",
            "Epoch 1068/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3449 - accuracy: 0.8774 - val_loss: 0.3828 - val_accuracy: 0.8510\n",
            "Epoch 1069/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3456 - accuracy: 0.8688 - val_loss: 0.3228 - val_accuracy: 0.8808\n",
            "Epoch 1070/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3269 - accuracy: 0.8864 - val_loss: 0.3138 - val_accuracy: 0.8868\n",
            "Epoch 1071/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3343 - accuracy: 0.8781 - val_loss: 0.3290 - val_accuracy: 0.8713\n",
            "Epoch 1072/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3158 - accuracy: 0.8850 - val_loss: 0.3068 - val_accuracy: 0.8915\n",
            "Epoch 1073/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3261 - accuracy: 0.8795 - val_loss: 0.3311 - val_accuracy: 0.8772\n",
            "Epoch 1074/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3298 - accuracy: 0.8824 - val_loss: 0.3119 - val_accuracy: 0.8856\n",
            "Epoch 1075/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3264 - accuracy: 0.8793 - val_loss: 0.3179 - val_accuracy: 0.8892\n",
            "Epoch 1076/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3193 - accuracy: 0.8890 - val_loss: 0.3152 - val_accuracy: 0.8892\n",
            "Epoch 1077/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3128 - accuracy: 0.8926 - val_loss: 0.3266 - val_accuracy: 0.8856\n",
            "Epoch 1078/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3148 - accuracy: 0.8914 - val_loss: 0.2960 - val_accuracy: 0.8951\n",
            "Epoch 1079/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3121 - accuracy: 0.8885 - val_loss: 0.2920 - val_accuracy: 0.8963\n",
            "Epoch 1080/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3115 - accuracy: 0.8895 - val_loss: 0.3228 - val_accuracy: 0.8784\n",
            "Epoch 1081/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3146 - accuracy: 0.8935 - val_loss: 0.3047 - val_accuracy: 0.8975\n",
            "Epoch 1082/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3126 - accuracy: 0.8890 - val_loss: 0.3081 - val_accuracy: 0.8868\n",
            "Epoch 1083/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3110 - accuracy: 0.8907 - val_loss: 0.3382 - val_accuracy: 0.8713\n",
            "Epoch 1084/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3430 - accuracy: 0.8743 - val_loss: 0.3289 - val_accuracy: 0.8772\n",
            "Epoch 1085/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3211 - accuracy: 0.8883 - val_loss: 0.3156 - val_accuracy: 0.8892\n",
            "Epoch 1086/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3419 - accuracy: 0.8781 - val_loss: 0.3633 - val_accuracy: 0.8641\n",
            "Epoch 1087/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3912 - accuracy: 0.8638 - val_loss: 0.3382 - val_accuracy: 0.8772\n",
            "Epoch 1088/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3448 - accuracy: 0.8714 - val_loss: 0.3509 - val_accuracy: 0.8725\n",
            "Epoch 1089/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3248 - accuracy: 0.8831 - val_loss: 0.3078 - val_accuracy: 0.8927\n",
            "Epoch 1090/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3106 - accuracy: 0.8905 - val_loss: 0.3081 - val_accuracy: 0.8915\n",
            "Epoch 1091/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3065 - accuracy: 0.8926 - val_loss: 0.3010 - val_accuracy: 0.8927\n",
            "Epoch 1092/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3100 - accuracy: 0.8921 - val_loss: 0.3176 - val_accuracy: 0.8880\n",
            "Epoch 1093/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3322 - accuracy: 0.8814 - val_loss: 0.4061 - val_accuracy: 0.8367\n",
            "Epoch 1094/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3504 - accuracy: 0.8702 - val_loss: 0.3501 - val_accuracy: 0.8653\n",
            "Epoch 1095/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3459 - accuracy: 0.8735 - val_loss: 0.3294 - val_accuracy: 0.8927\n",
            "Epoch 1096/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3346 - accuracy: 0.8754 - val_loss: 0.3130 - val_accuracy: 0.8760\n",
            "Epoch 1097/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3195 - accuracy: 0.8857 - val_loss: 0.3257 - val_accuracy: 0.8820\n",
            "Epoch 1098/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3254 - accuracy: 0.8843 - val_loss: 0.3157 - val_accuracy: 0.8880\n",
            "Epoch 1099/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3253 - accuracy: 0.8831 - val_loss: 0.3186 - val_accuracy: 0.8796\n",
            "Epoch 1100/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3266 - accuracy: 0.8804 - val_loss: 0.3309 - val_accuracy: 0.8796\n",
            "Epoch 1101/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3286 - accuracy: 0.8809 - val_loss: 0.3133 - val_accuracy: 0.8796\n",
            "Epoch 1102/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3082 - accuracy: 0.8926 - val_loss: 0.3214 - val_accuracy: 0.8892\n",
            "Epoch 1103/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3353 - accuracy: 0.8800 - val_loss: 0.3179 - val_accuracy: 0.8832\n",
            "Epoch 1104/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3326 - accuracy: 0.8788 - val_loss: 0.3289 - val_accuracy: 0.8749\n",
            "Epoch 1105/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3223 - accuracy: 0.8857 - val_loss: 0.3053 - val_accuracy: 0.8939\n",
            "Epoch 1106/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3104 - accuracy: 0.8926 - val_loss: 0.3329 - val_accuracy: 0.8915\n",
            "Epoch 1107/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3296 - accuracy: 0.8797 - val_loss: 0.3327 - val_accuracy: 0.8701\n",
            "Epoch 1108/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3277 - accuracy: 0.8788 - val_loss: 0.2979 - val_accuracy: 0.8939\n",
            "Epoch 1109/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3161 - accuracy: 0.8900 - val_loss: 0.3162 - val_accuracy: 0.8868\n",
            "Epoch 1110/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3348 - accuracy: 0.8807 - val_loss: 0.3211 - val_accuracy: 0.8844\n",
            "Epoch 1111/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3159 - accuracy: 0.8890 - val_loss: 0.3168 - val_accuracy: 0.8832\n",
            "Epoch 1112/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3058 - accuracy: 0.8905 - val_loss: 0.2938 - val_accuracy: 0.8999\n",
            "Epoch 1113/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3056 - accuracy: 0.8952 - val_loss: 0.3087 - val_accuracy: 0.8880\n",
            "Epoch 1114/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3177 - accuracy: 0.8871 - val_loss: 0.3026 - val_accuracy: 0.8999\n",
            "Epoch 1115/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3102 - accuracy: 0.8869 - val_loss: 0.2971 - val_accuracy: 0.8927\n",
            "Epoch 1116/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3098 - accuracy: 0.8885 - val_loss: 0.3199 - val_accuracy: 0.8701\n",
            "Epoch 1117/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3081 - accuracy: 0.8916 - val_loss: 0.3063 - val_accuracy: 0.8856\n",
            "Epoch 1118/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3095 - accuracy: 0.8905 - val_loss: 0.2948 - val_accuracy: 0.8939\n",
            "Epoch 1119/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3030 - accuracy: 0.8997 - val_loss: 0.3069 - val_accuracy: 0.8903\n",
            "Epoch 1120/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3111 - accuracy: 0.8902 - val_loss: 0.3028 - val_accuracy: 0.8856\n",
            "Epoch 1121/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3026 - accuracy: 0.8962 - val_loss: 0.2914 - val_accuracy: 0.9058\n",
            "Epoch 1122/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3053 - accuracy: 0.8914 - val_loss: 0.3590 - val_accuracy: 0.8653\n",
            "Epoch 1123/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3319 - accuracy: 0.8828 - val_loss: 0.3359 - val_accuracy: 0.8725\n",
            "Epoch 1124/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3333 - accuracy: 0.8790 - val_loss: 0.3125 - val_accuracy: 0.8975\n",
            "Epoch 1125/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3220 - accuracy: 0.8826 - val_loss: 0.3314 - val_accuracy: 0.8749\n",
            "Epoch 1126/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3191 - accuracy: 0.8788 - val_loss: 0.3240 - val_accuracy: 0.8737\n",
            "Epoch 1127/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3225 - accuracy: 0.8804 - val_loss: 0.3418 - val_accuracy: 0.8582\n",
            "Epoch 1128/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3302 - accuracy: 0.8795 - val_loss: 0.3519 - val_accuracy: 0.8725\n",
            "Epoch 1129/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3171 - accuracy: 0.8888 - val_loss: 0.3173 - val_accuracy: 0.8927\n",
            "Epoch 1130/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3147 - accuracy: 0.8845 - val_loss: 0.2927 - val_accuracy: 0.8963\n",
            "Epoch 1131/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3188 - accuracy: 0.8835 - val_loss: 0.3241 - val_accuracy: 0.8808\n",
            "Epoch 1132/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3240 - accuracy: 0.8840 - val_loss: 0.3164 - val_accuracy: 0.8796\n",
            "Epoch 1133/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3237 - accuracy: 0.8859 - val_loss: 0.2955 - val_accuracy: 0.8951\n",
            "Epoch 1134/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3125 - accuracy: 0.8888 - val_loss: 0.3197 - val_accuracy: 0.8832\n",
            "Epoch 1135/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3155 - accuracy: 0.8871 - val_loss: 0.3120 - val_accuracy: 0.8868\n",
            "Epoch 1136/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3260 - accuracy: 0.8819 - val_loss: 0.3957 - val_accuracy: 0.8451\n",
            "Epoch 1137/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3414 - accuracy: 0.8685 - val_loss: 0.3221 - val_accuracy: 0.8820\n",
            "Epoch 1138/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3215 - accuracy: 0.8833 - val_loss: 0.3025 - val_accuracy: 0.8939\n",
            "Epoch 1139/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3223 - accuracy: 0.8885 - val_loss: 0.3126 - val_accuracy: 0.8844\n",
            "Epoch 1140/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3132 - accuracy: 0.8869 - val_loss: 0.2861 - val_accuracy: 0.9011\n",
            "Epoch 1141/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3063 - accuracy: 0.8909 - val_loss: 0.3101 - val_accuracy: 0.8868\n",
            "Epoch 1142/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3263 - accuracy: 0.8845 - val_loss: 0.3447 - val_accuracy: 0.8772\n",
            "Epoch 1143/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3278 - accuracy: 0.8766 - val_loss: 0.3499 - val_accuracy: 0.8749\n",
            "Epoch 1144/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3398 - accuracy: 0.8728 - val_loss: 0.3324 - val_accuracy: 0.8772\n",
            "Epoch 1145/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3377 - accuracy: 0.8745 - val_loss: 0.3356 - val_accuracy: 0.8772\n",
            "Epoch 1146/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3238 - accuracy: 0.8845 - val_loss: 0.2988 - val_accuracy: 0.8903\n",
            "Epoch 1147/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3145 - accuracy: 0.8881 - val_loss: 0.3085 - val_accuracy: 0.8939\n",
            "Epoch 1148/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3163 - accuracy: 0.8869 - val_loss: 0.3090 - val_accuracy: 0.8856\n",
            "Epoch 1149/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3062 - accuracy: 0.8921 - val_loss: 0.3088 - val_accuracy: 0.8844\n",
            "Epoch 1150/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3085 - accuracy: 0.8890 - val_loss: 0.3013 - val_accuracy: 0.8939\n",
            "Epoch 1151/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3036 - accuracy: 0.8926 - val_loss: 0.2994 - val_accuracy: 0.8939\n",
            "Epoch 1152/1500\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.3060 - accuracy: 0.8921 - val_loss: 0.3015 - val_accuracy: 0.8963\n",
            "Epoch 1153/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3142 - accuracy: 0.8897 - val_loss: 0.2992 - val_accuracy: 0.8939\n",
            "Epoch 1154/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3074 - accuracy: 0.8881 - val_loss: 0.3170 - val_accuracy: 0.8820\n",
            "Epoch 1155/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3098 - accuracy: 0.8900 - val_loss: 0.3053 - val_accuracy: 0.8856\n",
            "Epoch 1156/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3241 - accuracy: 0.8831 - val_loss: 0.3074 - val_accuracy: 0.8868\n",
            "Epoch 1157/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3239 - accuracy: 0.8840 - val_loss: 0.3152 - val_accuracy: 0.8808\n",
            "Epoch 1158/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3074 - accuracy: 0.8926 - val_loss: 0.3238 - val_accuracy: 0.8713\n",
            "Epoch 1159/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3038 - accuracy: 0.8895 - val_loss: 0.3120 - val_accuracy: 0.8903\n",
            "Epoch 1160/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3116 - accuracy: 0.8862 - val_loss: 0.2878 - val_accuracy: 0.8975\n",
            "Epoch 1161/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3108 - accuracy: 0.8859 - val_loss: 0.3361 - val_accuracy: 0.8796\n",
            "Epoch 1162/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3184 - accuracy: 0.8876 - val_loss: 0.3001 - val_accuracy: 0.8927\n",
            "Epoch 1163/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3231 - accuracy: 0.8852 - val_loss: 0.3084 - val_accuracy: 0.8868\n",
            "Epoch 1164/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3042 - accuracy: 0.8916 - val_loss: 0.2966 - val_accuracy: 0.8975\n",
            "Epoch 1165/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3061 - accuracy: 0.8926 - val_loss: 0.3159 - val_accuracy: 0.8737\n",
            "Epoch 1166/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3089 - accuracy: 0.8905 - val_loss: 0.3236 - val_accuracy: 0.8784\n",
            "Epoch 1167/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3006 - accuracy: 0.8921 - val_loss: 0.2971 - val_accuracy: 0.8892\n",
            "Epoch 1168/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3027 - accuracy: 0.8895 - val_loss: 0.2951 - val_accuracy: 0.8868\n",
            "Epoch 1169/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3038 - accuracy: 0.8919 - val_loss: 0.3067 - val_accuracy: 0.8844\n",
            "Epoch 1170/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3060 - accuracy: 0.8909 - val_loss: 0.2919 - val_accuracy: 0.8927\n",
            "Epoch 1171/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3167 - accuracy: 0.8859 - val_loss: 0.3026 - val_accuracy: 0.8903\n",
            "Epoch 1172/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3005 - accuracy: 0.8964 - val_loss: 0.2912 - val_accuracy: 0.8939\n",
            "Epoch 1173/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3016 - accuracy: 0.8935 - val_loss: 0.3106 - val_accuracy: 0.8820\n",
            "Epoch 1174/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3043 - accuracy: 0.8909 - val_loss: 0.3030 - val_accuracy: 0.8808\n",
            "Epoch 1175/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3029 - accuracy: 0.8926 - val_loss: 0.3429 - val_accuracy: 0.8677\n",
            "Epoch 1176/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3095 - accuracy: 0.8902 - val_loss: 0.3116 - val_accuracy: 0.8808\n",
            "Epoch 1177/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3191 - accuracy: 0.8840 - val_loss: 0.2958 - val_accuracy: 0.8975\n",
            "Epoch 1178/1500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.3115 - accuracy: 0.8859 - val_loss: 0.3581 - val_accuracy: 0.8689\n",
            "Epoch 1179/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3271 - accuracy: 0.8778 - val_loss: 0.3429 - val_accuracy: 0.8725\n",
            "Epoch 1180/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3100 - accuracy: 0.8890 - val_loss: 0.3254 - val_accuracy: 0.8820\n",
            "Epoch 1181/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3169 - accuracy: 0.8888 - val_loss: 0.3440 - val_accuracy: 0.8653\n",
            "Epoch 1182/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3137 - accuracy: 0.8826 - val_loss: 0.3000 - val_accuracy: 0.8939\n",
            "Epoch 1183/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3091 - accuracy: 0.8859 - val_loss: 0.3082 - val_accuracy: 0.8832\n",
            "Epoch 1184/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3046 - accuracy: 0.8890 - val_loss: 0.3148 - val_accuracy: 0.8868\n",
            "Epoch 1185/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3250 - accuracy: 0.8814 - val_loss: 0.3429 - val_accuracy: 0.8760\n",
            "Epoch 1186/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3098 - accuracy: 0.8907 - val_loss: 0.3470 - val_accuracy: 0.8772\n",
            "Epoch 1187/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3124 - accuracy: 0.8897 - val_loss: 0.3176 - val_accuracy: 0.8784\n",
            "Epoch 1188/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3226 - accuracy: 0.8828 - val_loss: 0.3467 - val_accuracy: 0.8725\n",
            "Epoch 1189/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3387 - accuracy: 0.8757 - val_loss: 0.2924 - val_accuracy: 0.8915\n",
            "Epoch 1190/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3366 - accuracy: 0.8704 - val_loss: 0.3487 - val_accuracy: 0.8796\n",
            "Epoch 1191/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3362 - accuracy: 0.8781 - val_loss: 0.3792 - val_accuracy: 0.8451\n",
            "Epoch 1192/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3405 - accuracy: 0.8797 - val_loss: 0.5393 - val_accuracy: 0.8260\n",
            "Epoch 1193/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3633 - accuracy: 0.8623 - val_loss: 0.3022 - val_accuracy: 0.8808\n",
            "Epoch 1194/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3071 - accuracy: 0.8919 - val_loss: 0.3212 - val_accuracy: 0.8820\n",
            "Epoch 1195/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3090 - accuracy: 0.8914 - val_loss: 0.3039 - val_accuracy: 0.8939\n",
            "Epoch 1196/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3060 - accuracy: 0.8871 - val_loss: 0.3104 - val_accuracy: 0.8844\n",
            "Epoch 1197/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3111 - accuracy: 0.8859 - val_loss: 0.2971 - val_accuracy: 0.8951\n",
            "Epoch 1198/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2945 - accuracy: 0.8924 - val_loss: 0.2813 - val_accuracy: 0.8939\n",
            "Epoch 1199/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2946 - accuracy: 0.8943 - val_loss: 0.2941 - val_accuracy: 0.8987\n",
            "Epoch 1200/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3041 - accuracy: 0.8924 - val_loss: 0.2871 - val_accuracy: 0.8915\n",
            "Epoch 1201/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3003 - accuracy: 0.8947 - val_loss: 0.2945 - val_accuracy: 0.8963\n",
            "Epoch 1202/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2952 - accuracy: 0.8919 - val_loss: 0.3084 - val_accuracy: 0.8832\n",
            "Epoch 1203/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3101 - accuracy: 0.8874 - val_loss: 0.3692 - val_accuracy: 0.8522\n",
            "Epoch 1204/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3502 - accuracy: 0.8764 - val_loss: 0.3475 - val_accuracy: 0.8737\n",
            "Epoch 1205/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.3234 - accuracy: 0.8850 - val_loss: 0.3048 - val_accuracy: 0.8903\n",
            "Epoch 1206/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3049 - accuracy: 0.8914 - val_loss: 0.3167 - val_accuracy: 0.8749\n",
            "Epoch 1207/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3089 - accuracy: 0.8926 - val_loss: 0.3035 - val_accuracy: 0.8903\n",
            "Epoch 1208/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3210 - accuracy: 0.8847 - val_loss: 0.2917 - val_accuracy: 0.8951\n",
            "Epoch 1209/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3081 - accuracy: 0.8864 - val_loss: 0.2996 - val_accuracy: 0.8892\n",
            "Epoch 1210/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3034 - accuracy: 0.8897 - val_loss: 0.3235 - val_accuracy: 0.8808\n",
            "Epoch 1211/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3086 - accuracy: 0.8905 - val_loss: 0.2857 - val_accuracy: 0.9011\n",
            "Epoch 1212/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3075 - accuracy: 0.8881 - val_loss: 0.2944 - val_accuracy: 0.8892\n",
            "Epoch 1213/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2988 - accuracy: 0.8938 - val_loss: 0.2911 - val_accuracy: 0.8939\n",
            "Epoch 1214/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3095 - accuracy: 0.8876 - val_loss: 0.2965 - val_accuracy: 0.8963\n",
            "Epoch 1215/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3151 - accuracy: 0.8840 - val_loss: 0.3202 - val_accuracy: 0.8868\n",
            "Epoch 1216/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3071 - accuracy: 0.8874 - val_loss: 0.2974 - val_accuracy: 0.8939\n",
            "Epoch 1217/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3105 - accuracy: 0.8862 - val_loss: 0.3155 - val_accuracy: 0.8796\n",
            "Epoch 1218/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3174 - accuracy: 0.8831 - val_loss: 0.2988 - val_accuracy: 0.8915\n",
            "Epoch 1219/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3076 - accuracy: 0.8900 - val_loss: 0.2998 - val_accuracy: 0.8915\n",
            "Epoch 1220/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3000 - accuracy: 0.8943 - val_loss: 0.2880 - val_accuracy: 0.8939\n",
            "Epoch 1221/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.2986 - accuracy: 0.8938 - val_loss: 0.3164 - val_accuracy: 0.8844\n",
            "Epoch 1222/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3130 - accuracy: 0.8847 - val_loss: 0.3469 - val_accuracy: 0.8737\n",
            "Epoch 1223/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3164 - accuracy: 0.8850 - val_loss: 0.2919 - val_accuracy: 0.8903\n",
            "Epoch 1224/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2987 - accuracy: 0.8945 - val_loss: 0.2758 - val_accuracy: 0.8987\n",
            "Epoch 1225/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3020 - accuracy: 0.8928 - val_loss: 0.3082 - val_accuracy: 0.8951\n",
            "Epoch 1226/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3183 - accuracy: 0.8795 - val_loss: 0.3018 - val_accuracy: 0.8844\n",
            "Epoch 1227/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3079 - accuracy: 0.8878 - val_loss: 0.3086 - val_accuracy: 0.8820\n",
            "Epoch 1228/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3024 - accuracy: 0.8931 - val_loss: 0.3146 - val_accuracy: 0.8844\n",
            "Epoch 1229/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3009 - accuracy: 0.8969 - val_loss: 0.3035 - val_accuracy: 0.8880\n",
            "Epoch 1230/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2971 - accuracy: 0.8950 - val_loss: 0.3112 - val_accuracy: 0.8713\n",
            "Epoch 1231/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3049 - accuracy: 0.8933 - val_loss: 0.3294 - val_accuracy: 0.8641\n",
            "Epoch 1232/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3074 - accuracy: 0.8864 - val_loss: 0.2901 - val_accuracy: 0.8987\n",
            "Epoch 1233/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2986 - accuracy: 0.8935 - val_loss: 0.3368 - val_accuracy: 0.8653\n",
            "Epoch 1234/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3173 - accuracy: 0.8852 - val_loss: 0.3127 - val_accuracy: 0.8868\n",
            "Epoch 1235/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3034 - accuracy: 0.8883 - val_loss: 0.2843 - val_accuracy: 0.8987\n",
            "Epoch 1236/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3036 - accuracy: 0.8843 - val_loss: 0.3061 - val_accuracy: 0.8796\n",
            "Epoch 1237/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3061 - accuracy: 0.8912 - val_loss: 0.2968 - val_accuracy: 0.8856\n",
            "Epoch 1238/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3039 - accuracy: 0.8921 - val_loss: 0.2829 - val_accuracy: 0.8987\n",
            "Epoch 1239/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2976 - accuracy: 0.8940 - val_loss: 0.2860 - val_accuracy: 0.8951\n",
            "Epoch 1240/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3008 - accuracy: 0.8890 - val_loss: 0.3249 - val_accuracy: 0.8844\n",
            "Epoch 1241/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2957 - accuracy: 0.8981 - val_loss: 0.3105 - val_accuracy: 0.8892\n",
            "Epoch 1242/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3108 - accuracy: 0.8909 - val_loss: 0.2945 - val_accuracy: 0.8975\n",
            "Epoch 1243/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.2919 - accuracy: 0.8907 - val_loss: 0.2969 - val_accuracy: 0.8903\n",
            "Epoch 1244/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.2993 - accuracy: 0.8978 - val_loss: 0.2880 - val_accuracy: 0.8915\n",
            "Epoch 1245/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3101 - accuracy: 0.8862 - val_loss: 0.3931 - val_accuracy: 0.8522\n",
            "Epoch 1246/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3286 - accuracy: 0.8754 - val_loss: 0.2947 - val_accuracy: 0.8951\n",
            "Epoch 1247/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3177 - accuracy: 0.8850 - val_loss: 0.3010 - val_accuracy: 0.8927\n",
            "Epoch 1248/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3099 - accuracy: 0.8893 - val_loss: 0.3050 - val_accuracy: 0.8856\n",
            "Epoch 1249/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3151 - accuracy: 0.8869 - val_loss: 0.3082 - val_accuracy: 0.8880\n",
            "Epoch 1250/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3098 - accuracy: 0.8854 - val_loss: 0.3029 - val_accuracy: 0.8832\n",
            "Epoch 1251/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3053 - accuracy: 0.8888 - val_loss: 0.2960 - val_accuracy: 0.8939\n",
            "Epoch 1252/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2924 - accuracy: 0.8962 - val_loss: 0.2901 - val_accuracy: 0.8939\n",
            "Epoch 1253/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3000 - accuracy: 0.8931 - val_loss: 0.2862 - val_accuracy: 0.8987\n",
            "Epoch 1254/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.2933 - accuracy: 0.8945 - val_loss: 0.3033 - val_accuracy: 0.8892\n",
            "Epoch 1255/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3014 - accuracy: 0.8950 - val_loss: 0.2932 - val_accuracy: 0.8927\n",
            "Epoch 1256/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2953 - accuracy: 0.8952 - val_loss: 0.3482 - val_accuracy: 0.8570\n",
            "Epoch 1257/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3239 - accuracy: 0.8819 - val_loss: 0.3190 - val_accuracy: 0.8701\n",
            "Epoch 1258/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3144 - accuracy: 0.8828 - val_loss: 0.2999 - val_accuracy: 0.8903\n",
            "Epoch 1259/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3118 - accuracy: 0.8869 - val_loss: 0.3174 - val_accuracy: 0.8820\n",
            "Epoch 1260/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3101 - accuracy: 0.8916 - val_loss: 0.3054 - val_accuracy: 0.8844\n",
            "Epoch 1261/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3035 - accuracy: 0.8890 - val_loss: 0.2868 - val_accuracy: 0.8903\n",
            "Epoch 1262/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3010 - accuracy: 0.8919 - val_loss: 0.3022 - val_accuracy: 0.8844\n",
            "Epoch 1263/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3054 - accuracy: 0.8862 - val_loss: 0.2894 - val_accuracy: 0.8880\n",
            "Epoch 1264/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2911 - accuracy: 0.8928 - val_loss: 0.2796 - val_accuracy: 0.8999\n",
            "Epoch 1265/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2902 - accuracy: 0.8988 - val_loss: 0.2778 - val_accuracy: 0.9094\n",
            "Epoch 1266/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2951 - accuracy: 0.8902 - val_loss: 0.2957 - val_accuracy: 0.8903\n",
            "Epoch 1267/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2874 - accuracy: 0.8966 - val_loss: 0.2872 - val_accuracy: 0.8987\n",
            "Epoch 1268/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2854 - accuracy: 0.8971 - val_loss: 0.3013 - val_accuracy: 0.8892\n",
            "Epoch 1269/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3007 - accuracy: 0.8895 - val_loss: 0.2988 - val_accuracy: 0.8927\n",
            "Epoch 1270/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3068 - accuracy: 0.8890 - val_loss: 0.2855 - val_accuracy: 0.8999\n",
            "Epoch 1271/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2894 - accuracy: 0.8943 - val_loss: 0.2917 - val_accuracy: 0.8987\n",
            "Epoch 1272/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2994 - accuracy: 0.8883 - val_loss: 0.3086 - val_accuracy: 0.8784\n",
            "Epoch 1273/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3237 - accuracy: 0.8774 - val_loss: 0.4022 - val_accuracy: 0.8558\n",
            "Epoch 1274/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3505 - accuracy: 0.8659 - val_loss: 0.3164 - val_accuracy: 0.8856\n",
            "Epoch 1275/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3175 - accuracy: 0.8845 - val_loss: 0.2839 - val_accuracy: 0.9011\n",
            "Epoch 1276/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2985 - accuracy: 0.8924 - val_loss: 0.2771 - val_accuracy: 0.8987\n",
            "Epoch 1277/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2972 - accuracy: 0.8909 - val_loss: 0.2932 - val_accuracy: 0.8880\n",
            "Epoch 1278/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.2873 - accuracy: 0.8983 - val_loss: 0.2784 - val_accuracy: 0.9035\n",
            "Epoch 1279/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2909 - accuracy: 0.8957 - val_loss: 0.3021 - val_accuracy: 0.8784\n",
            "Epoch 1280/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2999 - accuracy: 0.8928 - val_loss: 0.2946 - val_accuracy: 0.8820\n",
            "Epoch 1281/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2909 - accuracy: 0.8971 - val_loss: 0.3039 - val_accuracy: 0.8820\n",
            "Epoch 1282/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2997 - accuracy: 0.8859 - val_loss: 0.2996 - val_accuracy: 0.8844\n",
            "Epoch 1283/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3097 - accuracy: 0.8874 - val_loss: 0.3186 - val_accuracy: 0.8808\n",
            "Epoch 1284/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3130 - accuracy: 0.8866 - val_loss: 0.2952 - val_accuracy: 0.8903\n",
            "Epoch 1285/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3086 - accuracy: 0.8926 - val_loss: 0.2961 - val_accuracy: 0.8927\n",
            "Epoch 1286/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3079 - accuracy: 0.8902 - val_loss: 0.3050 - val_accuracy: 0.8856\n",
            "Epoch 1287/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2959 - accuracy: 0.8919 - val_loss: 0.3284 - val_accuracy: 0.8820\n",
            "Epoch 1288/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2991 - accuracy: 0.8871 - val_loss: 0.2942 - val_accuracy: 0.8915\n",
            "Epoch 1289/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3017 - accuracy: 0.8900 - val_loss: 0.2834 - val_accuracy: 0.8999\n",
            "Epoch 1290/1500\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.2976 - accuracy: 0.8926 - val_loss: 0.2990 - val_accuracy: 0.8868\n",
            "Epoch 1291/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3025 - accuracy: 0.8940 - val_loss: 0.2988 - val_accuracy: 0.8892\n",
            "Epoch 1292/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2963 - accuracy: 0.8909 - val_loss: 0.3071 - val_accuracy: 0.8760\n",
            "Epoch 1293/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3091 - accuracy: 0.8871 - val_loss: 0.2910 - val_accuracy: 0.8939\n",
            "Epoch 1294/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3015 - accuracy: 0.8909 - val_loss: 0.3165 - val_accuracy: 0.8749\n",
            "Epoch 1295/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3090 - accuracy: 0.8883 - val_loss: 0.3141 - val_accuracy: 0.8892\n",
            "Epoch 1296/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3067 - accuracy: 0.8835 - val_loss: 0.2949 - val_accuracy: 0.8880\n",
            "Epoch 1297/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2964 - accuracy: 0.8900 - val_loss: 0.2978 - val_accuracy: 0.8868\n",
            "Epoch 1298/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2966 - accuracy: 0.8919 - val_loss: 0.3093 - val_accuracy: 0.8832\n",
            "Epoch 1299/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3023 - accuracy: 0.8878 - val_loss: 0.3077 - val_accuracy: 0.8844\n",
            "Epoch 1300/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3071 - accuracy: 0.8916 - val_loss: 0.3466 - val_accuracy: 0.8713\n",
            "Epoch 1301/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3095 - accuracy: 0.8859 - val_loss: 0.2805 - val_accuracy: 0.8987\n",
            "Epoch 1302/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3021 - accuracy: 0.8912 - val_loss: 0.2975 - val_accuracy: 0.8903\n",
            "Epoch 1303/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3065 - accuracy: 0.8845 - val_loss: 0.3334 - val_accuracy: 0.8701\n",
            "Epoch 1304/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3203 - accuracy: 0.8828 - val_loss: 0.3468 - val_accuracy: 0.8677\n",
            "Epoch 1305/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3304 - accuracy: 0.8816 - val_loss: 0.3435 - val_accuracy: 0.8701\n",
            "Epoch 1306/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3247 - accuracy: 0.8864 - val_loss: 0.3470 - val_accuracy: 0.8629\n",
            "Epoch 1307/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.3209 - accuracy: 0.8788 - val_loss: 0.3603 - val_accuracy: 0.8665\n",
            "Epoch 1308/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3350 - accuracy: 0.8812 - val_loss: 0.2731 - val_accuracy: 0.9070\n",
            "Epoch 1309/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3052 - accuracy: 0.8895 - val_loss: 0.2887 - val_accuracy: 0.8987\n",
            "Epoch 1310/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3005 - accuracy: 0.8926 - val_loss: 0.2883 - val_accuracy: 0.8915\n",
            "Epoch 1311/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3150 - accuracy: 0.8833 - val_loss: 0.3062 - val_accuracy: 0.8880\n",
            "Epoch 1312/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3035 - accuracy: 0.8947 - val_loss: 0.2783 - val_accuracy: 0.8927\n",
            "Epoch 1313/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3042 - accuracy: 0.8981 - val_loss: 0.3032 - val_accuracy: 0.8844\n",
            "Epoch 1314/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3203 - accuracy: 0.8800 - val_loss: 0.2938 - val_accuracy: 0.8927\n",
            "Epoch 1315/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3277 - accuracy: 0.8883 - val_loss: 0.2997 - val_accuracy: 0.8951\n",
            "Epoch 1316/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3175 - accuracy: 0.8847 - val_loss: 0.3135 - val_accuracy: 0.8963\n",
            "Epoch 1317/1500\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.3168 - accuracy: 0.8816 - val_loss: 0.3087 - val_accuracy: 0.8868\n",
            "Epoch 1318/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3048 - accuracy: 0.8852 - val_loss: 0.2968 - val_accuracy: 0.8975\n",
            "Epoch 1319/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2974 - accuracy: 0.8909 - val_loss: 0.3003 - val_accuracy: 0.8844\n",
            "Epoch 1320/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3139 - accuracy: 0.8866 - val_loss: 0.3320 - val_accuracy: 0.8605\n",
            "Epoch 1321/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3083 - accuracy: 0.8912 - val_loss: 0.3084 - val_accuracy: 0.8868\n",
            "Epoch 1322/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3087 - accuracy: 0.8900 - val_loss: 0.3264 - val_accuracy: 0.8713\n",
            "Epoch 1323/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3083 - accuracy: 0.8900 - val_loss: 0.3156 - val_accuracy: 0.8856\n",
            "Epoch 1324/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2996 - accuracy: 0.8916 - val_loss: 0.3306 - val_accuracy: 0.8665\n",
            "Epoch 1325/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3186 - accuracy: 0.8797 - val_loss: 0.2723 - val_accuracy: 0.8999\n",
            "Epoch 1326/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2832 - accuracy: 0.8983 - val_loss: 0.2728 - val_accuracy: 0.9070\n",
            "Epoch 1327/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2813 - accuracy: 0.8981 - val_loss: 0.3124 - val_accuracy: 0.8820\n",
            "Epoch 1328/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2944 - accuracy: 0.8931 - val_loss: 0.2855 - val_accuracy: 0.8999\n",
            "Epoch 1329/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2941 - accuracy: 0.8931 - val_loss: 0.3058 - val_accuracy: 0.8820\n",
            "Epoch 1330/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2950 - accuracy: 0.8921 - val_loss: 0.3004 - val_accuracy: 0.8844\n",
            "Epoch 1331/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.3065 - accuracy: 0.8854 - val_loss: 0.2785 - val_accuracy: 0.8999\n",
            "Epoch 1332/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3014 - accuracy: 0.8874 - val_loss: 0.2889 - val_accuracy: 0.8868\n",
            "Epoch 1333/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2985 - accuracy: 0.8902 - val_loss: 0.2813 - val_accuracy: 0.8915\n",
            "Epoch 1334/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2890 - accuracy: 0.8919 - val_loss: 0.2888 - val_accuracy: 0.8915\n",
            "Epoch 1335/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2829 - accuracy: 0.8978 - val_loss: 0.2848 - val_accuracy: 0.8975\n",
            "Epoch 1336/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2886 - accuracy: 0.8919 - val_loss: 0.2806 - val_accuracy: 0.8939\n",
            "Epoch 1337/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2879 - accuracy: 0.8943 - val_loss: 0.2956 - val_accuracy: 0.8927\n",
            "Epoch 1338/1500\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.2783 - accuracy: 0.9005 - val_loss: 0.2702 - val_accuracy: 0.9058\n",
            "Epoch 1339/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2798 - accuracy: 0.9000 - val_loss: 0.2726 - val_accuracy: 0.9058\n",
            "Epoch 1340/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2869 - accuracy: 0.8981 - val_loss: 0.2746 - val_accuracy: 0.8987\n",
            "Epoch 1341/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2857 - accuracy: 0.8985 - val_loss: 0.3071 - val_accuracy: 0.8796\n",
            "Epoch 1342/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2943 - accuracy: 0.8916 - val_loss: 0.2937 - val_accuracy: 0.8939\n",
            "Epoch 1343/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2871 - accuracy: 0.8950 - val_loss: 0.2725 - val_accuracy: 0.8963\n",
            "Epoch 1344/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2937 - accuracy: 0.8943 - val_loss: 0.3180 - val_accuracy: 0.8808\n",
            "Epoch 1345/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2911 - accuracy: 0.8981 - val_loss: 0.2719 - val_accuracy: 0.8987\n",
            "Epoch 1346/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2787 - accuracy: 0.9007 - val_loss: 0.2818 - val_accuracy: 0.8939\n",
            "Epoch 1347/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2935 - accuracy: 0.8985 - val_loss: 0.2949 - val_accuracy: 0.8903\n",
            "Epoch 1348/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2879 - accuracy: 0.8952 - val_loss: 0.2834 - val_accuracy: 0.8999\n",
            "Epoch 1349/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2846 - accuracy: 0.8959 - val_loss: 0.2863 - val_accuracy: 0.8975\n",
            "Epoch 1350/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2830 - accuracy: 0.8966 - val_loss: 0.2902 - val_accuracy: 0.8915\n",
            "Epoch 1351/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3046 - accuracy: 0.8862 - val_loss: 0.3269 - val_accuracy: 0.8808\n",
            "Epoch 1352/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3041 - accuracy: 0.8862 - val_loss: 0.3039 - val_accuracy: 0.8892\n",
            "Epoch 1353/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3074 - accuracy: 0.8854 - val_loss: 0.2901 - val_accuracy: 0.8939\n",
            "Epoch 1354/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3124 - accuracy: 0.8845 - val_loss: 0.3099 - val_accuracy: 0.8808\n",
            "Epoch 1355/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2953 - accuracy: 0.8931 - val_loss: 0.3120 - val_accuracy: 0.8868\n",
            "Epoch 1356/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2916 - accuracy: 0.8971 - val_loss: 0.2908 - val_accuracy: 0.8856\n",
            "Epoch 1357/1500\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.2925 - accuracy: 0.8974 - val_loss: 0.2759 - val_accuracy: 0.9070\n",
            "Epoch 1358/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2954 - accuracy: 0.8890 - val_loss: 0.2857 - val_accuracy: 0.8927\n",
            "Epoch 1359/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2934 - accuracy: 0.8914 - val_loss: 0.2965 - val_accuracy: 0.8820\n",
            "Epoch 1360/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2867 - accuracy: 0.8914 - val_loss: 0.2942 - val_accuracy: 0.8999\n",
            "Epoch 1361/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2881 - accuracy: 0.8964 - val_loss: 0.2889 - val_accuracy: 0.8939\n",
            "Epoch 1362/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2860 - accuracy: 0.8945 - val_loss: 0.2965 - val_accuracy: 0.8963\n",
            "Epoch 1363/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2954 - accuracy: 0.8962 - val_loss: 0.2971 - val_accuracy: 0.8892\n",
            "Epoch 1364/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2967 - accuracy: 0.8895 - val_loss: 0.2988 - val_accuracy: 0.8880\n",
            "Epoch 1365/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2903 - accuracy: 0.8933 - val_loss: 0.3060 - val_accuracy: 0.8892\n",
            "Epoch 1366/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2828 - accuracy: 0.8959 - val_loss: 0.2682 - val_accuracy: 0.9023\n",
            "Epoch 1367/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2832 - accuracy: 0.8990 - val_loss: 0.2806 - val_accuracy: 0.8951\n",
            "Epoch 1368/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2783 - accuracy: 0.9031 - val_loss: 0.2707 - val_accuracy: 0.9035\n",
            "Epoch 1369/1500\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.2885 - accuracy: 0.8919 - val_loss: 0.3137 - val_accuracy: 0.8808\n",
            "Epoch 1370/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3069 - accuracy: 0.8874 - val_loss: 0.2686 - val_accuracy: 0.9011\n",
            "Epoch 1371/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2882 - accuracy: 0.8933 - val_loss: 0.2982 - val_accuracy: 0.8951\n",
            "Epoch 1372/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2938 - accuracy: 0.8926 - val_loss: 0.2899 - val_accuracy: 0.8915\n",
            "Epoch 1373/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2897 - accuracy: 0.8978 - val_loss: 0.3418 - val_accuracy: 0.8629\n",
            "Epoch 1374/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3068 - accuracy: 0.8809 - val_loss: 0.3338 - val_accuracy: 0.8784\n",
            "Epoch 1375/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3031 - accuracy: 0.8857 - val_loss: 0.2971 - val_accuracy: 0.8844\n",
            "Epoch 1376/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2836 - accuracy: 0.8974 - val_loss: 0.2825 - val_accuracy: 0.8880\n",
            "Epoch 1377/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2743 - accuracy: 0.9014 - val_loss: 0.2919 - val_accuracy: 0.8939\n",
            "Epoch 1378/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2978 - accuracy: 0.8900 - val_loss: 0.3378 - val_accuracy: 0.8629\n",
            "Epoch 1379/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3425 - accuracy: 0.8712 - val_loss: 0.3339 - val_accuracy: 0.8737\n",
            "Epoch 1380/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3409 - accuracy: 0.8697 - val_loss: 0.3454 - val_accuracy: 0.8665\n",
            "Epoch 1381/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3224 - accuracy: 0.8804 - val_loss: 0.2891 - val_accuracy: 0.8856\n",
            "Epoch 1382/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3136 - accuracy: 0.8854 - val_loss: 0.3000 - val_accuracy: 0.8844\n",
            "Epoch 1383/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2935 - accuracy: 0.8921 - val_loss: 0.2979 - val_accuracy: 0.8868\n",
            "Epoch 1384/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2858 - accuracy: 0.8912 - val_loss: 0.2848 - val_accuracy: 0.8927\n",
            "Epoch 1385/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2884 - accuracy: 0.8938 - val_loss: 0.2944 - val_accuracy: 0.8880\n",
            "Epoch 1386/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2867 - accuracy: 0.8943 - val_loss: 0.2857 - val_accuracy: 0.9023\n",
            "Epoch 1387/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2939 - accuracy: 0.8926 - val_loss: 0.2845 - val_accuracy: 0.9023\n",
            "Epoch 1388/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3050 - accuracy: 0.8854 - val_loss: 0.2771 - val_accuracy: 0.8999\n",
            "Epoch 1389/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3128 - accuracy: 0.8866 - val_loss: 0.3100 - val_accuracy: 0.8856\n",
            "Epoch 1390/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2955 - accuracy: 0.8912 - val_loss: 0.2877 - val_accuracy: 0.8951\n",
            "Epoch 1391/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2862 - accuracy: 0.8969 - val_loss: 0.2860 - val_accuracy: 0.8915\n",
            "Epoch 1392/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2826 - accuracy: 0.8966 - val_loss: 0.2916 - val_accuracy: 0.9046\n",
            "Epoch 1393/1500\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.2914 - accuracy: 0.8959 - val_loss: 0.2935 - val_accuracy: 0.8903\n",
            "Epoch 1394/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2870 - accuracy: 0.8969 - val_loss: 0.2745 - val_accuracy: 0.8987\n",
            "Epoch 1395/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2796 - accuracy: 0.8981 - val_loss: 0.3001 - val_accuracy: 0.8868\n",
            "Epoch 1396/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2934 - accuracy: 0.8957 - val_loss: 0.2782 - val_accuracy: 0.9023\n",
            "Epoch 1397/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2959 - accuracy: 0.8907 - val_loss: 0.2851 - val_accuracy: 0.8868\n",
            "Epoch 1398/1500\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.2948 - accuracy: 0.8938 - val_loss: 0.3072 - val_accuracy: 0.8844\n",
            "Epoch 1399/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3129 - accuracy: 0.8854 - val_loss: 0.3210 - val_accuracy: 0.8796\n",
            "Epoch 1400/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3346 - accuracy: 0.8783 - val_loss: 0.3424 - val_accuracy: 0.8677\n",
            "Epoch 1401/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3159 - accuracy: 0.8812 - val_loss: 0.2853 - val_accuracy: 0.8999\n",
            "Epoch 1402/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2922 - accuracy: 0.8962 - val_loss: 0.2770 - val_accuracy: 0.8868\n",
            "Epoch 1403/1500\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.2931 - accuracy: 0.8919 - val_loss: 0.2864 - val_accuracy: 0.8951\n",
            "Epoch 1404/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2887 - accuracy: 0.8921 - val_loss: 0.2702 - val_accuracy: 0.9046\n",
            "Epoch 1405/1500\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.2829 - accuracy: 0.8933 - val_loss: 0.3134 - val_accuracy: 0.8844\n",
            "Epoch 1406/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2959 - accuracy: 0.8885 - val_loss: 0.2624 - val_accuracy: 0.9058\n",
            "Epoch 1407/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2869 - accuracy: 0.8950 - val_loss: 0.2966 - val_accuracy: 0.8856\n",
            "Epoch 1408/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2995 - accuracy: 0.8940 - val_loss: 0.2796 - val_accuracy: 0.9035\n",
            "Epoch 1409/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2910 - accuracy: 0.8916 - val_loss: 0.2960 - val_accuracy: 0.9011\n",
            "Epoch 1410/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3008 - accuracy: 0.8900 - val_loss: 0.2867 - val_accuracy: 0.8999\n",
            "Epoch 1411/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2931 - accuracy: 0.8857 - val_loss: 0.3040 - val_accuracy: 0.8903\n",
            "Epoch 1412/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2902 - accuracy: 0.8940 - val_loss: 0.3063 - val_accuracy: 0.8903\n",
            "Epoch 1413/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3003 - accuracy: 0.8874 - val_loss: 0.3195 - val_accuracy: 0.8749\n",
            "Epoch 1414/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3037 - accuracy: 0.8890 - val_loss: 0.2850 - val_accuracy: 0.8951\n",
            "Epoch 1415/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3058 - accuracy: 0.8902 - val_loss: 0.3005 - val_accuracy: 0.8927\n",
            "Epoch 1416/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3180 - accuracy: 0.8845 - val_loss: 0.2945 - val_accuracy: 0.8999\n",
            "Epoch 1417/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3012 - accuracy: 0.8900 - val_loss: 0.2926 - val_accuracy: 0.8915\n",
            "Epoch 1418/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2919 - accuracy: 0.8940 - val_loss: 0.2855 - val_accuracy: 0.8987\n",
            "Epoch 1419/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2779 - accuracy: 0.9009 - val_loss: 0.2737 - val_accuracy: 0.8939\n",
            "Epoch 1420/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2879 - accuracy: 0.9021 - val_loss: 0.2891 - val_accuracy: 0.8892\n",
            "Epoch 1421/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2949 - accuracy: 0.8905 - val_loss: 0.2760 - val_accuracy: 0.9046\n",
            "Epoch 1422/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2839 - accuracy: 0.8993 - val_loss: 0.2693 - val_accuracy: 0.9070\n",
            "Epoch 1423/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2826 - accuracy: 0.8916 - val_loss: 0.2964 - val_accuracy: 0.8892\n",
            "Epoch 1424/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2863 - accuracy: 0.8997 - val_loss: 0.3185 - val_accuracy: 0.8713\n",
            "Epoch 1425/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3017 - accuracy: 0.8876 - val_loss: 0.2765 - val_accuracy: 0.9011\n",
            "Epoch 1426/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2885 - accuracy: 0.8933 - val_loss: 0.2748 - val_accuracy: 0.8963\n",
            "Epoch 1427/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2852 - accuracy: 0.8959 - val_loss: 0.2760 - val_accuracy: 0.8999\n",
            "Epoch 1428/1500\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.2857 - accuracy: 0.8955 - val_loss: 0.2824 - val_accuracy: 0.9023\n",
            "Epoch 1429/1500\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.2870 - accuracy: 0.8966 - val_loss: 0.2987 - val_accuracy: 0.8892\n",
            "Epoch 1430/1500\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.2888 - accuracy: 0.8947 - val_loss: 0.2832 - val_accuracy: 0.9023\n",
            "Epoch 1431/1500\n",
            "9/9 [==============================] - 1s 137ms/step - loss: 0.2939 - accuracy: 0.8900 - val_loss: 0.2994 - val_accuracy: 0.8820\n",
            "Epoch 1432/1500\n",
            "9/9 [==============================] - 1s 136ms/step - loss: 0.3044 - accuracy: 0.8819 - val_loss: 0.3779 - val_accuracy: 0.8653\n",
            "Epoch 1433/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3216 - accuracy: 0.8802 - val_loss: 0.2884 - val_accuracy: 0.8880\n",
            "Epoch 1434/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2858 - accuracy: 0.8938 - val_loss: 0.2930 - val_accuracy: 0.8844\n",
            "Epoch 1435/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2947 - accuracy: 0.8876 - val_loss: 0.2949 - val_accuracy: 0.8856\n",
            "Epoch 1436/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2908 - accuracy: 0.8916 - val_loss: 0.2822 - val_accuracy: 0.8975\n",
            "Epoch 1437/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2857 - accuracy: 0.8964 - val_loss: 0.2616 - val_accuracy: 0.9011\n",
            "Epoch 1438/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2852 - accuracy: 0.8950 - val_loss: 0.2695 - val_accuracy: 0.8987\n",
            "Epoch 1439/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2937 - accuracy: 0.8874 - val_loss: 0.2779 - val_accuracy: 0.8975\n",
            "Epoch 1440/1500\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.2829 - accuracy: 0.8995 - val_loss: 0.2955 - val_accuracy: 0.8892\n",
            "Epoch 1441/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2856 - accuracy: 0.8933 - val_loss: 0.2899 - val_accuracy: 0.8927\n",
            "Epoch 1442/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2901 - accuracy: 0.8974 - val_loss: 0.2932 - val_accuracy: 0.8856\n",
            "Epoch 1443/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2891 - accuracy: 0.8909 - val_loss: 0.3186 - val_accuracy: 0.8713\n",
            "Epoch 1444/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2948 - accuracy: 0.8878 - val_loss: 0.2848 - val_accuracy: 0.8987\n",
            "Epoch 1445/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2972 - accuracy: 0.8862 - val_loss: 0.3068 - val_accuracy: 0.8784\n",
            "Epoch 1446/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2965 - accuracy: 0.8885 - val_loss: 0.2921 - val_accuracy: 0.8987\n",
            "Epoch 1447/1500\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.2911 - accuracy: 0.8919 - val_loss: 0.2740 - val_accuracy: 0.8939\n",
            "Epoch 1448/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2784 - accuracy: 0.9024 - val_loss: 0.2963 - val_accuracy: 0.8963\n",
            "Epoch 1449/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2889 - accuracy: 0.8981 - val_loss: 0.3484 - val_accuracy: 0.8570\n",
            "Epoch 1450/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3209 - accuracy: 0.8766 - val_loss: 0.3276 - val_accuracy: 0.8749\n",
            "Epoch 1451/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3138 - accuracy: 0.8814 - val_loss: 0.2782 - val_accuracy: 0.8939\n",
            "Epoch 1452/1500\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.2926 - accuracy: 0.8883 - val_loss: 0.2758 - val_accuracy: 0.8892\n",
            "Epoch 1453/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2873 - accuracy: 0.8952 - val_loss: 0.2666 - val_accuracy: 0.8975\n",
            "Epoch 1454/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2770 - accuracy: 0.8997 - val_loss: 0.2957 - val_accuracy: 0.8903\n",
            "Epoch 1455/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2955 - accuracy: 0.8919 - val_loss: 0.3138 - val_accuracy: 0.8760\n",
            "Epoch 1456/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2889 - accuracy: 0.8952 - val_loss: 0.2831 - val_accuracy: 0.8868\n",
            "Epoch 1457/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2804 - accuracy: 0.8995 - val_loss: 0.2802 - val_accuracy: 0.8963\n",
            "Epoch 1458/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2750 - accuracy: 0.8976 - val_loss: 0.2747 - val_accuracy: 0.8963\n",
            "Epoch 1459/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2823 - accuracy: 0.8940 - val_loss: 0.2851 - val_accuracy: 0.8939\n",
            "Epoch 1460/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2863 - accuracy: 0.8919 - val_loss: 0.2811 - val_accuracy: 0.8903\n",
            "Epoch 1461/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2884 - accuracy: 0.8916 - val_loss: 0.3177 - val_accuracy: 0.8892\n",
            "Epoch 1462/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3006 - accuracy: 0.8878 - val_loss: 0.3396 - val_accuracy: 0.8617\n",
            "Epoch 1463/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3237 - accuracy: 0.8797 - val_loss: 0.2740 - val_accuracy: 0.9011\n",
            "Epoch 1464/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3048 - accuracy: 0.8840 - val_loss: 0.2713 - val_accuracy: 0.9023\n",
            "Epoch 1465/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2885 - accuracy: 0.8914 - val_loss: 0.2976 - val_accuracy: 0.8856\n",
            "Epoch 1466/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2879 - accuracy: 0.8935 - val_loss: 0.2826 - val_accuracy: 0.8939\n",
            "Epoch 1467/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2897 - accuracy: 0.8959 - val_loss: 0.3027 - val_accuracy: 0.8760\n",
            "Epoch 1468/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2992 - accuracy: 0.8869 - val_loss: 0.2731 - val_accuracy: 0.8999\n",
            "Epoch 1469/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2743 - accuracy: 0.9007 - val_loss: 0.3016 - val_accuracy: 0.8832\n",
            "Epoch 1470/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.2843 - accuracy: 0.8928 - val_loss: 0.3025 - val_accuracy: 0.8903\n",
            "Epoch 1471/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3012 - accuracy: 0.8874 - val_loss: 0.2740 - val_accuracy: 0.8963\n",
            "Epoch 1472/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2834 - accuracy: 0.8950 - val_loss: 0.2713 - val_accuracy: 0.8939\n",
            "Epoch 1473/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2917 - accuracy: 0.8933 - val_loss: 0.2890 - val_accuracy: 0.8832\n",
            "Epoch 1474/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3012 - accuracy: 0.8883 - val_loss: 0.3039 - val_accuracy: 0.8832\n",
            "Epoch 1475/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3020 - accuracy: 0.8866 - val_loss: 0.3107 - val_accuracy: 0.8796\n",
            "Epoch 1476/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3108 - accuracy: 0.8816 - val_loss: 0.3453 - val_accuracy: 0.8629\n",
            "Epoch 1477/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2987 - accuracy: 0.8907 - val_loss: 0.2725 - val_accuracy: 0.8999\n",
            "Epoch 1478/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2899 - accuracy: 0.8933 - val_loss: 0.2908 - val_accuracy: 0.8856\n",
            "Epoch 1479/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2837 - accuracy: 0.8940 - val_loss: 0.2875 - val_accuracy: 0.8892\n",
            "Epoch 1480/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2828 - accuracy: 0.8931 - val_loss: 0.2818 - val_accuracy: 0.8915\n",
            "Epoch 1481/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2764 - accuracy: 0.8940 - val_loss: 0.2862 - val_accuracy: 0.9035\n",
            "Epoch 1482/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2807 - accuracy: 0.8981 - val_loss: 0.3200 - val_accuracy: 0.8760\n",
            "Epoch 1483/1500\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3060 - accuracy: 0.8864 - val_loss: 0.2897 - val_accuracy: 0.8832\n",
            "Epoch 1484/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2800 - accuracy: 0.8978 - val_loss: 0.2872 - val_accuracy: 0.8903\n",
            "Epoch 1485/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2803 - accuracy: 0.9009 - val_loss: 0.2651 - val_accuracy: 0.8999\n",
            "Epoch 1486/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2713 - accuracy: 0.9033 - val_loss: 0.3260 - val_accuracy: 0.8582\n",
            "Epoch 1487/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2924 - accuracy: 0.8883 - val_loss: 0.2891 - val_accuracy: 0.8820\n",
            "Epoch 1488/1500\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.2706 - accuracy: 0.9014 - val_loss: 0.2740 - val_accuracy: 0.8880\n",
            "Epoch 1489/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2763 - accuracy: 0.9007 - val_loss: 0.2822 - val_accuracy: 0.8880\n",
            "Epoch 1490/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2802 - accuracy: 0.8943 - val_loss: 0.2789 - val_accuracy: 0.8880\n",
            "Epoch 1491/1500\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.2706 - accuracy: 0.9007 - val_loss: 0.2750 - val_accuracy: 0.8927\n",
            "Epoch 1492/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2779 - accuracy: 0.8964 - val_loss: 0.2895 - val_accuracy: 0.8903\n",
            "Epoch 1493/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2914 - accuracy: 0.8888 - val_loss: 0.3126 - val_accuracy: 0.8808\n",
            "Epoch 1494/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3284 - accuracy: 0.8800 - val_loss: 0.2895 - val_accuracy: 0.8868\n",
            "Epoch 1495/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.3031 - accuracy: 0.8857 - val_loss: 0.2856 - val_accuracy: 0.8927\n",
            "Epoch 1496/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2865 - accuracy: 0.8955 - val_loss: 0.2770 - val_accuracy: 0.8927\n",
            "Epoch 1497/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3023 - accuracy: 0.8862 - val_loss: 0.3040 - val_accuracy: 0.8880\n",
            "Epoch 1498/1500\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.2969 - accuracy: 0.8928 - val_loss: 0.2932 - val_accuracy: 0.8903\n",
            "Epoch 1499/1500\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.2798 - accuracy: 0.8978 - val_loss: 0.2925 - val_accuracy: 0.8856\n",
            "Epoch 1500/1500\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.2831 - accuracy: 0.8969 - val_loss: 0.2622 - val_accuracy: 0.9023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(1500)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "BKNae25WCnig",
        "outputId": "72134894-f63d-4824-9868-6f3f16dd06fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbWSne-PFoHt",
        "outputId": "f8bd7cc0-cbd6-4891-8d56-d879f08dadb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2622 - accuracy: 0.9023\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26223233342170715, 0.9022645950317383]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DxT9TiikwX65"
      }
    }
  ]
}